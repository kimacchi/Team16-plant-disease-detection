{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":150545,"sourceType":"datasetVersion","datasetId":70909},{"sourceId":182633,"sourceType":"datasetVersion","datasetId":78313},{"sourceId":658267,"sourceType":"datasetVersion","datasetId":277323}],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Plant Disease Detection using Transfer Learning (EfficientNet)\n\nThis notebook demonstrates how to use transfer learning with EfficientNet to classify plant diseases based on images.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nimport matplotlib.pyplot as plt\n\n# Check TensorFlow version\nprint(f'TensorFlow Version: {tf.__version__}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T12:43:42.912957Z","iopub.execute_input":"2024-12-07T12:43:42.913841Z","iopub.status.idle":"2024-12-07T12:43:42.919307Z","shell.execute_reply.started":"2024-12-07T12:43:42.913813Z","shell.execute_reply":"2024-12-07T12:43:42.918377Z"}},"outputs":[{"name":"stdout","text":"TensorFlow Version: 2.13.0\n","output_type":"stream"}],"execution_count":23},{"cell_type":"markdown","source":"## 1. Load and Preprocess Dataset\nAssume we have a dataset structured with separate folders for each class of plant disease.","metadata":{}},{"cell_type":"code","source":"# Define paths\ntrain_dir = '../input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train'\nval_dir = '../input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train'\n\n# Image dimensions\nimg_height, img_width = 256, 256\nbatch_size = 32\n\n# Data generators with augmentation for training\ntrain_datagen = ImageDataGenerator(\n    rescale=1.0/255,\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True\n)\nval_datagen = ImageDataGenerator(rescale=1.0/255)\n\n# Load data\ntrain_data = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode='categorical'\n)\nval_data = val_datagen.flow_from_directory(\n    val_dir,\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode='categorical'\n)\n\n\nfor data_batch, labels_batch in train_data:\n    print(data_batch.shape, labels_batch.shape)\n    break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T12:54:07.999087Z","iopub.execute_input":"2024-12-07T12:54:07.999566Z","iopub.status.idle":"2024-12-07T12:54:47.013004Z","shell.execute_reply.started":"2024-12-07T12:54:07.999511Z","shell.execute_reply":"2024-12-07T12:54:47.012231Z"}},"outputs":[{"name":"stdout","text":"Found 70295 images belonging to 38 classes.\nFound 70295 images belonging to 38 classes.\n(32, 256, 256, 3) (32, 38)\n","output_type":"stream"}],"execution_count":32},{"cell_type":"markdown","source":"## 2. Build the Model using EfficientNet","metadata":{}},{"cell_type":"code","source":"# Load the EfficientNetB0 model pre-trained on ImageNet\nbase_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n\n# Freeze the base model\nbase_model.trainable = True\n\n# Add custom layers on top\nx = base_model.output\nx = GlobalAveragePooling2D()(x)\nx = Dropout(0.5)(x)\noutput = Dense(train_data.num_classes, activation='softmax')(x)\n\n# Define the model\nmodel = Model(inputs=base_model.input, outputs=output)\n\n\n# Compile the model\nmodel.compile(optimizer=\"Adam\", loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Summary of the model\nmodel.summary()\n\nprint(f\"Train data classes: {train_data.num_classes}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T13:15:59.203384Z","iopub.execute_input":"2024-12-07T13:15:59.203727Z","iopub.status.idle":"2024-12-07T13:16:01.548871Z","shell.execute_reply.started":"2024-12-07T13:15:59.203699Z","shell.execute_reply":"2024-12-07T13:16:01.547968Z"}},"outputs":[{"name":"stdout","text":"Model: \"model_9\"\n__________________________________________________________________________________________________\n Layer (type)                Output Shape                 Param #   Connected to                  \n==================================================================================================\n input_10 (InputLayer)       [(None, 256, 256, 3)]        0         []                            \n                                                                                                  \n rescaling_18 (Rescaling)    (None, 256, 256, 3)          0         ['input_10[0][0]']            \n                                                                                                  \n normalization_9 (Normaliza  (None, 256, 256, 3)          7         ['rescaling_18[0][0]']        \n tion)                                                                                            \n                                                                                                  \n rescaling_19 (Rescaling)    (None, 256, 256, 3)          0         ['normalization_9[0][0]']     \n                                                                                                  \n stem_conv_pad (ZeroPadding  (None, 257, 257, 3)          0         ['rescaling_19[0][0]']        \n 2D)                                                                                              \n                                                                                                  \n stem_conv (Conv2D)          (None, 128, 128, 32)         864       ['stem_conv_pad[0][0]']       \n                                                                                                  \n stem_bn (BatchNormalizatio  (None, 128, 128, 32)         128       ['stem_conv[0][0]']           \n n)                                                                                               \n                                                                                                  \n stem_activation (Activatio  (None, 128, 128, 32)         0         ['stem_bn[0][0]']             \n n)                                                                                               \n                                                                                                  \n block1a_dwconv (DepthwiseC  (None, 128, 128, 32)         288       ['stem_activation[0][0]']     \n onv2D)                                                                                           \n                                                                                                  \n block1a_bn (BatchNormaliza  (None, 128, 128, 32)         128       ['block1a_dwconv[0][0]']      \n tion)                                                                                            \n                                                                                                  \n block1a_activation (Activa  (None, 128, 128, 32)         0         ['block1a_bn[0][0]']          \n tion)                                                                                            \n                                                                                                  \n block1a_se_squeeze (Global  (None, 32)                   0         ['block1a_activation[0][0]']  \n AveragePooling2D)                                                                                \n                                                                                                  \n block1a_se_reshape (Reshap  (None, 1, 1, 32)             0         ['block1a_se_squeeze[0][0]']  \n e)                                                                                               \n                                                                                                  \n block1a_se_reduce (Conv2D)  (None, 1, 1, 8)              264       ['block1a_se_reshape[0][0]']  \n                                                                                                  \n block1a_se_expand (Conv2D)  (None, 1, 1, 32)             288       ['block1a_se_reduce[0][0]']   \n                                                                                                  \n block1a_se_excite (Multipl  (None, 128, 128, 32)         0         ['block1a_activation[0][0]',  \n y)                                                                  'block1a_se_expand[0][0]']   \n                                                                                                  \n block1a_project_conv (Conv  (None, 128, 128, 16)         512       ['block1a_se_excite[0][0]']   \n 2D)                                                                                              \n                                                                                                  \n block1a_project_bn (BatchN  (None, 128, 128, 16)         64        ['block1a_project_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n block2a_expand_conv (Conv2  (None, 128, 128, 96)         1536      ['block1a_project_bn[0][0]']  \n D)                                                                                               \n                                                                                                  \n block2a_expand_bn (BatchNo  (None, 128, 128, 96)         384       ['block2a_expand_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n block2a_expand_activation   (None, 128, 128, 96)         0         ['block2a_expand_bn[0][0]']   \n (Activation)                                                                                     \n                                                                                                  \n block2a_dwconv_pad (ZeroPa  (None, 129, 129, 96)         0         ['block2a_expand_activation[0]\n dding2D)                                                           [0]']                         \n                                                                                                  \n block2a_dwconv (DepthwiseC  (None, 64, 64, 96)           864       ['block2a_dwconv_pad[0][0]']  \n onv2D)                                                                                           \n                                                                                                  \n block2a_bn (BatchNormaliza  (None, 64, 64, 96)           384       ['block2a_dwconv[0][0]']      \n tion)                                                                                            \n                                                                                                  \n block2a_activation (Activa  (None, 64, 64, 96)           0         ['block2a_bn[0][0]']          \n tion)                                                                                            \n                                                                                                  \n block2a_se_squeeze (Global  (None, 96)                   0         ['block2a_activation[0][0]']  \n AveragePooling2D)                                                                                \n                                                                                                  \n block2a_se_reshape (Reshap  (None, 1, 1, 96)             0         ['block2a_se_squeeze[0][0]']  \n e)                                                                                               \n                                                                                                  \n block2a_se_reduce (Conv2D)  (None, 1, 1, 4)              388       ['block2a_se_reshape[0][0]']  \n                                                                                                  \n block2a_se_expand (Conv2D)  (None, 1, 1, 96)             480       ['block2a_se_reduce[0][0]']   \n                                                                                                  \n block2a_se_excite (Multipl  (None, 64, 64, 96)           0         ['block2a_activation[0][0]',  \n y)                                                                  'block2a_se_expand[0][0]']   \n                                                                                                  \n block2a_project_conv (Conv  (None, 64, 64, 24)           2304      ['block2a_se_excite[0][0]']   \n 2D)                                                                                              \n                                                                                                  \n block2a_project_bn (BatchN  (None, 64, 64, 24)           96        ['block2a_project_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n block2b_expand_conv (Conv2  (None, 64, 64, 144)          3456      ['block2a_project_bn[0][0]']  \n D)                                                                                               \n                                                                                                  \n block2b_expand_bn (BatchNo  (None, 64, 64, 144)          576       ['block2b_expand_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n block2b_expand_activation   (None, 64, 64, 144)          0         ['block2b_expand_bn[0][0]']   \n (Activation)                                                                                     \n                                                                                                  \n block2b_dwconv (DepthwiseC  (None, 64, 64, 144)          1296      ['block2b_expand_activation[0]\n onv2D)                                                             [0]']                         \n                                                                                                  \n block2b_bn (BatchNormaliza  (None, 64, 64, 144)          576       ['block2b_dwconv[0][0]']      \n tion)                                                                                            \n                                                                                                  \n block2b_activation (Activa  (None, 64, 64, 144)          0         ['block2b_bn[0][0]']          \n tion)                                                                                            \n                                                                                                  \n block2b_se_squeeze (Global  (None, 144)                  0         ['block2b_activation[0][0]']  \n AveragePooling2D)                                                                                \n                                                                                                  \n block2b_se_reshape (Reshap  (None, 1, 1, 144)            0         ['block2b_se_squeeze[0][0]']  \n e)                                                                                               \n                                                                                                  \n block2b_se_reduce (Conv2D)  (None, 1, 1, 6)              870       ['block2b_se_reshape[0][0]']  \n                                                                                                  \n block2b_se_expand (Conv2D)  (None, 1, 1, 144)            1008      ['block2b_se_reduce[0][0]']   \n                                                                                                  \n block2b_se_excite (Multipl  (None, 64, 64, 144)          0         ['block2b_activation[0][0]',  \n y)                                                                  'block2b_se_expand[0][0]']   \n                                                                                                  \n block2b_project_conv (Conv  (None, 64, 64, 24)           3456      ['block2b_se_excite[0][0]']   \n 2D)                                                                                              \n                                                                                                  \n block2b_project_bn (BatchN  (None, 64, 64, 24)           96        ['block2b_project_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n block2b_drop (Dropout)      (None, 64, 64, 24)           0         ['block2b_project_bn[0][0]']  \n                                                                                                  \n block2b_add (Add)           (None, 64, 64, 24)           0         ['block2b_drop[0][0]',        \n                                                                     'block2a_project_bn[0][0]']  \n                                                                                                  \n block3a_expand_conv (Conv2  (None, 64, 64, 144)          3456      ['block2b_add[0][0]']         \n D)                                                                                               \n                                                                                                  \n block3a_expand_bn (BatchNo  (None, 64, 64, 144)          576       ['block3a_expand_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n block3a_expand_activation   (None, 64, 64, 144)          0         ['block3a_expand_bn[0][0]']   \n (Activation)                                                                                     \n                                                                                                  \n block3a_dwconv_pad (ZeroPa  (None, 67, 67, 144)          0         ['block3a_expand_activation[0]\n dding2D)                                                           [0]']                         \n                                                                                                  \n block3a_dwconv (DepthwiseC  (None, 32, 32, 144)          3600      ['block3a_dwconv_pad[0][0]']  \n onv2D)                                                                                           \n                                                                                                  \n block3a_bn (BatchNormaliza  (None, 32, 32, 144)          576       ['block3a_dwconv[0][0]']      \n tion)                                                                                            \n                                                                                                  \n block3a_activation (Activa  (None, 32, 32, 144)          0         ['block3a_bn[0][0]']          \n tion)                                                                                            \n                                                                                                  \n block3a_se_squeeze (Global  (None, 144)                  0         ['block3a_activation[0][0]']  \n AveragePooling2D)                                                                                \n                                                                                                  \n block3a_se_reshape (Reshap  (None, 1, 1, 144)            0         ['block3a_se_squeeze[0][0]']  \n e)                                                                                               \n                                                                                                  \n block3a_se_reduce (Conv2D)  (None, 1, 1, 6)              870       ['block3a_se_reshape[0][0]']  \n                                                                                                  \n block3a_se_expand (Conv2D)  (None, 1, 1, 144)            1008      ['block3a_se_reduce[0][0]']   \n                                                                                                  \n block3a_se_excite (Multipl  (None, 32, 32, 144)          0         ['block3a_activation[0][0]',  \n y)                                                                  'block3a_se_expand[0][0]']   \n                                                                                                  \n block3a_project_conv (Conv  (None, 32, 32, 40)           5760      ['block3a_se_excite[0][0]']   \n 2D)                                                                                              \n                                                                                                  \n block3a_project_bn (BatchN  (None, 32, 32, 40)           160       ['block3a_project_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n block3b_expand_conv (Conv2  (None, 32, 32, 240)          9600      ['block3a_project_bn[0][0]']  \n D)                                                                                               \n                                                                                                  \n block3b_expand_bn (BatchNo  (None, 32, 32, 240)          960       ['block3b_expand_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n block3b_expand_activation   (None, 32, 32, 240)          0         ['block3b_expand_bn[0][0]']   \n (Activation)                                                                                     \n                                                                                                  \n block3b_dwconv (DepthwiseC  (None, 32, 32, 240)          6000      ['block3b_expand_activation[0]\n onv2D)                                                             [0]']                         \n                                                                                                  \n block3b_bn (BatchNormaliza  (None, 32, 32, 240)          960       ['block3b_dwconv[0][0]']      \n tion)                                                                                            \n                                                                                                  \n block3b_activation (Activa  (None, 32, 32, 240)          0         ['block3b_bn[0][0]']          \n tion)                                                                                            \n                                                                                                  \n block3b_se_squeeze (Global  (None, 240)                  0         ['block3b_activation[0][0]']  \n AveragePooling2D)                                                                                \n                                                                                                  \n block3b_se_reshape (Reshap  (None, 1, 1, 240)            0         ['block3b_se_squeeze[0][0]']  \n e)                                                                                               \n                                                                                                  \n block3b_se_reduce (Conv2D)  (None, 1, 1, 10)             2410      ['block3b_se_reshape[0][0]']  \n                                                                                                  \n block3b_se_expand (Conv2D)  (None, 1, 1, 240)            2640      ['block3b_se_reduce[0][0]']   \n                                                                                                  \n block3b_se_excite (Multipl  (None, 32, 32, 240)          0         ['block3b_activation[0][0]',  \n y)                                                                  'block3b_se_expand[0][0]']   \n                                                                                                  \n block3b_project_conv (Conv  (None, 32, 32, 40)           9600      ['block3b_se_excite[0][0]']   \n 2D)                                                                                              \n                                                                                                  \n block3b_project_bn (BatchN  (None, 32, 32, 40)           160       ['block3b_project_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n block3b_drop (Dropout)      (None, 32, 32, 40)           0         ['block3b_project_bn[0][0]']  \n                                                                                                  \n block3b_add (Add)           (None, 32, 32, 40)           0         ['block3b_drop[0][0]',        \n                                                                     'block3a_project_bn[0][0]']  \n                                                                                                  \n block4a_expand_conv (Conv2  (None, 32, 32, 240)          9600      ['block3b_add[0][0]']         \n D)                                                                                               \n                                                                                                  \n block4a_expand_bn (BatchNo  (None, 32, 32, 240)          960       ['block4a_expand_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n block4a_expand_activation   (None, 32, 32, 240)          0         ['block4a_expand_bn[0][0]']   \n (Activation)                                                                                     \n                                                                                                  \n block4a_dwconv_pad (ZeroPa  (None, 33, 33, 240)          0         ['block4a_expand_activation[0]\n dding2D)                                                           [0]']                         \n                                                                                                  \n block4a_dwconv (DepthwiseC  (None, 16, 16, 240)          2160      ['block4a_dwconv_pad[0][0]']  \n onv2D)                                                                                           \n                                                                                                  \n block4a_bn (BatchNormaliza  (None, 16, 16, 240)          960       ['block4a_dwconv[0][0]']      \n tion)                                                                                            \n                                                                                                  \n block4a_activation (Activa  (None, 16, 16, 240)          0         ['block4a_bn[0][0]']          \n tion)                                                                                            \n                                                                                                  \n block4a_se_squeeze (Global  (None, 240)                  0         ['block4a_activation[0][0]']  \n AveragePooling2D)                                                                                \n                                                                                                  \n block4a_se_reshape (Reshap  (None, 1, 1, 240)            0         ['block4a_se_squeeze[0][0]']  \n e)                                                                                               \n                                                                                                  \n block4a_se_reduce (Conv2D)  (None, 1, 1, 10)             2410      ['block4a_se_reshape[0][0]']  \n                                                                                                  \n block4a_se_expand (Conv2D)  (None, 1, 1, 240)            2640      ['block4a_se_reduce[0][0]']   \n                                                                                                  \n block4a_se_excite (Multipl  (None, 16, 16, 240)          0         ['block4a_activation[0][0]',  \n y)                                                                  'block4a_se_expand[0][0]']   \n                                                                                                  \n block4a_project_conv (Conv  (None, 16, 16, 80)           19200     ['block4a_se_excite[0][0]']   \n 2D)                                                                                              \n                                                                                                  \n block4a_project_bn (BatchN  (None, 16, 16, 80)           320       ['block4a_project_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n block4b_expand_conv (Conv2  (None, 16, 16, 480)          38400     ['block4a_project_bn[0][0]']  \n D)                                                                                               \n                                                                                                  \n block4b_expand_bn (BatchNo  (None, 16, 16, 480)          1920      ['block4b_expand_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n block4b_expand_activation   (None, 16, 16, 480)          0         ['block4b_expand_bn[0][0]']   \n (Activation)                                                                                     \n                                                                                                  \n block4b_dwconv (DepthwiseC  (None, 16, 16, 480)          4320      ['block4b_expand_activation[0]\n onv2D)                                                             [0]']                         \n                                                                                                  \n block4b_bn (BatchNormaliza  (None, 16, 16, 480)          1920      ['block4b_dwconv[0][0]']      \n tion)                                                                                            \n                                                                                                  \n block4b_activation (Activa  (None, 16, 16, 480)          0         ['block4b_bn[0][0]']          \n tion)                                                                                            \n                                                                                                  \n block4b_se_squeeze (Global  (None, 480)                  0         ['block4b_activation[0][0]']  \n AveragePooling2D)                                                                                \n                                                                                                  \n block4b_se_reshape (Reshap  (None, 1, 1, 480)            0         ['block4b_se_squeeze[0][0]']  \n e)                                                                                               \n                                                                                                  \n block4b_se_reduce (Conv2D)  (None, 1, 1, 20)             9620      ['block4b_se_reshape[0][0]']  \n                                                                                                  \n block4b_se_expand (Conv2D)  (None, 1, 1, 480)            10080     ['block4b_se_reduce[0][0]']   \n                                                                                                  \n block4b_se_excite (Multipl  (None, 16, 16, 480)          0         ['block4b_activation[0][0]',  \n y)                                                                  'block4b_se_expand[0][0]']   \n                                                                                                  \n block4b_project_conv (Conv  (None, 16, 16, 80)           38400     ['block4b_se_excite[0][0]']   \n 2D)                                                                                              \n                                                                                                  \n block4b_project_bn (BatchN  (None, 16, 16, 80)           320       ['block4b_project_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n block4b_drop (Dropout)      (None, 16, 16, 80)           0         ['block4b_project_bn[0][0]']  \n                                                                                                  \n block4b_add (Add)           (None, 16, 16, 80)           0         ['block4b_drop[0][0]',        \n                                                                     'block4a_project_bn[0][0]']  \n                                                                                                  \n block4c_expand_conv (Conv2  (None, 16, 16, 480)          38400     ['block4b_add[0][0]']         \n D)                                                                                               \n                                                                                                  \n block4c_expand_bn (BatchNo  (None, 16, 16, 480)          1920      ['block4c_expand_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n block4c_expand_activation   (None, 16, 16, 480)          0         ['block4c_expand_bn[0][0]']   \n (Activation)                                                                                     \n                                                                                                  \n block4c_dwconv (DepthwiseC  (None, 16, 16, 480)          4320      ['block4c_expand_activation[0]\n onv2D)                                                             [0]']                         \n                                                                                                  \n block4c_bn (BatchNormaliza  (None, 16, 16, 480)          1920      ['block4c_dwconv[0][0]']      \n tion)                                                                                            \n                                                                                                  \n block4c_activation (Activa  (None, 16, 16, 480)          0         ['block4c_bn[0][0]']          \n tion)                                                                                            \n                                                                                                  \n block4c_se_squeeze (Global  (None, 480)                  0         ['block4c_activation[0][0]']  \n AveragePooling2D)                                                                                \n                                                                                                  \n block4c_se_reshape (Reshap  (None, 1, 1, 480)            0         ['block4c_se_squeeze[0][0]']  \n e)                                                                                               \n                                                                                                  \n block4c_se_reduce (Conv2D)  (None, 1, 1, 20)             9620      ['block4c_se_reshape[0][0]']  \n                                                                                                  \n block4c_se_expand (Conv2D)  (None, 1, 1, 480)            10080     ['block4c_se_reduce[0][0]']   \n                                                                                                  \n block4c_se_excite (Multipl  (None, 16, 16, 480)          0         ['block4c_activation[0][0]',  \n y)                                                                  'block4c_se_expand[0][0]']   \n                                                                                                  \n block4c_project_conv (Conv  (None, 16, 16, 80)           38400     ['block4c_se_excite[0][0]']   \n 2D)                                                                                              \n                                                                                                  \n block4c_project_bn (BatchN  (None, 16, 16, 80)           320       ['block4c_project_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n block4c_drop (Dropout)      (None, 16, 16, 80)           0         ['block4c_project_bn[0][0]']  \n                                                                                                  \n block4c_add (Add)           (None, 16, 16, 80)           0         ['block4c_drop[0][0]',        \n                                                                     'block4b_add[0][0]']         \n                                                                                                  \n block5a_expand_conv (Conv2  (None, 16, 16, 480)          38400     ['block4c_add[0][0]']         \n D)                                                                                               \n                                                                                                  \n block5a_expand_bn (BatchNo  (None, 16, 16, 480)          1920      ['block5a_expand_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n block5a_expand_activation   (None, 16, 16, 480)          0         ['block5a_expand_bn[0][0]']   \n (Activation)                                                                                     \n                                                                                                  \n block5a_dwconv (DepthwiseC  (None, 16, 16, 480)          12000     ['block5a_expand_activation[0]\n onv2D)                                                             [0]']                         \n                                                                                                  \n block5a_bn (BatchNormaliza  (None, 16, 16, 480)          1920      ['block5a_dwconv[0][0]']      \n tion)                                                                                            \n                                                                                                  \n block5a_activation (Activa  (None, 16, 16, 480)          0         ['block5a_bn[0][0]']          \n tion)                                                                                            \n                                                                                                  \n block5a_se_squeeze (Global  (None, 480)                  0         ['block5a_activation[0][0]']  \n AveragePooling2D)                                                                                \n                                                                                                  \n block5a_se_reshape (Reshap  (None, 1, 1, 480)            0         ['block5a_se_squeeze[0][0]']  \n e)                                                                                               \n                                                                                                  \n block5a_se_reduce (Conv2D)  (None, 1, 1, 20)             9620      ['block5a_se_reshape[0][0]']  \n                                                                                                  \n block5a_se_expand (Conv2D)  (None, 1, 1, 480)            10080     ['block5a_se_reduce[0][0]']   \n                                                                                                  \n block5a_se_excite (Multipl  (None, 16, 16, 480)          0         ['block5a_activation[0][0]',  \n y)                                                                  'block5a_se_expand[0][0]']   \n                                                                                                  \n block5a_project_conv (Conv  (None, 16, 16, 112)          53760     ['block5a_se_excite[0][0]']   \n 2D)                                                                                              \n                                                                                                  \n block5a_project_bn (BatchN  (None, 16, 16, 112)          448       ['block5a_project_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n block5b_expand_conv (Conv2  (None, 16, 16, 672)          75264     ['block5a_project_bn[0][0]']  \n D)                                                                                               \n                                                                                                  \n block5b_expand_bn (BatchNo  (None, 16, 16, 672)          2688      ['block5b_expand_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n block5b_expand_activation   (None, 16, 16, 672)          0         ['block5b_expand_bn[0][0]']   \n (Activation)                                                                                     \n                                                                                                  \n block5b_dwconv (DepthwiseC  (None, 16, 16, 672)          16800     ['block5b_expand_activation[0]\n onv2D)                                                             [0]']                         \n                                                                                                  \n block5b_bn (BatchNormaliza  (None, 16, 16, 672)          2688      ['block5b_dwconv[0][0]']      \n tion)                                                                                            \n                                                                                                  \n block5b_activation (Activa  (None, 16, 16, 672)          0         ['block5b_bn[0][0]']          \n tion)                                                                                            \n                                                                                                  \n block5b_se_squeeze (Global  (None, 672)                  0         ['block5b_activation[0][0]']  \n AveragePooling2D)                                                                                \n                                                                                                  \n block5b_se_reshape (Reshap  (None, 1, 1, 672)            0         ['block5b_se_squeeze[0][0]']  \n e)                                                                                               \n                                                                                                  \n block5b_se_reduce (Conv2D)  (None, 1, 1, 28)             18844     ['block5b_se_reshape[0][0]']  \n                                                                                                  \n block5b_se_expand (Conv2D)  (None, 1, 1, 672)            19488     ['block5b_se_reduce[0][0]']   \n                                                                                                  \n block5b_se_excite (Multipl  (None, 16, 16, 672)          0         ['block5b_activation[0][0]',  \n y)                                                                  'block5b_se_expand[0][0]']   \n                                                                                                  \n block5b_project_conv (Conv  (None, 16, 16, 112)          75264     ['block5b_se_excite[0][0]']   \n 2D)                                                                                              \n                                                                                                  \n block5b_project_bn (BatchN  (None, 16, 16, 112)          448       ['block5b_project_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n block5b_drop (Dropout)      (None, 16, 16, 112)          0         ['block5b_project_bn[0][0]']  \n                                                                                                  \n block5b_add (Add)           (None, 16, 16, 112)          0         ['block5b_drop[0][0]',        \n                                                                     'block5a_project_bn[0][0]']  \n                                                                                                  \n block5c_expand_conv (Conv2  (None, 16, 16, 672)          75264     ['block5b_add[0][0]']         \n D)                                                                                               \n                                                                                                  \n block5c_expand_bn (BatchNo  (None, 16, 16, 672)          2688      ['block5c_expand_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n block5c_expand_activation   (None, 16, 16, 672)          0         ['block5c_expand_bn[0][0]']   \n (Activation)                                                                                     \n                                                                                                  \n block5c_dwconv (DepthwiseC  (None, 16, 16, 672)          16800     ['block5c_expand_activation[0]\n onv2D)                                                             [0]']                         \n                                                                                                  \n block5c_bn (BatchNormaliza  (None, 16, 16, 672)          2688      ['block5c_dwconv[0][0]']      \n tion)                                                                                            \n                                                                                                  \n block5c_activation (Activa  (None, 16, 16, 672)          0         ['block5c_bn[0][0]']          \n tion)                                                                                            \n                                                                                                  \n block5c_se_squeeze (Global  (None, 672)                  0         ['block5c_activation[0][0]']  \n AveragePooling2D)                                                                                \n                                                                                                  \n block5c_se_reshape (Reshap  (None, 1, 1, 672)            0         ['block5c_se_squeeze[0][0]']  \n e)                                                                                               \n                                                                                                  \n block5c_se_reduce (Conv2D)  (None, 1, 1, 28)             18844     ['block5c_se_reshape[0][0]']  \n                                                                                                  \n block5c_se_expand (Conv2D)  (None, 1, 1, 672)            19488     ['block5c_se_reduce[0][0]']   \n                                                                                                  \n block5c_se_excite (Multipl  (None, 16, 16, 672)          0         ['block5c_activation[0][0]',  \n y)                                                                  'block5c_se_expand[0][0]']   \n                                                                                                  \n block5c_project_conv (Conv  (None, 16, 16, 112)          75264     ['block5c_se_excite[0][0]']   \n 2D)                                                                                              \n                                                                                                  \n block5c_project_bn (BatchN  (None, 16, 16, 112)          448       ['block5c_project_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n block5c_drop (Dropout)      (None, 16, 16, 112)          0         ['block5c_project_bn[0][0]']  \n                                                                                                  \n block5c_add (Add)           (None, 16, 16, 112)          0         ['block5c_drop[0][0]',        \n                                                                     'block5b_add[0][0]']         \n                                                                                                  \n block6a_expand_conv (Conv2  (None, 16, 16, 672)          75264     ['block5c_add[0][0]']         \n D)                                                                                               \n                                                                                                  \n block6a_expand_bn (BatchNo  (None, 16, 16, 672)          2688      ['block6a_expand_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n block6a_expand_activation   (None, 16, 16, 672)          0         ['block6a_expand_bn[0][0]']   \n (Activation)                                                                                     \n                                                                                                  \n block6a_dwconv_pad (ZeroPa  (None, 19, 19, 672)          0         ['block6a_expand_activation[0]\n dding2D)                                                           [0]']                         \n                                                                                                  \n block6a_dwconv (DepthwiseC  (None, 8, 8, 672)            16800     ['block6a_dwconv_pad[0][0]']  \n onv2D)                                                                                           \n                                                                                                  \n block6a_bn (BatchNormaliza  (None, 8, 8, 672)            2688      ['block6a_dwconv[0][0]']      \n tion)                                                                                            \n                                                                                                  \n block6a_activation (Activa  (None, 8, 8, 672)            0         ['block6a_bn[0][0]']          \n tion)                                                                                            \n                                                                                                  \n block6a_se_squeeze (Global  (None, 672)                  0         ['block6a_activation[0][0]']  \n AveragePooling2D)                                                                                \n                                                                                                  \n block6a_se_reshape (Reshap  (None, 1, 1, 672)            0         ['block6a_se_squeeze[0][0]']  \n e)                                                                                               \n                                                                                                  \n block6a_se_reduce (Conv2D)  (None, 1, 1, 28)             18844     ['block6a_se_reshape[0][0]']  \n                                                                                                  \n block6a_se_expand (Conv2D)  (None, 1, 1, 672)            19488     ['block6a_se_reduce[0][0]']   \n                                                                                                  \n block6a_se_excite (Multipl  (None, 8, 8, 672)            0         ['block6a_activation[0][0]',  \n y)                                                                  'block6a_se_expand[0][0]']   \n                                                                                                  \n block6a_project_conv (Conv  (None, 8, 8, 192)            129024    ['block6a_se_excite[0][0]']   \n 2D)                                                                                              \n                                                                                                  \n block6a_project_bn (BatchN  (None, 8, 8, 192)            768       ['block6a_project_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n block6b_expand_conv (Conv2  (None, 8, 8, 1152)           221184    ['block6a_project_bn[0][0]']  \n D)                                                                                               \n                                                                                                  \n block6b_expand_bn (BatchNo  (None, 8, 8, 1152)           4608      ['block6b_expand_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n block6b_expand_activation   (None, 8, 8, 1152)           0         ['block6b_expand_bn[0][0]']   \n (Activation)                                                                                     \n                                                                                                  \n block6b_dwconv (DepthwiseC  (None, 8, 8, 1152)           28800     ['block6b_expand_activation[0]\n onv2D)                                                             [0]']                         \n                                                                                                  \n block6b_bn (BatchNormaliza  (None, 8, 8, 1152)           4608      ['block6b_dwconv[0][0]']      \n tion)                                                                                            \n                                                                                                  \n block6b_activation (Activa  (None, 8, 8, 1152)           0         ['block6b_bn[0][0]']          \n tion)                                                                                            \n                                                                                                  \n block6b_se_squeeze (Global  (None, 1152)                 0         ['block6b_activation[0][0]']  \n AveragePooling2D)                                                                                \n                                                                                                  \n block6b_se_reshape (Reshap  (None, 1, 1, 1152)           0         ['block6b_se_squeeze[0][0]']  \n e)                                                                                               \n                                                                                                  \n block6b_se_reduce (Conv2D)  (None, 1, 1, 48)             55344     ['block6b_se_reshape[0][0]']  \n                                                                                                  \n block6b_se_expand (Conv2D)  (None, 1, 1, 1152)           56448     ['block6b_se_reduce[0][0]']   \n                                                                                                  \n block6b_se_excite (Multipl  (None, 8, 8, 1152)           0         ['block6b_activation[0][0]',  \n y)                                                                  'block6b_se_expand[0][0]']   \n                                                                                                  \n block6b_project_conv (Conv  (None, 8, 8, 192)            221184    ['block6b_se_excite[0][0]']   \n 2D)                                                                                              \n                                                                                                  \n block6b_project_bn (BatchN  (None, 8, 8, 192)            768       ['block6b_project_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n block6b_drop (Dropout)      (None, 8, 8, 192)            0         ['block6b_project_bn[0][0]']  \n                                                                                                  \n block6b_add (Add)           (None, 8, 8, 192)            0         ['block6b_drop[0][0]',        \n                                                                     'block6a_project_bn[0][0]']  \n                                                                                                  \n block6c_expand_conv (Conv2  (None, 8, 8, 1152)           221184    ['block6b_add[0][0]']         \n D)                                                                                               \n                                                                                                  \n block6c_expand_bn (BatchNo  (None, 8, 8, 1152)           4608      ['block6c_expand_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n block6c_expand_activation   (None, 8, 8, 1152)           0         ['block6c_expand_bn[0][0]']   \n (Activation)                                                                                     \n                                                                                                  \n block6c_dwconv (DepthwiseC  (None, 8, 8, 1152)           28800     ['block6c_expand_activation[0]\n onv2D)                                                             [0]']                         \n                                                                                                  \n block6c_bn (BatchNormaliza  (None, 8, 8, 1152)           4608      ['block6c_dwconv[0][0]']      \n tion)                                                                                            \n                                                                                                  \n block6c_activation (Activa  (None, 8, 8, 1152)           0         ['block6c_bn[0][0]']          \n tion)                                                                                            \n                                                                                                  \n block6c_se_squeeze (Global  (None, 1152)                 0         ['block6c_activation[0][0]']  \n AveragePooling2D)                                                                                \n                                                                                                  \n block6c_se_reshape (Reshap  (None, 1, 1, 1152)           0         ['block6c_se_squeeze[0][0]']  \n e)                                                                                               \n                                                                                                  \n block6c_se_reduce (Conv2D)  (None, 1, 1, 48)             55344     ['block6c_se_reshape[0][0]']  \n                                                                                                  \n block6c_se_expand (Conv2D)  (None, 1, 1, 1152)           56448     ['block6c_se_reduce[0][0]']   \n                                                                                                  \n block6c_se_excite (Multipl  (None, 8, 8, 1152)           0         ['block6c_activation[0][0]',  \n y)                                                                  'block6c_se_expand[0][0]']   \n                                                                                                  \n block6c_project_conv (Conv  (None, 8, 8, 192)            221184    ['block6c_se_excite[0][0]']   \n 2D)                                                                                              \n                                                                                                  \n block6c_project_bn (BatchN  (None, 8, 8, 192)            768       ['block6c_project_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n block6c_drop (Dropout)      (None, 8, 8, 192)            0         ['block6c_project_bn[0][0]']  \n                                                                                                  \n block6c_add (Add)           (None, 8, 8, 192)            0         ['block6c_drop[0][0]',        \n                                                                     'block6b_add[0][0]']         \n                                                                                                  \n block6d_expand_conv (Conv2  (None, 8, 8, 1152)           221184    ['block6c_add[0][0]']         \n D)                                                                                               \n                                                                                                  \n block6d_expand_bn (BatchNo  (None, 8, 8, 1152)           4608      ['block6d_expand_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n block6d_expand_activation   (None, 8, 8, 1152)           0         ['block6d_expand_bn[0][0]']   \n (Activation)                                                                                     \n                                                                                                  \n block6d_dwconv (DepthwiseC  (None, 8, 8, 1152)           28800     ['block6d_expand_activation[0]\n onv2D)                                                             [0]']                         \n                                                                                                  \n block6d_bn (BatchNormaliza  (None, 8, 8, 1152)           4608      ['block6d_dwconv[0][0]']      \n tion)                                                                                            \n                                                                                                  \n block6d_activation (Activa  (None, 8, 8, 1152)           0         ['block6d_bn[0][0]']          \n tion)                                                                                            \n                                                                                                  \n block6d_se_squeeze (Global  (None, 1152)                 0         ['block6d_activation[0][0]']  \n AveragePooling2D)                                                                                \n                                                                                                  \n block6d_se_reshape (Reshap  (None, 1, 1, 1152)           0         ['block6d_se_squeeze[0][0]']  \n e)                                                                                               \n                                                                                                  \n block6d_se_reduce (Conv2D)  (None, 1, 1, 48)             55344     ['block6d_se_reshape[0][0]']  \n                                                                                                  \n block6d_se_expand (Conv2D)  (None, 1, 1, 1152)           56448     ['block6d_se_reduce[0][0]']   \n                                                                                                  \n block6d_se_excite (Multipl  (None, 8, 8, 1152)           0         ['block6d_activation[0][0]',  \n y)                                                                  'block6d_se_expand[0][0]']   \n                                                                                                  \n block6d_project_conv (Conv  (None, 8, 8, 192)            221184    ['block6d_se_excite[0][0]']   \n 2D)                                                                                              \n                                                                                                  \n block6d_project_bn (BatchN  (None, 8, 8, 192)            768       ['block6d_project_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n block6d_drop (Dropout)      (None, 8, 8, 192)            0         ['block6d_project_bn[0][0]']  \n                                                                                                  \n block6d_add (Add)           (None, 8, 8, 192)            0         ['block6d_drop[0][0]',        \n                                                                     'block6c_add[0][0]']         \n                                                                                                  \n block7a_expand_conv (Conv2  (None, 8, 8, 1152)           221184    ['block6d_add[0][0]']         \n D)                                                                                               \n                                                                                                  \n block7a_expand_bn (BatchNo  (None, 8, 8, 1152)           4608      ['block7a_expand_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n block7a_expand_activation   (None, 8, 8, 1152)           0         ['block7a_expand_bn[0][0]']   \n (Activation)                                                                                     \n                                                                                                  \n block7a_dwconv (DepthwiseC  (None, 8, 8, 1152)           10368     ['block7a_expand_activation[0]\n onv2D)                                                             [0]']                         \n                                                                                                  \n block7a_bn (BatchNormaliza  (None, 8, 8, 1152)           4608      ['block7a_dwconv[0][0]']      \n tion)                                                                                            \n                                                                                                  \n block7a_activation (Activa  (None, 8, 8, 1152)           0         ['block7a_bn[0][0]']          \n tion)                                                                                            \n                                                                                                  \n block7a_se_squeeze (Global  (None, 1152)                 0         ['block7a_activation[0][0]']  \n AveragePooling2D)                                                                                \n                                                                                                  \n block7a_se_reshape (Reshap  (None, 1, 1, 1152)           0         ['block7a_se_squeeze[0][0]']  \n e)                                                                                               \n                                                                                                  \n block7a_se_reduce (Conv2D)  (None, 1, 1, 48)             55344     ['block7a_se_reshape[0][0]']  \n                                                                                                  \n block7a_se_expand (Conv2D)  (None, 1, 1, 1152)           56448     ['block7a_se_reduce[0][0]']   \n                                                                                                  \n block7a_se_excite (Multipl  (None, 8, 8, 1152)           0         ['block7a_activation[0][0]',  \n y)                                                                  'block7a_se_expand[0][0]']   \n                                                                                                  \n block7a_project_conv (Conv  (None, 8, 8, 320)            368640    ['block7a_se_excite[0][0]']   \n 2D)                                                                                              \n                                                                                                  \n block7a_project_bn (BatchN  (None, 8, 8, 320)            1280      ['block7a_project_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n top_conv (Conv2D)           (None, 8, 8, 1280)           409600    ['block7a_project_bn[0][0]']  \n                                                                                                  \n top_bn (BatchNormalization  (None, 8, 8, 1280)           5120      ['top_conv[0][0]']            \n )                                                                                                \n                                                                                                  \n top_activation (Activation  (None, 8, 8, 1280)           0         ['top_bn[0][0]']              \n )                                                                                                \n                                                                                                  \n global_average_pooling2d_9  (None, 1280)                 0         ['top_activation[0][0]']      \n  (GlobalAveragePooling2D)                                                                        \n                                                                                                  \n dropout_9 (Dropout)         (None, 1280)                 0         ['global_average_pooling2d_9[0\n                                                                    ][0]']                        \n                                                                                                  \n dense_9 (Dense)             (None, 38)                   48678     ['dropout_9[0][0]']           \n                                                                                                  \n==================================================================================================\nTotal params: 4098249 (15.63 MB)\nTrainable params: 4056226 (15.47 MB)\nNon-trainable params: 42023 (164.16 KB)\n__________________________________________________________________________________________________\nTrain data classes: 38\n","output_type":"stream"}],"execution_count":46},{"cell_type":"markdown","source":"## 3. Train the Model","metadata":{}},{"cell_type":"code","source":"# Callbacks\nearly_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\ncheckpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True)\n\nclass BatchValidationCallback(tf.keras.callbacks.Callback):\n    def on_train_batch_end(self, batch, logs=None):\n        print(f\" Step {batch + 1}: Train Accuracy = {logs['accuracy']:.4f}\")\n    \n    def on_test_batch_end(self, batch, logs=None):\n        print(f\" Validation Step {batch + 1}: Validation Accuracy = {logs['accuracy']:.4f}\")\n\n\nlog_batch_metrics = BatchValidationCallback()\n\n# Train the model\ntry:\n    history = model.fit_generator(\n        train_data,\n        validation_data=val_data,\n        epochs=5,\n        callbacks=[early_stopping, checkpoint, log_batch_metrics],\n        verbose=1\n    )\nexcept Exception as e:\n    print(f\"Error during training: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T13:29:46.533546Z","iopub.execute_input":"2024-12-07T13:29:46.533907Z","iopub.status.idle":"2024-12-07T13:41:20.052502Z","shell.execute_reply.started":"2024-12-07T13:29:46.533882Z","shell.execute_reply":"2024-12-07T13:41:20.051209Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_42/3423135365.py:17: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n  history = model.fit_generator(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/5\n Step 1: Train Accuracy = 0.7500\n   1/2197 [..............................] - ETA: 35:34 - loss: 0.6456 - accuracy: 0.7500 Step 2: Train Accuracy = 0.8125\n   2/2197 [..............................] - ETA: 18:55 - loss: 0.5657 - accuracy: 0.8125 Step 3: Train Accuracy = 0.8125\n   3/2197 [..............................] - ETA: 20:28 - loss: 0.5549 - accuracy: 0.8125 Step 4: Train Accuracy = 0.8281\n   4/2197 [..............................] - ETA: 21:13 - loss: 0.5893 - accuracy: 0.8281 Step 5: Train Accuracy = 0.8500\n   5/2197 [..............................] - ETA: 20:21 - loss: 0.5229 - accuracy: 0.8500 Step 6: Train Accuracy = 0.8646\n   6/2197 [..............................] - ETA: 19:32 - loss: 0.4721 - accuracy: 0.8646 Step 7: Train Accuracy = 0.8750\n   7/2197 [..............................] - ETA: 20:24 - loss: 0.4565 - accuracy: 0.8750 Step 8: Train Accuracy = 0.8633\n   8/2197 [..............................] - ETA: 20:40 - loss: 0.4858 - accuracy: 0.8633 Step 9: Train Accuracy = 0.8646\n   9/2197 [..............................] - ETA: 21:17 - loss: 0.4849 - accuracy: 0.8646 Step 10: Train Accuracy = 0.8562\n  10/2197 [..............................] - ETA: 21:28 - loss: 0.4957 - accuracy: 0.8562 Step 11: Train Accuracy = 0.8466\n  11/2197 [..............................] - ETA: 20:52 - loss: 0.5148 - accuracy: 0.8466 Step 12: Train Accuracy = 0.8516\n  12/2197 [..............................] - ETA: 21:03 - loss: 0.4979 - accuracy: 0.8516 Step 13: Train Accuracy = 0.8413\n  13/2197 [..............................] - ETA: 21:09 - loss: 0.5274 - accuracy: 0.8413 Step 14: Train Accuracy = 0.8393\n  14/2197 [..............................] - ETA: 21:21 - loss: 0.5495 - accuracy: 0.8393 Step 15: Train Accuracy = 0.8458\n  15/2197 [..............................] - ETA: 21:34 - loss: 0.5310 - accuracy: 0.8458 Step 16: Train Accuracy = 0.8496\n  16/2197 [..............................] - ETA: 21:39 - loss: 0.5196 - accuracy: 0.8496 Step 17: Train Accuracy = 0.8548\n  17/2197 [..............................] - ETA: 21:17 - loss: 0.5041 - accuracy: 0.8548 Step 18: Train Accuracy = 0.8559\n  18/2197 [..............................] - ETA: 21:26 - loss: 0.4999 - accuracy: 0.8559 Step 19: Train Accuracy = 0.8586\n  19/2197 [..............................] - ETA: 21:16 - loss: 0.4938 - accuracy: 0.8586 Step 20: Train Accuracy = 0.8578\n  20/2197 [..............................] - ETA: 21:00 - loss: 0.4911 - accuracy: 0.8578 Step 21: Train Accuracy = 0.8586\n  21/2197 [..............................] - ETA: 21:02 - loss: 0.4917 - accuracy: 0.8586 Step 22: Train Accuracy = 0.8580\n  22/2197 [..............................] - ETA: 21:09 - loss: 0.4998 - accuracy: 0.8580 Step 23: Train Accuracy = 0.8573\n  23/2197 [..............................] - ETA: 21:12 - loss: 0.4943 - accuracy: 0.8573 Step 24: Train Accuracy = 0.8568\n  24/2197 [..............................] - ETA: 21:16 - loss: 0.4948 - accuracy: 0.8568 Step 25: Train Accuracy = 0.8575\n  25/2197 [..............................] - ETA: 21:20 - loss: 0.4953 - accuracy: 0.8575 Step 26: Train Accuracy = 0.8546\n  26/2197 [..............................] - ETA: 21:26 - loss: 0.5046 - accuracy: 0.8546 Step 27: Train Accuracy = 0.8542\n  27/2197 [..............................] - ETA: 21:14 - loss: 0.5043 - accuracy: 0.8542 Step 28: Train Accuracy = 0.8571\n  28/2197 [..............................] - ETA: 21:19 - loss: 0.5014 - accuracy: 0.8571 Step 29: Train Accuracy = 0.8556\n  29/2197 [..............................] - ETA: 21:24 - loss: 0.5039 - accuracy: 0.8556 Step 30: Train Accuracy = 0.8573\n  30/2197 [..............................] - ETA: 21:29 - loss: 0.4985 - accuracy: 0.8573 Step 31: Train Accuracy = 0.8569\n  31/2197 [..............................] - ETA: 21:33 - loss: 0.4949 - accuracy: 0.8569 Step 32: Train Accuracy = 0.8574\n  32/2197 [..............................] - ETA: 21:36 - loss: 0.4932 - accuracy: 0.8574 Step 33: Train Accuracy = 0.8580\n  33/2197 [..............................] - ETA: 21:25 - loss: 0.4882 - accuracy: 0.8580 Step 34: Train Accuracy = 0.8612\n  34/2197 [..............................] - ETA: 21:28 - loss: 0.4813 - accuracy: 0.8612 Step 35: Train Accuracy = 0.8607\n  35/2197 [..............................] - ETA: 21:39 - loss: 0.4792 - accuracy: 0.8607 Step 36: Train Accuracy = 0.8594\n  36/2197 [..............................] - ETA: 21:41 - loss: 0.4835 - accuracy: 0.8594 Step 37: Train Accuracy = 0.8598\n  37/2197 [..............................] - ETA: 21:44 - loss: 0.4824 - accuracy: 0.8598 Step 38: Train Accuracy = 0.8586\n  38/2197 [..............................] - ETA: 21:48 - loss: 0.4781 - accuracy: 0.8586 Step 39: Train Accuracy = 0.8590\n  39/2197 [..............................] - ETA: 21:51 - loss: 0.4752 - accuracy: 0.8590 Step 40: Train Accuracy = 0.8594\n  40/2197 [..............................] - ETA: 21:53 - loss: 0.4722 - accuracy: 0.8594 Step 41: Train Accuracy = 0.8598\n  41/2197 [..............................] - ETA: 21:54 - loss: 0.4704 - accuracy: 0.8598 Step 42: Train Accuracy = 0.8609\n  42/2197 [..............................] - ETA: 21:55 - loss: 0.4683 - accuracy: 0.8609 Step 43: Train Accuracy = 0.8590\n  43/2197 [..............................] - ETA: 21:56 - loss: 0.4690 - accuracy: 0.8590 Step 44: Train Accuracy = 0.8601\n  44/2197 [..............................] - ETA: 22:00 - loss: 0.4717 - accuracy: 0.8601 Step 45: Train Accuracy = 0.8611\n  45/2197 [..............................] - ETA: 22:03 - loss: 0.4680 - accuracy: 0.8611 Step 46: Train Accuracy = 0.8614\n  46/2197 [..............................] - ETA: 22:03 - loss: 0.4665 - accuracy: 0.8614 Step 47: Train Accuracy = 0.8637\n  47/2197 [..............................] - ETA: 22:04 - loss: 0.4615 - accuracy: 0.8637 Step 48: Train Accuracy = 0.8646\n  48/2197 [..............................] - ETA: 22:06 - loss: 0.4572 - accuracy: 0.8646 Step 49: Train Accuracy = 0.8642\n  49/2197 [..............................] - ETA: 22:09 - loss: 0.4612 - accuracy: 0.8642 Step 50: Train Accuracy = 0.8644\n  50/2197 [..............................] - ETA: 22:09 - loss: 0.4594 - accuracy: 0.8644 Step 51: Train Accuracy = 0.8646\n  51/2197 [..............................] - ETA: 22:13 - loss: 0.4585 - accuracy: 0.8646 Step 52: Train Accuracy = 0.8642\n  52/2197 [..............................] - ETA: 22:18 - loss: 0.4585 - accuracy: 0.8642 Step 53: Train Accuracy = 0.8644\n  53/2197 [..............................] - ETA: 22:18 - loss: 0.4600 - accuracy: 0.8644 Step 54: Train Accuracy = 0.8646\n  54/2197 [..............................] - ETA: 22:10 - loss: 0.4600 - accuracy: 0.8646 Step 55: Train Accuracy = 0.8642\n  55/2197 [..............................] - ETA: 22:04 - loss: 0.4634 - accuracy: 0.8642 Step 56: Train Accuracy = 0.8661\n  56/2197 [..............................] - ETA: 22:07 - loss: 0.4586 - accuracy: 0.8661 Step 57: Train Accuracy = 0.8657\n  57/2197 [..............................] - ETA: 22:06 - loss: 0.4564 - accuracy: 0.8657 Step 58: Train Accuracy = 0.8653\n  58/2197 [..............................] - ETA: 22:07 - loss: 0.4596 - accuracy: 0.8653 Step 59: Train Accuracy = 0.8655\n  59/2197 [..............................] - ETA: 22:08 - loss: 0.4570 - accuracy: 0.8655 Step 60: Train Accuracy = 0.8672\n  60/2197 [..............................] - ETA: 22:02 - loss: 0.4521 - accuracy: 0.8672 Step 61: Train Accuracy = 0.8673\n  61/2197 [..............................] - ETA: 22:02 - loss: 0.4502 - accuracy: 0.8673 Step 62: Train Accuracy = 0.8679\n  62/2197 [..............................] - ETA: 22:03 - loss: 0.4490 - accuracy: 0.8679 Step 63: Train Accuracy = 0.8690\n  63/2197 [..............................] - ETA: 22:04 - loss: 0.4469 - accuracy: 0.8690 Step 64: Train Accuracy = 0.8691\n  64/2197 [..............................] - ETA: 22:04 - loss: 0.4450 - accuracy: 0.8691 Step 65: Train Accuracy = 0.8697\n  65/2197 [..............................] - ETA: 22:03 - loss: 0.4425 - accuracy: 0.8697 Step 66: Train Accuracy = 0.8688\n  66/2197 [..............................] - ETA: 22:05 - loss: 0.4452 - accuracy: 0.8688 Step 67: Train Accuracy = 0.8671\n  67/2197 [..............................] - ETA: 22:06 - loss: 0.4492 - accuracy: 0.8671 Step 68: Train Accuracy = 0.8663\n  68/2197 [..............................] - ETA: 22:05 - loss: 0.4492 - accuracy: 0.8663 Step 69: Train Accuracy = 0.8668\n  69/2197 [..............................] - ETA: 21:59 - loss: 0.4484 - accuracy: 0.8668 Step 70: Train Accuracy = 0.8679\n  70/2197 [..............................] - ETA: 21:58 - loss: 0.4456 - accuracy: 0.8679 Step 71: Train Accuracy = 0.8680\n  71/2197 [..............................] - ETA: 21:58 - loss: 0.4445 - accuracy: 0.8680 Step 72: Train Accuracy = 0.8685\n  72/2197 [..............................] - ETA: 21:53 - loss: 0.4422 - accuracy: 0.8685 Step 73: Train Accuracy = 0.8703\n  73/2197 [..............................] - ETA: 21:53 - loss: 0.4373 - accuracy: 0.8703 Step 74: Train Accuracy = 0.8704\n  74/2197 [>.............................] - ETA: 21:53 - loss: 0.4369 - accuracy: 0.8704 Step 75: Train Accuracy = 0.8712\n  75/2197 [>.............................] - ETA: 21:47 - loss: 0.4344 - accuracy: 0.8712 Step 76: Train Accuracy = 0.8705\n  76/2197 [>.............................] - ETA: 21:47 - loss: 0.4343 - accuracy: 0.8705 Step 77: Train Accuracy = 0.8713\n  77/2197 [>.............................] - ETA: 21:47 - loss: 0.4311 - accuracy: 0.8713 Step 78: Train Accuracy = 0.8718\n  78/2197 [>.............................] - ETA: 21:46 - loss: 0.4300 - accuracy: 0.8718 Step 79: Train Accuracy = 0.8722\n  79/2197 [>.............................] - ETA: 21:42 - loss: 0.4286 - accuracy: 0.8722 Step 80: Train Accuracy = 0.8719\n  80/2197 [>.............................] - ETA: 21:41 - loss: 0.4277 - accuracy: 0.8719 Step 81: Train Accuracy = 0.8731\n  81/2197 [>.............................] - ETA: 21:41 - loss: 0.4241 - accuracy: 0.8731 Step 82: Train Accuracy = 0.8731\n  82/2197 [>.............................] - ETA: 21:41 - loss: 0.4249 - accuracy: 0.8731 Step 83: Train Accuracy = 0.8739\n  83/2197 [>.............................] - ETA: 21:42 - loss: 0.4224 - accuracy: 0.8739 Step 84: Train Accuracy = 0.8739\n  84/2197 [>.............................] - ETA: 21:42 - loss: 0.4231 - accuracy: 0.8739 Step 85: Train Accuracy = 0.8732\n  85/2197 [>.............................] - ETA: 21:42 - loss: 0.4236 - accuracy: 0.8732 Step 86: Train Accuracy = 0.8732\n  86/2197 [>.............................] - ETA: 21:41 - loss: 0.4240 - accuracy: 0.8732 Step 87: Train Accuracy = 0.8732\n  87/2197 [>.............................] - ETA: 21:41 - loss: 0.4232 - accuracy: 0.8732 Step 88: Train Accuracy = 0.8729\n  88/2197 [>.............................] - ETA: 21:43 - loss: 0.4235 - accuracy: 0.8729 Step 89: Train Accuracy = 0.8729\n  89/2197 [>.............................] - ETA: 21:43 - loss: 0.4248 - accuracy: 0.8729 Step 90: Train Accuracy = 0.8726\n  90/2197 [>.............................] - ETA: 21:43 - loss: 0.4254 - accuracy: 0.8726 Step 91: Train Accuracy = 0.8729\n  91/2197 [>.............................] - ETA: 21:38 - loss: 0.4243 - accuracy: 0.8729 Step 92: Train Accuracy = 0.8733\n  92/2197 [>.............................] - ETA: 21:38 - loss: 0.4241 - accuracy: 0.8733 Step 93: Train Accuracy = 0.8740\n  93/2197 [>.............................] - ETA: 21:33 - loss: 0.4222 - accuracy: 0.8740 Step 94: Train Accuracy = 0.8753\n  94/2197 [>.............................] - ETA: 21:33 - loss: 0.4188 - accuracy: 0.8753 Step 95: Train Accuracy = 0.8760\n  95/2197 [>.............................] - ETA: 21:29 - loss: 0.4173 - accuracy: 0.8760 Step 96: Train Accuracy = 0.8753\n  96/2197 [>.............................] - ETA: 21:29 - loss: 0.4202 - accuracy: 0.8753 Step 97: Train Accuracy = 0.8756\n  97/2197 [>.............................] - ETA: 21:25 - loss: 0.4183 - accuracy: 0.8756 Step 98: Train Accuracy = 0.8750\n  98/2197 [>.............................] - ETA: 21:26 - loss: 0.4184 - accuracy: 0.8750 Step 99: Train Accuracy = 0.8750\n  99/2197 [>.............................] - ETA: 21:27 - loss: 0.4172 - accuracy: 0.8750 Step 100: Train Accuracy = 0.8750\n 100/2197 [>.............................] - ETA: 21:28 - loss: 0.4178 - accuracy: 0.8750 Step 101: Train Accuracy = 0.8747\n 101/2197 [>.............................] - ETA: 21:28 - loss: 0.4168 - accuracy: 0.8747 Step 102: Train Accuracy = 0.8753\n 102/2197 [>.............................] - ETA: 21:28 - loss: 0.4150 - accuracy: 0.8753 Step 103: Train Accuracy = 0.8753\n 103/2197 [>.............................] - ETA: 21:30 - loss: 0.4138 - accuracy: 0.8753 Step 104: Train Accuracy = 0.8759\n 104/2197 [>.............................] - ETA: 21:30 - loss: 0.4127 - accuracy: 0.8759 Step 105: Train Accuracy = 0.8759\n 105/2197 [>.............................] - ETA: 21:30 - loss: 0.4139 - accuracy: 0.8759 Step 106: Train Accuracy = 0.8753\n 106/2197 [>.............................] - ETA: 21:30 - loss: 0.4179 - accuracy: 0.8753 Step 107: Train Accuracy = 0.8759\n 107/2197 [>.............................] - ETA: 21:26 - loss: 0.4171 - accuracy: 0.8759 Step 108: Train Accuracy = 0.8762\n 108/2197 [>.............................] - ETA: 21:22 - loss: 0.4168 - accuracy: 0.8762 Step 109: Train Accuracy = 0.8761\n 109/2197 [>.............................] - ETA: 21:22 - loss: 0.4187 - accuracy: 0.8761 Step 110: Train Accuracy = 0.8759\n 110/2197 [>.............................] - ETA: 21:21 - loss: 0.4195 - accuracy: 0.8759 Step 111: Train Accuracy = 0.8758\n 111/2197 [>.............................] - ETA: 21:21 - loss: 0.4182 - accuracy: 0.8758 Step 112: Train Accuracy = 0.8747\n 112/2197 [>.............................] - ETA: 21:20 - loss: 0.4211 - accuracy: 0.8747 Step 113: Train Accuracy = 0.8747\n 113/2197 [>.............................] - ETA: 21:17 - loss: 0.4221 - accuracy: 0.8747 Step 114: Train Accuracy = 0.8739\n 114/2197 [>.............................] - ETA: 21:16 - loss: 0.4250 - accuracy: 0.8739 Step 115: Train Accuracy = 0.8739\n 115/2197 [>.............................] - ETA: 21:16 - loss: 0.4248 - accuracy: 0.8739 Step 116: Train Accuracy = 0.8739\n 116/2197 [>.............................] - ETA: 21:17 - loss: 0.4239 - accuracy: 0.8739 Step 117: Train Accuracy = 0.8745\n 117/2197 [>.............................] - ETA: 21:18 - loss: 0.4236 - accuracy: 0.8745 Step 118: Train Accuracy = 0.8753\n 118/2197 [>.............................] - ETA: 21:14 - loss: 0.4226 - accuracy: 0.8753 Step 119: Train Accuracy = 0.8755\n 119/2197 [>.............................] - ETA: 21:11 - loss: 0.4217 - accuracy: 0.8755 Step 120: Train Accuracy = 0.8755\n 120/2197 [>.............................] - ETA: 21:07 - loss: 0.4220 - accuracy: 0.8755 Step 121: Train Accuracy = 0.8753\n 121/2197 [>.............................] - ETA: 21:07 - loss: 0.4229 - accuracy: 0.8753 Step 122: Train Accuracy = 0.8758\n 122/2197 [>.............................] - ETA: 21:07 - loss: 0.4216 - accuracy: 0.8758 Step 123: Train Accuracy = 0.8758\n 123/2197 [>.............................] - ETA: 21:04 - loss: 0.4214 - accuracy: 0.8758 Step 124: Train Accuracy = 0.8763\n 124/2197 [>.............................] - ETA: 21:04 - loss: 0.4194 - accuracy: 0.8763 Step 125: Train Accuracy = 0.8763\n 125/2197 [>.............................] - ETA: 21:06 - loss: 0.4186 - accuracy: 0.8763 Step 126: Train Accuracy = 0.8767\n 126/2197 [>.............................] - ETA: 21:06 - loss: 0.4171 - accuracy: 0.8767 Step 127: Train Accuracy = 0.8767\n 127/2197 [>.............................] - ETA: 21:06 - loss: 0.4168 - accuracy: 0.8767 Step 128: Train Accuracy = 0.8767\n 128/2197 [>.............................] - ETA: 21:07 - loss: 0.4165 - accuracy: 0.8767 Step 129: Train Accuracy = 0.8777\n 129/2197 [>.............................] - ETA: 21:06 - loss: 0.4140 - accuracy: 0.8777 Step 130: Train Accuracy = 0.8772\n 130/2197 [>.............................] - ETA: 21:06 - loss: 0.4139 - accuracy: 0.8772 Step 131: Train Accuracy = 0.8771\n 131/2197 [>.............................] - ETA: 21:03 - loss: 0.4138 - accuracy: 0.8771 Step 132: Train Accuracy = 0.8776\n 132/2197 [>.............................] - ETA: 21:03 - loss: 0.4127 - accuracy: 0.8776 Step 133: Train Accuracy = 0.8778\n 133/2197 [>.............................] - ETA: 21:04 - loss: 0.4115 - accuracy: 0.8778 Step 134: Train Accuracy = 0.8785\n 134/2197 [>.............................] - ETA: 21:01 - loss: 0.4091 - accuracy: 0.8785 Step 135: Train Accuracy = 0.8787\n 135/2197 [>.............................] - ETA: 21:01 - loss: 0.4082 - accuracy: 0.8787 Step 136: Train Accuracy = 0.8794\n 136/2197 [>.............................] - ETA: 21:01 - loss: 0.4068 - accuracy: 0.8794 Step 137: Train Accuracy = 0.8798\n 137/2197 [>.............................] - ETA: 21:01 - loss: 0.4052 - accuracy: 0.8798 Step 138: Train Accuracy = 0.8800\n 138/2197 [>.............................] - ETA: 21:01 - loss: 0.4042 - accuracy: 0.8800 Step 139: Train Accuracy = 0.8797\n 139/2197 [>.............................] - ETA: 21:01 - loss: 0.4049 - accuracy: 0.8797 Step 140: Train Accuracy = 0.8795\n 140/2197 [>.............................] - ETA: 20:58 - loss: 0.4049 - accuracy: 0.8795 Step 141: Train Accuracy = 0.8801\n 141/2197 [>.............................] - ETA: 20:58 - loss: 0.4031 - accuracy: 0.8801 Step 142: Train Accuracy = 0.8805\n 142/2197 [>.............................] - ETA: 20:55 - loss: 0.4023 - accuracy: 0.8805 Step 143: Train Accuracy = 0.8811\n 143/2197 [>.............................] - ETA: 20:55 - loss: 0.3999 - accuracy: 0.8811 Step 144: Train Accuracy = 0.8815\n 144/2197 [>.............................] - ETA: 20:55 - loss: 0.3984 - accuracy: 0.8815 Step 145: Train Accuracy = 0.8819\n 145/2197 [>.............................] - ETA: 20:55 - loss: 0.3972 - accuracy: 0.8819 Step 146: Train Accuracy = 0.8816\n 146/2197 [>.............................] - ETA: 20:53 - loss: 0.3971 - accuracy: 0.8816 Step 147: Train Accuracy = 0.8820\n 147/2197 [=>............................] - ETA: 20:53 - loss: 0.3959 - accuracy: 0.8820 Step 148: Train Accuracy = 0.8822\n 148/2197 [=>............................] - ETA: 20:53 - loss: 0.3965 - accuracy: 0.8822 Step 149: Train Accuracy = 0.8828\n 149/2197 [=>............................] - ETA: 20:54 - loss: 0.3953 - accuracy: 0.8828 Step 150: Train Accuracy = 0.8825\n 150/2197 [=>............................] - ETA: 20:54 - loss: 0.3957 - accuracy: 0.8825 Step 151: Train Accuracy = 0.8825\n 151/2197 [=>............................] - ETA: 20:54 - loss: 0.3947 - accuracy: 0.8825 Step 152: Train Accuracy = 0.8830\n 152/2197 [=>............................] - ETA: 20:54 - loss: 0.3932 - accuracy: 0.8830 Step 153: Train Accuracy = 0.8832\n 153/2197 [=>............................] - ETA: 20:54 - loss: 0.3923 - accuracy: 0.8832 Step 154: Train Accuracy = 0.8837\n 154/2197 [=>............................] - ETA: 20:54 - loss: 0.3910 - accuracy: 0.8837 Step 155: Train Accuracy = 0.8839\n 155/2197 [=>............................] - ETA: 20:52 - loss: 0.3905 - accuracy: 0.8839 Step 156: Train Accuracy = 0.8836\n 156/2197 [=>............................] - ETA: 20:51 - loss: 0.3908 - accuracy: 0.8836 Step 157: Train Accuracy = 0.8836\n 157/2197 [=>............................] - ETA: 20:49 - loss: 0.3908 - accuracy: 0.8836 Step 158: Train Accuracy = 0.8833\n 158/2197 [=>............................] - ETA: 20:49 - loss: 0.3910 - accuracy: 0.8833 Step 159: Train Accuracy = 0.8829\n 159/2197 [=>............................] - ETA: 20:49 - loss: 0.3935 - accuracy: 0.8829 Step 160: Train Accuracy = 0.8822\n 160/2197 [=>............................] - ETA: 20:48 - loss: 0.3944 - accuracy: 0.8822 Step 161: Train Accuracy = 0.8824\n 161/2197 [=>............................] - ETA: 20:48 - loss: 0.3934 - accuracy: 0.8824 Step 162: Train Accuracy = 0.8823\n 162/2197 [=>............................] - ETA: 20:46 - loss: 0.3922 - accuracy: 0.8823 Step 163: Train Accuracy = 0.8823\n 163/2197 [=>............................] - ETA: 20:45 - loss: 0.3924 - accuracy: 0.8823 Step 164: Train Accuracy = 0.8830\n 164/2197 [=>............................] - ETA: 20:43 - loss: 0.3903 - accuracy: 0.8830 Step 165: Train Accuracy = 0.8830\n 165/2197 [=>............................] - ETA: 20:43 - loss: 0.3911 - accuracy: 0.8830 Step 166: Train Accuracy = 0.8831\n 166/2197 [=>............................] - ETA: 20:43 - loss: 0.3900 - accuracy: 0.8831 Step 167: Train Accuracy = 0.8830\n 167/2197 [=>............................] - ETA: 20:41 - loss: 0.3896 - accuracy: 0.8830 Step 168: Train Accuracy = 0.8836\n 168/2197 [=>............................] - ETA: 20:38 - loss: 0.3885 - accuracy: 0.8836 Step 169: Train Accuracy = 0.8839\n 169/2197 [=>............................] - ETA: 20:38 - loss: 0.3872 - accuracy: 0.8839 Step 170: Train Accuracy = 0.8840\n 170/2197 [=>............................] - ETA: 20:38 - loss: 0.3870 - accuracy: 0.8840 Step 171: Train Accuracy = 0.8840\n 171/2197 [=>............................] - ETA: 20:38 - loss: 0.3862 - accuracy: 0.8840 Step 172: Train Accuracy = 0.8835\n 172/2197 [=>............................] - ETA: 20:37 - loss: 0.3870 - accuracy: 0.8835 Step 173: Train Accuracy = 0.8833\n 173/2197 [=>............................] - ETA: 20:35 - loss: 0.3870 - accuracy: 0.8833 Step 174: Train Accuracy = 0.8836\n 174/2197 [=>............................] - ETA: 20:32 - loss: 0.3855 - accuracy: 0.8836 Step 175: Train Accuracy = 0.8836\n 175/2197 [=>............................] - ETA: 20:32 - loss: 0.3866 - accuracy: 0.8836 Step 176: Train Accuracy = 0.8835\n 176/2197 [=>............................] - ETA: 20:31 - loss: 0.3862 - accuracy: 0.8835 Step 177: Train Accuracy = 0.8833\n 177/2197 [=>............................] - ETA: 20:31 - loss: 0.3869 - accuracy: 0.8833 Step 178: Train Accuracy = 0.8834\n 178/2197 [=>............................] - ETA: 20:30 - loss: 0.3874 - accuracy: 0.8834 Step 179: Train Accuracy = 0.8834\n 179/2197 [=>............................] - ETA: 20:30 - loss: 0.3871 - accuracy: 0.8834 Step 180: Train Accuracy = 0.8840\n 180/2197 [=>............................] - ETA: 20:29 - loss: 0.3856 - accuracy: 0.8840 Step 181: Train Accuracy = 0.8845\n 181/2197 [=>............................] - ETA: 20:28 - loss: 0.3843 - accuracy: 0.8845 Step 182: Train Accuracy = 0.8848\n 182/2197 [=>............................] - ETA: 20:29 - loss: 0.3832 - accuracy: 0.8848 Step 183: Train Accuracy = 0.8851\n 183/2197 [=>............................] - ETA: 20:28 - loss: 0.3824 - accuracy: 0.8851 Step 184: Train Accuracy = 0.8854\n 184/2197 [=>............................] - ETA: 20:26 - loss: 0.3816 - accuracy: 0.8854 Step 185: Train Accuracy = 0.8853\n 185/2197 [=>............................] - ETA: 20:26 - loss: 0.3813 - accuracy: 0.8853 Step 186: Train Accuracy = 0.8854\n 186/2197 [=>............................] - ETA: 20:23 - loss: 0.3800 - accuracy: 0.8854 Step 187: Train Accuracy = 0.8859\n 187/2197 [=>............................] - ETA: 20:23 - loss: 0.3785 - accuracy: 0.8859 Step 188: Train Accuracy = 0.8853\n 188/2197 [=>............................] - ETA: 20:23 - loss: 0.3800 - accuracy: 0.8853 Step 189: Train Accuracy = 0.8848\n 189/2197 [=>............................] - ETA: 20:21 - loss: 0.3813 - accuracy: 0.8848 Step 190: Train Accuracy = 0.8849\n 190/2197 [=>............................] - ETA: 20:20 - loss: 0.3810 - accuracy: 0.8849 Step 191: Train Accuracy = 0.8850\n 191/2197 [=>............................] - ETA: 20:20 - loss: 0.3808 - accuracy: 0.8850 Step 192: Train Accuracy = 0.8854\n 192/2197 [=>............................] - ETA: 20:20 - loss: 0.3797 - accuracy: 0.8854 Step 193: Train Accuracy = 0.8852\n 193/2197 [=>............................] - ETA: 20:20 - loss: 0.3813 - accuracy: 0.8852 Step 194: Train Accuracy = 0.8856\n 194/2197 [=>............................] - ETA: 20:19 - loss: 0.3798 - accuracy: 0.8856 Step 195: Train Accuracy = 0.8861\n 195/2197 [=>............................] - ETA: 20:17 - loss: 0.3785 - accuracy: 0.8861 Step 196: Train Accuracy = 0.8860\n 196/2197 [=>............................] - ETA: 20:17 - loss: 0.3778 - accuracy: 0.8860 Step 197: Train Accuracy = 0.8861\n 197/2197 [=>............................] - ETA: 20:17 - loss: 0.3777 - accuracy: 0.8861 Step 198: Train Accuracy = 0.8860\n 198/2197 [=>............................] - ETA: 20:16 - loss: 0.3771 - accuracy: 0.8860 Step 199: Train Accuracy = 0.8865\n 199/2197 [=>............................] - ETA: 20:16 - loss: 0.3758 - accuracy: 0.8865 Step 200: Train Accuracy = 0.8869\n 200/2197 [=>............................] - ETA: 20:16 - loss: 0.3744 - accuracy: 0.8869 Step 201: Train Accuracy = 0.8870\n 201/2197 [=>............................] - ETA: 20:15 - loss: 0.3745 - accuracy: 0.8870 Step 202: Train Accuracy = 0.8869\n 202/2197 [=>............................] - ETA: 20:15 - loss: 0.3741 - accuracy: 0.8869 Step 203: Train Accuracy = 0.8872\n 203/2197 [=>............................] - ETA: 20:15 - loss: 0.3734 - accuracy: 0.8872 Step 204: Train Accuracy = 0.8868\n 204/2197 [=>............................] - ETA: 20:13 - loss: 0.3740 - accuracy: 0.8868 Step 205: Train Accuracy = 0.8870\n 205/2197 [=>............................] - ETA: 20:11 - loss: 0.3738 - accuracy: 0.8870 Step 206: Train Accuracy = 0.8874\n 206/2197 [=>............................] - ETA: 20:11 - loss: 0.3729 - accuracy: 0.8874 Step 207: Train Accuracy = 0.8878\n 207/2197 [=>............................] - ETA: 20:10 - loss: 0.3715 - accuracy: 0.8878 Step 208: Train Accuracy = 0.8881\n 208/2197 [=>............................] - ETA: 20:10 - loss: 0.3714 - accuracy: 0.8881 Step 209: Train Accuracy = 0.8882\n 209/2197 [=>............................] - ETA: 20:09 - loss: 0.3713 - accuracy: 0.8882 Step 210: Train Accuracy = 0.8885\n 210/2197 [=>............................] - ETA: 20:09 - loss: 0.3702 - accuracy: 0.8885 Step 211: Train Accuracy = 0.8889\n 211/2197 [=>............................] - ETA: 20:08 - loss: 0.3691 - accuracy: 0.8889 Step 212: Train Accuracy = 0.8893\n 212/2197 [=>............................] - ETA: 20:07 - loss: 0.3683 - accuracy: 0.8893 Step 213: Train Accuracy = 0.8892\n 213/2197 [=>............................] - ETA: 20:07 - loss: 0.3681 - accuracy: 0.8892 Step 214: Train Accuracy = 0.8896\n 214/2197 [=>............................] - ETA: 20:07 - loss: 0.3670 - accuracy: 0.8896 Step 215: Train Accuracy = 0.8897\n 215/2197 [=>............................] - ETA: 20:06 - loss: 0.3661 - accuracy: 0.8897 Step 216: Train Accuracy = 0.8896\n 216/2197 [=>............................] - ETA: 20:04 - loss: 0.3657 - accuracy: 0.8896 Step 217: Train Accuracy = 0.8900\n 217/2197 [=>............................] - ETA: 20:04 - loss: 0.3648 - accuracy: 0.8900 Step 218: Train Accuracy = 0.8899\n 218/2197 [=>............................] - ETA: 20:03 - loss: 0.3653 - accuracy: 0.8899 Step 219: Train Accuracy = 0.8898\n 219/2197 [=>............................] - ETA: 20:03 - loss: 0.3654 - accuracy: 0.8898 Step 220: Train Accuracy = 0.8901\n 220/2197 [==>...........................] - ETA: 20:03 - loss: 0.3646 - accuracy: 0.8901 Step 221: Train Accuracy = 0.8900\n 221/2197 [==>...........................] - ETA: 20:03 - loss: 0.3643 - accuracy: 0.8900 Step 222: Train Accuracy = 0.8903\n 222/2197 [==>...........................] - ETA: 20:02 - loss: 0.3636 - accuracy: 0.8903 Step 223: Train Accuracy = 0.8906\n 223/2197 [==>...........................] - ETA: 20:02 - loss: 0.3629 - accuracy: 0.8906 Step 224: Train Accuracy = 0.8905\n 224/2197 [==>...........................] - ETA: 20:02 - loss: 0.3638 - accuracy: 0.8905 Step 225: Train Accuracy = 0.8906\n 225/2197 [==>...........................] - ETA: 20:02 - loss: 0.3631 - accuracy: 0.8906 Step 226: Train Accuracy = 0.8905\n 226/2197 [==>...........................] - ETA: 20:02 - loss: 0.3625 - accuracy: 0.8905 Step 227: Train Accuracy = 0.8899\n 227/2197 [==>...........................] - ETA: 20:00 - loss: 0.3634 - accuracy: 0.8899 Step 228: Train Accuracy = 0.8902\n 228/2197 [==>...........................] - ETA: 19:58 - loss: 0.3625 - accuracy: 0.8902 Step 229: Train Accuracy = 0.8903\n 229/2197 [==>...........................] - ETA: 19:57 - loss: 0.3625 - accuracy: 0.8903 Step 230: Train Accuracy = 0.8902\n 230/2197 [==>...........................] - ETA: 19:57 - loss: 0.3626 - accuracy: 0.8902 Step 231: Train Accuracy = 0.8902\n 231/2197 [==>...........................] - ETA: 19:55 - loss: 0.3627 - accuracy: 0.8902 Step 232: Train Accuracy = 0.8906\n 232/2197 [==>...........................] - ETA: 19:55 - loss: 0.3616 - accuracy: 0.8906 Step 233: Train Accuracy = 0.8908\n 233/2197 [==>...........................] - ETA: 19:55 - loss: 0.3607 - accuracy: 0.8908 Step 234: Train Accuracy = 0.8912\n 234/2197 [==>...........................] - ETA: 19:55 - loss: 0.3600 - accuracy: 0.8912 Step 235: Train Accuracy = 0.8912\n 235/2197 [==>...........................] - ETA: 19:55 - loss: 0.3596 - accuracy: 0.8912 Step 236: Train Accuracy = 0.8913\n 236/2197 [==>...........................] - ETA: 19:53 - loss: 0.3596 - accuracy: 0.8913 Step 237: Train Accuracy = 0.8914\n 237/2197 [==>...........................] - ETA: 19:53 - loss: 0.3594 - accuracy: 0.8914 Step 238: Train Accuracy = 0.8915\n 238/2197 [==>...........................] - ETA: 19:53 - loss: 0.3588 - accuracy: 0.8915 Step 239: Train Accuracy = 0.8917\n 239/2197 [==>...........................] - ETA: 19:53 - loss: 0.3582 - accuracy: 0.8917 Step 240: Train Accuracy = 0.8918\n 240/2197 [==>...........................] - ETA: 19:53 - loss: 0.3578 - accuracy: 0.8918 Step 241: Train Accuracy = 0.8919\n 241/2197 [==>...........................] - ETA: 19:52 - loss: 0.3576 - accuracy: 0.8919 Step 242: Train Accuracy = 0.8922\n 242/2197 [==>...........................] - ETA: 19:52 - loss: 0.3565 - accuracy: 0.8922 Step 243: Train Accuracy = 0.8922\n 243/2197 [==>...........................] - ETA: 19:50 - loss: 0.3561 - accuracy: 0.8922 Step 244: Train Accuracy = 0.8925\n 244/2197 [==>...........................] - ETA: 19:50 - loss: 0.3550 - accuracy: 0.8925 Step 245: Train Accuracy = 0.8927\n 245/2197 [==>...........................] - ETA: 19:50 - loss: 0.3546 - accuracy: 0.8927 Step 246: Train Accuracy = 0.8928\n 246/2197 [==>...........................] - ETA: 19:50 - loss: 0.3546 - accuracy: 0.8928 Step 247: Train Accuracy = 0.8931\n 247/2197 [==>...........................] - ETA: 19:49 - loss: 0.3535 - accuracy: 0.8931 Step 248: Train Accuracy = 0.8930\n 248/2197 [==>...........................] - ETA: 19:49 - loss: 0.3537 - accuracy: 0.8930 Step 249: Train Accuracy = 0.8932\n 249/2197 [==>...........................] - ETA: 19:49 - loss: 0.3531 - accuracy: 0.8932 Step 250: Train Accuracy = 0.8934\n 250/2197 [==>...........................] - ETA: 19:47 - loss: 0.3525 - accuracy: 0.8934 Step 251: Train Accuracy = 0.8933\n 251/2197 [==>...........................] - ETA: 19:47 - loss: 0.3527 - accuracy: 0.8933 Step 252: Train Accuracy = 0.8932\n 252/2197 [==>...........................] - ETA: 19:45 - loss: 0.3531 - accuracy: 0.8932 Step 253: Train Accuracy = 0.8934\n 253/2197 [==>...........................] - ETA: 19:43 - loss: 0.3525 - accuracy: 0.8934 Step 254: Train Accuracy = 0.8931\n 254/2197 [==>...........................] - ETA: 19:43 - loss: 0.3533 - accuracy: 0.8931 Step 255: Train Accuracy = 0.8934\n 255/2197 [==>...........................] - ETA: 19:43 - loss: 0.3521 - accuracy: 0.8934 Step 256: Train Accuracy = 0.8936\n 256/2197 [==>...........................] - ETA: 19:43 - loss: 0.3513 - accuracy: 0.8936 Step 257: Train Accuracy = 0.8937\n 257/2197 [==>...........................] - ETA: 19:42 - loss: 0.3503 - accuracy: 0.8937 Step 258: Train Accuracy = 0.8940\n 258/2197 [==>...........................] - ETA: 19:42 - loss: 0.3498 - accuracy: 0.8940 Step 259: Train Accuracy = 0.8944\n 259/2197 [==>...........................] - ETA: 19:40 - loss: 0.3486 - accuracy: 0.8944 Step 260: Train Accuracy = 0.8945\n 260/2197 [==>...........................] - ETA: 19:40 - loss: 0.3485 - accuracy: 0.8945 Step 261: Train Accuracy = 0.8948\n 261/2197 [==>...........................] - ETA: 19:39 - loss: 0.3477 - accuracy: 0.8948 Step 262: Train Accuracy = 0.8950\n 262/2197 [==>...........................] - ETA: 19:39 - loss: 0.3470 - accuracy: 0.8950 Step 263: Train Accuracy = 0.8948\n 263/2197 [==>...........................] - ETA: 19:39 - loss: 0.3474 - accuracy: 0.8948 Step 264: Train Accuracy = 0.8950\n 264/2197 [==>...........................] - ETA: 19:38 - loss: 0.3469 - accuracy: 0.8950 Step 265: Train Accuracy = 0.8949\n 265/2197 [==>...........................] - ETA: 19:38 - loss: 0.3464 - accuracy: 0.8949 Step 266: Train Accuracy = 0.8951\n 266/2197 [==>...........................] - ETA: 19:38 - loss: 0.3460 - accuracy: 0.8951 Step 267: Train Accuracy = 0.8955\n 267/2197 [==>...........................] - ETA: 19:38 - loss: 0.3451 - accuracy: 0.8955 Step 268: Train Accuracy = 0.8959\n 268/2197 [==>...........................] - ETA: 19:37 - loss: 0.3440 - accuracy: 0.8959 Step 269: Train Accuracy = 0.8954\n 269/2197 [==>...........................] - ETA: 19:37 - loss: 0.3446 - accuracy: 0.8954 Step 270: Train Accuracy = 0.8957\n 270/2197 [==>...........................] - ETA: 19:35 - loss: 0.3440 - accuracy: 0.8957 Step 271: Train Accuracy = 0.8956\n 271/2197 [==>...........................] - ETA: 19:35 - loss: 0.3442 - accuracy: 0.8956 Step 272: Train Accuracy = 0.8957\n 272/2197 [==>...........................] - ETA: 19:35 - loss: 0.3448 - accuracy: 0.8957 Step 273: Train Accuracy = 0.8956\n 273/2197 [==>...........................] - ETA: 19:34 - loss: 0.3449 - accuracy: 0.8956 Step 274: Train Accuracy = 0.8955\n 274/2197 [==>...........................] - ETA: 19:34 - loss: 0.3450 - accuracy: 0.8955 Step 275: Train Accuracy = 0.8957\n 275/2197 [==>...........................] - ETA: 19:33 - loss: 0.3449 - accuracy: 0.8957 Step 276: Train Accuracy = 0.8958\n 276/2197 [==>...........................] - ETA: 19:32 - loss: 0.3444 - accuracy: 0.8958 Step 277: Train Accuracy = 0.8960\n 277/2197 [==>...........................] - ETA: 19:31 - loss: 0.3444 - accuracy: 0.8960 Step 278: Train Accuracy = 0.8962\n 278/2197 [==>...........................] - ETA: 19:29 - loss: 0.3435 - accuracy: 0.8962 Step 279: Train Accuracy = 0.8964\n 279/2197 [==>...........................] - ETA: 19:29 - loss: 0.3430 - accuracy: 0.8964 Step 280: Train Accuracy = 0.8961\n 280/2197 [==>...........................] - ETA: 19:29 - loss: 0.3437 - accuracy: 0.8961 Step 281: Train Accuracy = 0.8960\n 281/2197 [==>...........................] - ETA: 19:29 - loss: 0.3438 - accuracy: 0.8960 Step 282: Train Accuracy = 0.8962\n 282/2197 [==>...........................] - ETA: 19:28 - loss: 0.3441 - accuracy: 0.8962 Step 283: Train Accuracy = 0.8961\n 283/2197 [==>...........................] - ETA: 19:28 - loss: 0.3441 - accuracy: 0.8961 Step 284: Train Accuracy = 0.8962\n 284/2197 [==>...........................] - ETA: 19:28 - loss: 0.3436 - accuracy: 0.8962 Step 285: Train Accuracy = 0.8964\n 285/2197 [==>...........................] - ETA: 19:27 - loss: 0.3429 - accuracy: 0.8964 Step 286: Train Accuracy = 0.8961\n 286/2197 [==>...........................] - ETA: 19:27 - loss: 0.3441 - accuracy: 0.8961 Step 287: Train Accuracy = 0.8958\n 287/2197 [==>...........................] - ETA: 19:26 - loss: 0.3443 - accuracy: 0.8958 Step 288: Train Accuracy = 0.8959\n 288/2197 [==>...........................] - ETA: 19:26 - loss: 0.3437 - accuracy: 0.8959 Step 289: Train Accuracy = 0.8960\n 289/2197 [==>...........................] - ETA: 19:26 - loss: 0.3440 - accuracy: 0.8960 Step 290: Train Accuracy = 0.8962\n 290/2197 [==>...........................] - ETA: 19:26 - loss: 0.3432 - accuracy: 0.8962 Step 291: Train Accuracy = 0.8966\n 291/2197 [==>...........................] - ETA: 19:25 - loss: 0.3422 - accuracy: 0.8966 Step 292: Train Accuracy = 0.8967\n 292/2197 [==>...........................] - ETA: 19:25 - loss: 0.3419 - accuracy: 0.8967 Step 293: Train Accuracy = 0.8971\n 293/2197 [===>..........................] - ETA: 19:24 - loss: 0.3410 - accuracy: 0.8971 Step 294: Train Accuracy = 0.8971\n 294/2197 [===>..........................] - ETA: 19:24 - loss: 0.3404 - accuracy: 0.8971 Step 295: Train Accuracy = 0.8972\n 295/2197 [===>..........................] - ETA: 19:24 - loss: 0.3400 - accuracy: 0.8972 Step 296: Train Accuracy = 0.8970\n 296/2197 [===>..........................] - ETA: 19:24 - loss: 0.3411 - accuracy: 0.8970 Step 297: Train Accuracy = 0.8972\n 297/2197 [===>..........................] - ETA: 19:22 - loss: 0.3407 - accuracy: 0.8972 Step 298: Train Accuracy = 0.8971\n 298/2197 [===>..........................] - ETA: 19:22 - loss: 0.3403 - accuracy: 0.8971 Step 299: Train Accuracy = 0.8972\n 299/2197 [===>..........................] - ETA: 19:20 - loss: 0.3401 - accuracy: 0.8972 Step 300: Train Accuracy = 0.8972\n 300/2197 [===>..........................] - ETA: 19:19 - loss: 0.3397 - accuracy: 0.8972 Step 301: Train Accuracy = 0.8970\n 301/2197 [===>..........................] - ETA: 19:17 - loss: 0.3402 - accuracy: 0.8970 Step 302: Train Accuracy = 0.8970\n 302/2197 [===>..........................] - ETA: 19:17 - loss: 0.3400 - accuracy: 0.8970 Step 303: Train Accuracy = 0.8971\n 303/2197 [===>..........................] - ETA: 19:16 - loss: 0.3396 - accuracy: 0.8971 Step 304: Train Accuracy = 0.8971\n 304/2197 [===>..........................] - ETA: 19:15 - loss: 0.3394 - accuracy: 0.8971 Step 305: Train Accuracy = 0.8967\n 305/2197 [===>..........................] - ETA: 19:14 - loss: 0.3403 - accuracy: 0.8967 Step 306: Train Accuracy = 0.8971\n 306/2197 [===>..........................] - ETA: 19:12 - loss: 0.3392 - accuracy: 0.8971 Step 307: Train Accuracy = 0.8972\n 307/2197 [===>..........................] - ETA: 19:12 - loss: 0.3389 - accuracy: 0.8972 Step 308: Train Accuracy = 0.8972\n 308/2197 [===>..........................] - ETA: 19:12 - loss: 0.3391 - accuracy: 0.8972 Step 309: Train Accuracy = 0.8968\n 309/2197 [===>..........................] - ETA: 19:11 - loss: 0.3408 - accuracy: 0.8968 Step 310: Train Accuracy = 0.8969\n 310/2197 [===>..........................] - ETA: 19:11 - loss: 0.3407 - accuracy: 0.8969 Step 311: Train Accuracy = 0.8971\n 311/2197 [===>..........................] - ETA: 19:09 - loss: 0.3401 - accuracy: 0.8971 Step 312: Train Accuracy = 0.8973\n 312/2197 [===>..........................] - ETA: 19:09 - loss: 0.3394 - accuracy: 0.8973 Step 313: Train Accuracy = 0.8973\n 313/2197 [===>..........................] - ETA: 19:09 - loss: 0.3395 - accuracy: 0.8973 Step 314: Train Accuracy = 0.8972\n 314/2197 [===>..........................] - ETA: 19:09 - loss: 0.3397 - accuracy: 0.8972 Step 315: Train Accuracy = 0.8975\n 315/2197 [===>..........................] - ETA: 19:09 - loss: 0.3389 - accuracy: 0.8975 Step 316: Train Accuracy = 0.8975\n 316/2197 [===>..........................] - ETA: 19:08 - loss: 0.3388 - accuracy: 0.8975 Step 317: Train Accuracy = 0.8977\n 317/2197 [===>..........................] - ETA: 19:07 - loss: 0.3384 - accuracy: 0.8977 Step 318: Train Accuracy = 0.8979\n 318/2197 [===>..........................] - ETA: 19:06 - loss: 0.3377 - accuracy: 0.8979 Step 319: Train Accuracy = 0.8980\n 319/2197 [===>..........................] - ETA: 19:05 - loss: 0.3374 - accuracy: 0.8980 Step 320: Train Accuracy = 0.8980\n 320/2197 [===>..........................] - ETA: 19:04 - loss: 0.3370 - accuracy: 0.8980 Step 321: Train Accuracy = 0.8981\n 321/2197 [===>..........................] - ETA: 19:02 - loss: 0.3368 - accuracy: 0.8981 Step 322: Train Accuracy = 0.8981\n 322/2197 [===>..........................] - ETA: 19:02 - loss: 0.3365 - accuracy: 0.8981 Step 323: Train Accuracy = 0.8982\n 323/2197 [===>..........................] - ETA: 19:00 - loss: 0.3362 - accuracy: 0.8982 Step 324: Train Accuracy = 0.8983\n 324/2197 [===>..........................] - ETA: 19:00 - loss: 0.3357 - accuracy: 0.8983 Step 325: Train Accuracy = 0.8985\n 325/2197 [===>..........................] - ETA: 18:59 - loss: 0.3353 - accuracy: 0.8985 Step 326: Train Accuracy = 0.8985\n 326/2197 [===>..........................] - ETA: 18:59 - loss: 0.3358 - accuracy: 0.8985 Step 327: Train Accuracy = 0.8985\n 327/2197 [===>..........................] - ETA: 18:58 - loss: 0.3355 - accuracy: 0.8985 Step 328: Train Accuracy = 0.8986\n 328/2197 [===>..........................] - ETA: 18:57 - loss: 0.3353 - accuracy: 0.8986 Step 329: Train Accuracy = 0.8987\n 329/2197 [===>..........................] - ETA: 18:56 - loss: 0.3348 - accuracy: 0.8987 Step 330: Train Accuracy = 0.8988\n 330/2197 [===>..........................] - ETA: 18:55 - loss: 0.3343 - accuracy: 0.8988 Step 331: Train Accuracy = 0.8987\n 331/2197 [===>..........................] - ETA: 18:55 - loss: 0.3349 - accuracy: 0.8987 Step 332: Train Accuracy = 0.8989\n 332/2197 [===>..........................] - ETA: 18:54 - loss: 0.3347 - accuracy: 0.8989 Step 333: Train Accuracy = 0.8990\n 333/2197 [===>..........................] - ETA: 18:53 - loss: 0.3345 - accuracy: 0.8990 Step 334: Train Accuracy = 0.8990\n 334/2197 [===>..........................] - ETA: 18:52 - loss: 0.3345 - accuracy: 0.8990 Step 335: Train Accuracy = 0.8990\n 335/2197 [===>..........................] - ETA: 18:52 - loss: 0.3344 - accuracy: 0.8990 Step 336: Train Accuracy = 0.8993\n 336/2197 [===>..........................] - ETA: 18:51 - loss: 0.3335 - accuracy: 0.8993 Step 337: Train Accuracy = 0.8991\n 337/2197 [===>..........................] - ETA: 18:51 - loss: 0.3337 - accuracy: 0.8991 Step 338: Train Accuracy = 0.8993\n 338/2197 [===>..........................] - ETA: 18:50 - loss: 0.3332 - accuracy: 0.8993 Step 339: Train Accuracy = 0.8995\n 339/2197 [===>..........................] - ETA: 18:50 - loss: 0.3327 - accuracy: 0.8995 Step 340: Train Accuracy = 0.8997\n 340/2197 [===>..........................] - ETA: 18:49 - loss: 0.3321 - accuracy: 0.8997 Step 341: Train Accuracy = 0.8999\n 341/2197 [===>..........................] - ETA: 18:49 - loss: 0.3316 - accuracy: 0.8999 Step 342: Train Accuracy = 0.9001\n 342/2197 [===>..........................] - ETA: 18:48 - loss: 0.3310 - accuracy: 0.9001 Step 343: Train Accuracy = 0.9002\n 343/2197 [===>..........................] - ETA: 18:48 - loss: 0.3308 - accuracy: 0.9002 Step 344: Train Accuracy = 0.9004\n 344/2197 [===>..........................] - ETA: 18:48 - loss: 0.3301 - accuracy: 0.9004 Step 345: Train Accuracy = 0.9003\n 345/2197 [===>..........................] - ETA: 18:47 - loss: 0.3301 - accuracy: 0.9003 Step 346: Train Accuracy = 0.9003\n 346/2197 [===>..........................] - ETA: 18:46 - loss: 0.3298 - accuracy: 0.9003 Step 347: Train Accuracy = 0.9006\n 347/2197 [===>..........................] - ETA: 18:46 - loss: 0.3290 - accuracy: 0.9006 Step 348: Train Accuracy = 0.9006\n 348/2197 [===>..........................] - ETA: 18:46 - loss: 0.3292 - accuracy: 0.9006 Step 349: Train Accuracy = 0.9008\n 349/2197 [===>..........................] - ETA: 18:44 - loss: 0.3285 - accuracy: 0.9008 Step 350: Train Accuracy = 0.9008\n 350/2197 [===>..........................] - ETA: 18:44 - loss: 0.3283 - accuracy: 0.9008 Step 351: Train Accuracy = 0.9011\n 351/2197 [===>..........................] - ETA: 18:43 - loss: 0.3275 - accuracy: 0.9011 Step 352: Train Accuracy = 0.9012\n 352/2197 [===>..........................] - ETA: 18:43 - loss: 0.3269 - accuracy: 0.9012 Step 353: Train Accuracy = 0.9011\n 353/2197 [===>..........................] - ETA: 18:43 - loss: 0.3270 - accuracy: 0.9011 Step 354: Train Accuracy = 0.9011\n 354/2197 [===>..........................] - ETA: 18:42 - loss: 0.3268 - accuracy: 0.9011 Step 355: Train Accuracy = 0.9011\n 355/2197 [===>..........................] - ETA: 18:42 - loss: 0.3267 - accuracy: 0.9011 Step 356: Train Accuracy = 0.9013\n 356/2197 [===>..........................] - ETA: 18:41 - loss: 0.3262 - accuracy: 0.9013 Step 357: Train Accuracy = 0.9014\n 357/2197 [===>..........................] - ETA: 18:40 - loss: 0.3257 - accuracy: 0.9014 Step 358: Train Accuracy = 0.9014\n 358/2197 [===>..........................] - ETA: 18:40 - loss: 0.3256 - accuracy: 0.9014 Step 359: Train Accuracy = 0.9015\n 359/2197 [===>..........................] - ETA: 18:39 - loss: 0.3254 - accuracy: 0.9015 Step 360: Train Accuracy = 0.9016\n 360/2197 [===>..........................] - ETA: 18:38 - loss: 0.3256 - accuracy: 0.9016 Step 361: Train Accuracy = 0.9017\n 361/2197 [===>..........................] - ETA: 18:38 - loss: 0.3253 - accuracy: 0.9017 Step 362: Train Accuracy = 0.9019\n 362/2197 [===>..........................] - ETA: 18:37 - loss: 0.3249 - accuracy: 0.9019 Step 363: Train Accuracy = 0.9022\n 363/2197 [===>..........................] - ETA: 18:37 - loss: 0.3242 - accuracy: 0.9022 Step 364: Train Accuracy = 0.9024\n 364/2197 [===>..........................] - ETA: 18:36 - loss: 0.3236 - accuracy: 0.9024 Step 365: Train Accuracy = 0.9027\n 365/2197 [===>..........................] - ETA: 18:36 - loss: 0.3229 - accuracy: 0.9027 Step 366: Train Accuracy = 0.9028\n 366/2197 [===>..........................] - ETA: 18:36 - loss: 0.3225 - accuracy: 0.9028 Step 367: Train Accuracy = 0.9029\n 367/2197 [====>.........................] - ETA: 18:36 - loss: 0.3222 - accuracy: 0.9029 Step 368: Train Accuracy = 0.9030\n 368/2197 [====>.........................] - ETA: 18:35 - loss: 0.3221 - accuracy: 0.9030 Step 369: Train Accuracy = 0.9031\n 369/2197 [====>.........................] - ETA: 18:34 - loss: 0.3218 - accuracy: 0.9031 Step 370: Train Accuracy = 0.9033\n 370/2197 [====>.........................] - ETA: 18:34 - loss: 0.3212 - accuracy: 0.9033 Step 371: Train Accuracy = 0.9034\n 371/2197 [====>.........................] - ETA: 18:33 - loss: 0.3209 - accuracy: 0.9034 Step 372: Train Accuracy = 0.9036\n 372/2197 [====>.........................] - ETA: 18:32 - loss: 0.3206 - accuracy: 0.9036 Step 373: Train Accuracy = 0.9035\n 373/2197 [====>.........................] - ETA: 18:31 - loss: 0.3210 - accuracy: 0.9035 Step 374: Train Accuracy = 0.9037\n 374/2197 [====>.........................] - ETA: 18:31 - loss: 0.3204 - accuracy: 0.9037 Step 375: Train Accuracy = 0.9038\n 375/2197 [====>.........................] - ETA: 18:29 - loss: 0.3207 - accuracy: 0.9038 Step 376: Train Accuracy = 0.9038\n 376/2197 [====>.........................] - ETA: 18:29 - loss: 0.3205 - accuracy: 0.9038 Step 377: Train Accuracy = 0.9040\n 377/2197 [====>.........................] - ETA: 18:28 - loss: 0.3199 - accuracy: 0.9040 Step 378: Train Accuracy = 0.9041\n 378/2197 [====>.........................] - ETA: 18:27 - loss: 0.3201 - accuracy: 0.9041 Step 379: Train Accuracy = 0.9041\n 379/2197 [====>.........................] - ETA: 18:26 - loss: 0.3198 - accuracy: 0.9041 Step 380: Train Accuracy = 0.9043\n 380/2197 [====>.........................] - ETA: 18:25 - loss: 0.3192 - accuracy: 0.9043 Step 381: Train Accuracy = 0.9042\n 381/2197 [====>.........................] - ETA: 18:25 - loss: 0.3194 - accuracy: 0.9042 Step 382: Train Accuracy = 0.9043\n 382/2197 [====>.........................] - ETA: 18:25 - loss: 0.3190 - accuracy: 0.9043 Step 383: Train Accuracy = 0.9045\n 383/2197 [====>.........................] - ETA: 18:24 - loss: 0.3182 - accuracy: 0.9045 Step 384: Train Accuracy = 0.9046\n 384/2197 [====>.........................] - ETA: 18:24 - loss: 0.3179 - accuracy: 0.9046 Step 385: Train Accuracy = 0.9047\n 385/2197 [====>.........................] - ETA: 18:23 - loss: 0.3176 - accuracy: 0.9047 Step 386: Train Accuracy = 0.9048\n 386/2197 [====>.........................] - ETA: 18:23 - loss: 0.3172 - accuracy: 0.9048 Step 387: Train Accuracy = 0.9046\n 387/2197 [====>.........................] - ETA: 18:21 - loss: 0.3184 - accuracy: 0.9046 Step 388: Train Accuracy = 0.9047\n 388/2197 [====>.........................] - ETA: 18:21 - loss: 0.3179 - accuracy: 0.9047 Step 389: Train Accuracy = 0.9049\n 389/2197 [====>.........................] - ETA: 18:20 - loss: 0.3174 - accuracy: 0.9049 Step 390: Train Accuracy = 0.9047\n 390/2197 [====>.........................] - ETA: 18:20 - loss: 0.3175 - accuracy: 0.9047 Step 391: Train Accuracy = 0.9049\n 391/2197 [====>.........................] - ETA: 18:19 - loss: 0.3169 - accuracy: 0.9049 Step 392: Train Accuracy = 0.9050\n 392/2197 [====>.........................] - ETA: 18:19 - loss: 0.3168 - accuracy: 0.9050 Step 393: Train Accuracy = 0.9050\n 393/2197 [====>.........................] - ETA: 18:18 - loss: 0.3169 - accuracy: 0.9050 Step 394: Train Accuracy = 0.9051\n 394/2197 [====>.........................] - ETA: 18:18 - loss: 0.3166 - accuracy: 0.9051 Step 395: Train Accuracy = 0.9054\n 395/2197 [====>.........................] - ETA: 18:17 - loss: 0.3159 - accuracy: 0.9054 Step 396: Train Accuracy = 0.9054\n 396/2197 [====>.........................] - ETA: 18:17 - loss: 0.3155 - accuracy: 0.9054 Step 397: Train Accuracy = 0.9055\n 397/2197 [====>.........................] - ETA: 18:17 - loss: 0.3154 - accuracy: 0.9055 Step 398: Train Accuracy = 0.9056\n 398/2197 [====>.........................] - ETA: 18:16 - loss: 0.3150 - accuracy: 0.9056 Step 399: Train Accuracy = 0.9058\n 399/2197 [====>.........................] - ETA: 18:16 - loss: 0.3144 - accuracy: 0.9058 Step 400: Train Accuracy = 0.9060\n 400/2197 [====>.........................] - ETA: 18:15 - loss: 0.3137 - accuracy: 0.9060 Step 401: Train Accuracy = 0.9061\n 401/2197 [====>.........................] - ETA: 18:15 - loss: 0.3136 - accuracy: 0.9061 Step 402: Train Accuracy = 0.9063\n 402/2197 [====>.........................] - ETA: 18:14 - loss: 0.3130 - accuracy: 0.9063 Step 403: Train Accuracy = 0.9064\n 403/2197 [====>.........................] - ETA: 18:14 - loss: 0.3127 - accuracy: 0.9064 Step 404: Train Accuracy = 0.9063\n 404/2197 [====>.........................] - ETA: 18:13 - loss: 0.3126 - accuracy: 0.9063 Step 405: Train Accuracy = 0.9065\n 405/2197 [====>.........................] - ETA: 18:13 - loss: 0.3125 - accuracy: 0.9065 Step 406: Train Accuracy = 0.9066\n 406/2197 [====>.........................] - ETA: 18:11 - loss: 0.3120 - accuracy: 0.9066 Step 407: Train Accuracy = 0.9069\n 407/2197 [====>.........................] - ETA: 18:11 - loss: 0.3113 - accuracy: 0.9069 Step 408: Train Accuracy = 0.9069\n 408/2197 [====>.........................] - ETA: 18:10 - loss: 0.3111 - accuracy: 0.9069 Step 409: Train Accuracy = 0.9068\n 409/2197 [====>.........................] - ETA: 18:10 - loss: 0.3112 - accuracy: 0.9068 Step 410: Train Accuracy = 0.9067\n 410/2197 [====>.........................] - ETA: 18:08 - loss: 0.3113 - accuracy: 0.9067 Step 411: Train Accuracy = 0.9067\n 411/2197 [====>.........................] - ETA: 18:08 - loss: 0.3113 - accuracy: 0.9067 Step 412: Train Accuracy = 0.9068\n 412/2197 [====>.........................] - ETA: 18:08 - loss: 0.3111 - accuracy: 0.9068 Step 413: Train Accuracy = 0.9069\n 413/2197 [====>.........................] - ETA: 18:07 - loss: 0.3110 - accuracy: 0.9069 Step 414: Train Accuracy = 0.9069\n 414/2197 [====>.........................] - ETA: 18:07 - loss: 0.3104 - accuracy: 0.9069 Step 415: Train Accuracy = 0.9071\n 415/2197 [====>.........................] - ETA: 18:06 - loss: 0.3099 - accuracy: 0.9071 Step 416: Train Accuracy = 0.9072\n 416/2197 [====>.........................] - ETA: 18:06 - loss: 0.3093 - accuracy: 0.9072 Step 417: Train Accuracy = 0.9073\n 417/2197 [====>.........................] - ETA: 18:05 - loss: 0.3090 - accuracy: 0.9073 Step 418: Train Accuracy = 0.9074\n 418/2197 [====>.........................] - ETA: 18:05 - loss: 0.3088 - accuracy: 0.9074 Step 419: Train Accuracy = 0.9074\n 419/2197 [====>.........................] - ETA: 18:04 - loss: 0.3085 - accuracy: 0.9074 Step 420: Train Accuracy = 0.9074\n 420/2197 [====>.........................] - ETA: 18:03 - loss: 0.3083 - accuracy: 0.9074 Step 421: Train Accuracy = 0.9074\n 421/2197 [====>.........................] - ETA: 18:03 - loss: 0.3084 - accuracy: 0.9074 Step 422: Train Accuracy = 0.9074\n 422/2197 [====>.........................] - ETA: 18:02 - loss: 0.3084 - accuracy: 0.9074 Step 423: Train Accuracy = 0.9074\n 423/2197 [====>.........................] - ETA: 18:02 - loss: 0.3082 - accuracy: 0.9074 Step 424: Train Accuracy = 0.9077\n 424/2197 [====>.........................] - ETA: 18:02 - loss: 0.3076 - accuracy: 0.9077 Step 425: Train Accuracy = 0.9077\n 425/2197 [====>.........................] - ETA: 18:01 - loss: 0.3073 - accuracy: 0.9077 Step 426: Train Accuracy = 0.9079\n 426/2197 [====>.........................] - ETA: 18:01 - loss: 0.3068 - accuracy: 0.9079 Step 427: Train Accuracy = 0.9080\n 427/2197 [====>.........................] - ETA: 18:01 - loss: 0.3064 - accuracy: 0.9080 Step 428: Train Accuracy = 0.9081\n 428/2197 [====>.........................] - ETA: 18:00 - loss: 0.3060 - accuracy: 0.9081 Step 429: Train Accuracy = 0.9081\n 429/2197 [====>.........................] - ETA: 18:00 - loss: 0.3057 - accuracy: 0.9081 Step 430: Train Accuracy = 0.9081\n 430/2197 [====>.........................] - ETA: 17:59 - loss: 0.3054 - accuracy: 0.9081 Step 431: Train Accuracy = 0.9081\n 431/2197 [====>.........................] - ETA: 17:58 - loss: 0.3054 - accuracy: 0.9081 Step 432: Train Accuracy = 0.9081\n 432/2197 [====>.........................] - ETA: 17:57 - loss: 0.3060 - accuracy: 0.9081 Step 433: Train Accuracy = 0.9080\n 433/2197 [====>.........................] - ETA: 17:57 - loss: 0.3061 - accuracy: 0.9080 Step 434: Train Accuracy = 0.9080\n 434/2197 [====>.........................] - ETA: 17:56 - loss: 0.3059 - accuracy: 0.9080 Step 435: Train Accuracy = 0.9080\n 435/2197 [====>.........................] - ETA: 17:56 - loss: 0.3056 - accuracy: 0.9080 Step 436: Train Accuracy = 0.9081\n 436/2197 [====>.........................] - ETA: 17:55 - loss: 0.3051 - accuracy: 0.9081 Step 437: Train Accuracy = 0.9081\n 437/2197 [====>.........................] - ETA: 17:55 - loss: 0.3052 - accuracy: 0.9081 Step 438: Train Accuracy = 0.9082\n 438/2197 [====>.........................] - ETA: 17:55 - loss: 0.3048 - accuracy: 0.9082 Step 439: Train Accuracy = 0.9084\n 439/2197 [====>.........................] - ETA: 17:54 - loss: 0.3043 - accuracy: 0.9084 Step 440: Train Accuracy = 0.9086\n 440/2197 [=====>........................] - ETA: 17:54 - loss: 0.3037 - accuracy: 0.9086 Step 441: Train Accuracy = 0.9087\n 441/2197 [=====>........................] - ETA: 17:54 - loss: 0.3034 - accuracy: 0.9087 Step 442: Train Accuracy = 0.9088\n 442/2197 [=====>........................] - ETA: 17:53 - loss: 0.3030 - accuracy: 0.9088 Step 443: Train Accuracy = 0.9089\n 443/2197 [=====>........................] - ETA: 17:53 - loss: 0.3025 - accuracy: 0.9089 Step 444: Train Accuracy = 0.9088\n 444/2197 [=====>........................] - ETA: 17:52 - loss: 0.3025 - accuracy: 0.9088 Step 445: Train Accuracy = 0.9089\n 445/2197 [=====>........................] - ETA: 17:52 - loss: 0.3019 - accuracy: 0.9089 Step 446: Train Accuracy = 0.9089\n 446/2197 [=====>........................] - ETA: 17:51 - loss: 0.3017 - accuracy: 0.9089 Step 447: Train Accuracy = 0.9090\n 447/2197 [=====>........................] - ETA: 17:50 - loss: 0.3014 - accuracy: 0.9090 Step 448: Train Accuracy = 0.9091\n 448/2197 [=====>........................] - ETA: 17:49 - loss: 0.3009 - accuracy: 0.9091 Step 449: Train Accuracy = 0.9092\n 449/2197 [=====>........................] - ETA: 17:49 - loss: 0.3008 - accuracy: 0.9092 Step 450: Train Accuracy = 0.9092\n 450/2197 [=====>........................] - ETA: 17:48 - loss: 0.3011 - accuracy: 0.9092 Step 451: Train Accuracy = 0.9094\n 451/2197 [=====>........................] - ETA: 17:48 - loss: 0.3005 - accuracy: 0.9094 Step 452: Train Accuracy = 0.9095\n 452/2197 [=====>........................] - ETA: 17:46 - loss: 0.3007 - accuracy: 0.9095 Step 453: Train Accuracy = 0.9097\n 453/2197 [=====>........................] - ETA: 17:46 - loss: 0.3001 - accuracy: 0.9097 Step 454: Train Accuracy = 0.9097\n 454/2197 [=====>........................] - ETA: 17:45 - loss: 0.3002 - accuracy: 0.9097 Step 455: Train Accuracy = 0.9096\n 455/2197 [=====>........................] - ETA: 17:45 - loss: 0.3004 - accuracy: 0.9096 Step 456: Train Accuracy = 0.9097\n 456/2197 [=====>........................] - ETA: 17:45 - loss: 0.3002 - accuracy: 0.9097 Step 457: Train Accuracy = 0.9099\n 457/2197 [=====>........................] - ETA: 17:44 - loss: 0.2999 - accuracy: 0.9099 Step 458: Train Accuracy = 0.9099\n 458/2197 [=====>........................] - ETA: 17:44 - loss: 0.2998 - accuracy: 0.9099 Step 459: Train Accuracy = 0.9100\n 459/2197 [=====>........................] - ETA: 17:43 - loss: 0.2995 - accuracy: 0.9100 Step 460: Train Accuracy = 0.9100\n 460/2197 [=====>........................] - ETA: 17:42 - loss: 0.2993 - accuracy: 0.9100 Step 461: Train Accuracy = 0.9101\n 461/2197 [=====>........................] - ETA: 17:42 - loss: 0.2990 - accuracy: 0.9101 Step 462: Train Accuracy = 0.9103\n 462/2197 [=====>........................] - ETA: 17:41 - loss: 0.2985 - accuracy: 0.9103 Step 463: Train Accuracy = 0.9102\n 463/2197 [=====>........................] - ETA: 17:41 - loss: 0.2984 - accuracy: 0.9102 Step 464: Train Accuracy = 0.9103\n 464/2197 [=====>........................] - ETA: 17:41 - loss: 0.2982 - accuracy: 0.9103 Step 465: Train Accuracy = 0.9104\n 465/2197 [=====>........................] - ETA: 17:40 - loss: 0.2977 - accuracy: 0.9104 Step 466: Train Accuracy = 0.9106\n 466/2197 [=====>........................] - ETA: 17:40 - loss: 0.2972 - accuracy: 0.9106 Step 467: Train Accuracy = 0.9106\n 467/2197 [=====>........................] - ETA: 17:39 - loss: 0.2971 - accuracy: 0.9106 Step 468: Train Accuracy = 0.9106\n 468/2197 [=====>........................] - ETA: 17:39 - loss: 0.2968 - accuracy: 0.9106 Step 469: Train Accuracy = 0.9108\n 469/2197 [=====>........................] - ETA: 17:38 - loss: 0.2964 - accuracy: 0.9108 Step 470: Train Accuracy = 0.9108\n 470/2197 [=====>........................] - ETA: 17:37 - loss: 0.2960 - accuracy: 0.9108 Step 471: Train Accuracy = 0.9108\n 471/2197 [=====>........................] - ETA: 17:37 - loss: 0.2960 - accuracy: 0.9108 Step 472: Train Accuracy = 0.9109\n 472/2197 [=====>........................] - ETA: 17:36 - loss: 0.2958 - accuracy: 0.9109 Step 473: Train Accuracy = 0.9110\n 473/2197 [=====>........................] - ETA: 17:36 - loss: 0.2956 - accuracy: 0.9110 Step 474: Train Accuracy = 0.9110\n 474/2197 [=====>........................] - ETA: 17:35 - loss: 0.2954 - accuracy: 0.9110 Step 475: Train Accuracy = 0.9112\n 475/2197 [=====>........................] - ETA: 17:35 - loss: 0.2949 - accuracy: 0.9112 Step 476: Train Accuracy = 0.9113\n 476/2197 [=====>........................] - ETA: 17:34 - loss: 0.2944 - accuracy: 0.9113 Step 477: Train Accuracy = 0.9114\n 477/2197 [=====>........................] - ETA: 17:33 - loss: 0.2941 - accuracy: 0.9114 Step 478: Train Accuracy = 0.9113\n 478/2197 [=====>........................] - ETA: 17:33 - loss: 0.2940 - accuracy: 0.9113 Step 479: Train Accuracy = 0.9114\n 479/2197 [=====>........................] - ETA: 17:33 - loss: 0.2944 - accuracy: 0.9114 Step 480: Train Accuracy = 0.9115\n 480/2197 [=====>........................] - ETA: 17:32 - loss: 0.2942 - accuracy: 0.9115 Step 481: Train Accuracy = 0.9116\n 481/2197 [=====>........................] - ETA: 17:31 - loss: 0.2937 - accuracy: 0.9116 Step 482: Train Accuracy = 0.9117\n 482/2197 [=====>........................] - ETA: 17:30 - loss: 0.2934 - accuracy: 0.9117 Step 483: Train Accuracy = 0.9117\n 483/2197 [=====>........................] - ETA: 17:30 - loss: 0.2934 - accuracy: 0.9117 Step 484: Train Accuracy = 0.9117\n 484/2197 [=====>........................] - ETA: 17:29 - loss: 0.2935 - accuracy: 0.9117 Step 485: Train Accuracy = 0.9118\n 485/2197 [=====>........................] - ETA: 17:29 - loss: 0.2931 - accuracy: 0.9118 Step 486: Train Accuracy = 0.9119\n 486/2197 [=====>........................] - ETA: 17:28 - loss: 0.2926 - accuracy: 0.9119 Step 487: Train Accuracy = 0.9121\n 487/2197 [=====>........................] - ETA: 17:27 - loss: 0.2921 - accuracy: 0.9121 Step 488: Train Accuracy = 0.9120\n 488/2197 [=====>........................] - ETA: 17:27 - loss: 0.2921 - accuracy: 0.9120 Step 489: Train Accuracy = 0.9121\n 489/2197 [=====>........................] - ETA: 17:26 - loss: 0.2916 - accuracy: 0.9121 Step 490: Train Accuracy = 0.9122\n 490/2197 [=====>........................] - ETA: 17:26 - loss: 0.2913 - accuracy: 0.9122 Step 491: Train Accuracy = 0.9124\n 491/2197 [=====>........................] - ETA: 17:25 - loss: 0.2910 - accuracy: 0.9124 Step 492: Train Accuracy = 0.9125\n 492/2197 [=====>........................] - ETA: 17:25 - loss: 0.2906 - accuracy: 0.9125 Step 493: Train Accuracy = 0.9127\n 493/2197 [=====>........................] - ETA: 17:24 - loss: 0.2901 - accuracy: 0.9127 Step 494: Train Accuracy = 0.9126\n 494/2197 [=====>........................] - ETA: 17:22 - loss: 0.2899 - accuracy: 0.9126 Step 495: Train Accuracy = 0.9126\n 495/2197 [=====>........................] - ETA: 17:22 - loss: 0.2899 - accuracy: 0.9126 Step 496: Train Accuracy = 0.9128\n 496/2197 [=====>........................] - ETA: 17:21 - loss: 0.2894 - accuracy: 0.9128 Step 497: Train Accuracy = 0.9129\n 497/2197 [=====>........................] - ETA: 17:20 - loss: 0.2892 - accuracy: 0.9129 Step 498: Train Accuracy = 0.9129\n 498/2197 [=====>........................] - ETA: 17:20 - loss: 0.2888 - accuracy: 0.9129 Step 499: Train Accuracy = 0.9130\n 499/2197 [=====>........................] - ETA: 17:19 - loss: 0.2886 - accuracy: 0.9130 Step 500: Train Accuracy = 0.9131\n 500/2197 [=====>........................] - ETA: 17:19 - loss: 0.2880 - accuracy: 0.9131 Step 501: Train Accuracy = 0.9131\n 501/2197 [=====>........................] - ETA: 17:17 - loss: 0.2878 - accuracy: 0.9131 Step 502: Train Accuracy = 0.9131\n 502/2197 [=====>........................] - ETA: 17:17 - loss: 0.2878 - accuracy: 0.9131 Step 503: Train Accuracy = 0.9133\n 503/2197 [=====>........................] - ETA: 17:16 - loss: 0.2873 - accuracy: 0.9133 Step 504: Train Accuracy = 0.9134\n 504/2197 [=====>........................] - ETA: 17:16 - loss: 0.2868 - accuracy: 0.9134 Step 505: Train Accuracy = 0.9136\n 505/2197 [=====>........................] - ETA: 17:15 - loss: 0.2863 - accuracy: 0.9136 Step 506: Train Accuracy = 0.9135\n 506/2197 [=====>........................] - ETA: 17:15 - loss: 0.2865 - accuracy: 0.9135 Step 507: Train Accuracy = 0.9136\n 507/2197 [=====>........................] - ETA: 17:14 - loss: 0.2859 - accuracy: 0.9136 Step 508: Train Accuracy = 0.9136\n 508/2197 [=====>........................] - ETA: 17:13 - loss: 0.2859 - accuracy: 0.9136 Step 509: Train Accuracy = 0.9138\n 509/2197 [=====>........................] - ETA: 17:12 - loss: 0.2854 - accuracy: 0.9138 Step 510: Train Accuracy = 0.9138\n 510/2197 [=====>........................] - ETA: 17:12 - loss: 0.2852 - accuracy: 0.9138 Step 511: Train Accuracy = 0.9140\n 511/2197 [=====>........................] - ETA: 17:10 - loss: 0.2850 - accuracy: 0.9140 Step 512: Train Accuracy = 0.9141\n 512/2197 [=====>........................] - ETA: 17:09 - loss: 0.2846 - accuracy: 0.9141 Step 513: Train Accuracy = 0.9140\n 513/2197 [======>.......................] - ETA: 17:09 - loss: 0.2845 - accuracy: 0.9140 Step 514: Train Accuracy = 0.9142\n 514/2197 [======>.......................] - ETA: 17:08 - loss: 0.2841 - accuracy: 0.9142 Step 515: Train Accuracy = 0.9143\n 515/2197 [======>.......................] - ETA: 17:07 - loss: 0.2840 - accuracy: 0.9143 Step 516: Train Accuracy = 0.9142\n 516/2197 [======>.......................] - ETA: 17:07 - loss: 0.2842 - accuracy: 0.9142 Step 517: Train Accuracy = 0.9142\n 517/2197 [======>.......................] - ETA: 17:06 - loss: 0.2840 - accuracy: 0.9142 Step 518: Train Accuracy = 0.9143\n 518/2197 [======>.......................] - ETA: 17:06 - loss: 0.2838 - accuracy: 0.9143 Step 519: Train Accuracy = 0.9144\n 519/2197 [======>.......................] - ETA: 17:05 - loss: 0.2835 - accuracy: 0.9144 Step 520: Train Accuracy = 0.9145\n 520/2197 [======>.......................] - ETA: 17:04 - loss: 0.2831 - accuracy: 0.9145 Step 521: Train Accuracy = 0.9145\n 521/2197 [======>.......................] - ETA: 17:04 - loss: 0.2834 - accuracy: 0.9145 Step 522: Train Accuracy = 0.9145\n 522/2197 [======>.......................] - ETA: 17:03 - loss: 0.2832 - accuracy: 0.9145 Step 523: Train Accuracy = 0.9146\n 523/2197 [======>.......................] - ETA: 17:03 - loss: 0.2828 - accuracy: 0.9146 Step 524: Train Accuracy = 0.9147\n 524/2197 [======>.......................] - ETA: 17:02 - loss: 0.2824 - accuracy: 0.9147 Step 525: Train Accuracy = 0.9148\n 525/2197 [======>.......................] - ETA: 17:01 - loss: 0.2819 - accuracy: 0.9148 Step 526: Train Accuracy = 0.9149\n 526/2197 [======>.......................] - ETA: 17:01 - loss: 0.2815 - accuracy: 0.9149 Step 527: Train Accuracy = 0.9150\n 527/2197 [======>.......................] - ETA: 17:01 - loss: 0.2811 - accuracy: 0.9150 Step 528: Train Accuracy = 0.9151\n 528/2197 [======>.......................] - ETA: 17:00 - loss: 0.2808 - accuracy: 0.9151 Step 529: Train Accuracy = 0.9153\n 529/2197 [======>.......................] - ETA: 17:00 - loss: 0.2803 - accuracy: 0.9153 Step 530: Train Accuracy = 0.9152\n 530/2197 [======>.......................] - ETA: 16:59 - loss: 0.2802 - accuracy: 0.9152 Step 531: Train Accuracy = 0.9154\n 531/2197 [======>.......................] - ETA: 16:59 - loss: 0.2798 - accuracy: 0.9154 Step 532: Train Accuracy = 0.9153\n 532/2197 [======>.......................] - ETA: 16:58 - loss: 0.2797 - accuracy: 0.9153 Step 533: Train Accuracy = 0.9152\n 533/2197 [======>.......................] - ETA: 16:58 - loss: 0.2797 - accuracy: 0.9152 Step 534: Train Accuracy = 0.9152\n 534/2197 [======>.......................] - ETA: 16:57 - loss: 0.2796 - accuracy: 0.9152 Step 535: Train Accuracy = 0.9153\n 535/2197 [======>.......................] - ETA: 16:57 - loss: 0.2795 - accuracy: 0.9153 Step 536: Train Accuracy = 0.9154\n 536/2197 [======>.......................] - ETA: 16:56 - loss: 0.2792 - accuracy: 0.9154 Step 537: Train Accuracy = 0.9154\n 537/2197 [======>.......................] - ETA: 16:55 - loss: 0.2792 - accuracy: 0.9154 Step 538: Train Accuracy = 0.9155\n 538/2197 [======>.......................] - ETA: 16:55 - loss: 0.2789 - accuracy: 0.9155 Step 539: Train Accuracy = 0.9155\n 539/2197 [======>.......................] - ETA: 16:54 - loss: 0.2789 - accuracy: 0.9155 Step 540: Train Accuracy = 0.9157\n 540/2197 [======>.......................] - ETA: 16:54 - loss: 0.2785 - accuracy: 0.9157 Step 541: Train Accuracy = 0.9157\n 541/2197 [======>.......................] - ETA: 16:53 - loss: 0.2784 - accuracy: 0.9157 Step 542: Train Accuracy = 0.9158\n 542/2197 [======>.......................] - ETA: 16:53 - loss: 0.2782 - accuracy: 0.9158 Step 543: Train Accuracy = 0.9157\n 543/2197 [======>.......................] - ETA: 16:52 - loss: 0.2782 - accuracy: 0.9157 Step 544: Train Accuracy = 0.9158\n 544/2197 [======>.......................] - ETA: 16:51 - loss: 0.2780 - accuracy: 0.9158 Step 545: Train Accuracy = 0.9159\n 545/2197 [======>.......................] - ETA: 16:51 - loss: 0.2777 - accuracy: 0.9159 Step 546: Train Accuracy = 0.9160\n 546/2197 [======>.......................] - ETA: 16:50 - loss: 0.2776 - accuracy: 0.9160 Step 547: Train Accuracy = 0.9160\n 547/2197 [======>.......................] - ETA: 16:50 - loss: 0.2774 - accuracy: 0.9160 Step 548: Train Accuracy = 0.9161\n 548/2197 [======>.......................] - ETA: 16:49 - loss: 0.2771 - accuracy: 0.9161 Step 549: Train Accuracy = 0.9161\n 549/2197 [======>.......................] - ETA: 16:47 - loss: 0.2770 - accuracy: 0.9161 Step 550: Train Accuracy = 0.9162\n 550/2197 [======>.......................] - ETA: 16:47 - loss: 0.2767 - accuracy: 0.9162 Step 551: Train Accuracy = 0.9161\n 551/2197 [======>.......................] - ETA: 16:46 - loss: 0.2765 - accuracy: 0.9161 Step 552: Train Accuracy = 0.9161\n 552/2197 [======>.......................] - ETA: 16:46 - loss: 0.2764 - accuracy: 0.9161 Step 553: Train Accuracy = 0.9163\n 553/2197 [======>.......................] - ETA: 16:45 - loss: 0.2759 - accuracy: 0.9163 Step 554: Train Accuracy = 0.9164\n 554/2197 [======>.......................] - ETA: 16:44 - loss: 0.2755 - accuracy: 0.9164 Step 555: Train Accuracy = 0.9165\n 555/2197 [======>.......................] - ETA: 16:44 - loss: 0.2753 - accuracy: 0.9165 Step 556: Train Accuracy = 0.9165\n 556/2197 [======>.......................] - ETA: 16:43 - loss: 0.2750 - accuracy: 0.9165 Step 557: Train Accuracy = 0.9166\n 557/2197 [======>.......................] - ETA: 16:42 - loss: 0.2748 - accuracy: 0.9166 Step 558: Train Accuracy = 0.9166\n 558/2197 [======>.......................] - ETA: 16:42 - loss: 0.2747 - accuracy: 0.9166 Step 559: Train Accuracy = 0.9166\n 559/2197 [======>.......................] - ETA: 16:41 - loss: 0.2746 - accuracy: 0.9166 Step 560: Train Accuracy = 0.9166\n 560/2197 [======>.......................] - ETA: 16:40 - loss: 0.2744 - accuracy: 0.9166 Step 561: Train Accuracy = 0.9167\n 561/2197 [======>.......................] - ETA: 16:39 - loss: 0.2741 - accuracy: 0.9167 Step 562: Train Accuracy = 0.9169\n 562/2197 [======>.......................] - ETA: 16:38 - loss: 0.2737 - accuracy: 0.9169 Step 563: Train Accuracy = 0.9170\n 563/2197 [======>.......................] - ETA: 16:37 - loss: 0.2736 - accuracy: 0.9170 Step 564: Train Accuracy = 0.9171\n 564/2197 [======>.......................] - ETA: 16:36 - loss: 0.2733 - accuracy: 0.9171 Step 565: Train Accuracy = 0.9171\n 565/2197 [======>.......................] - ETA: 16:36 - loss: 0.2732 - accuracy: 0.9171 Step 566: Train Accuracy = 0.9173\n 566/2197 [======>.......................] - ETA: 16:35 - loss: 0.2727 - accuracy: 0.9173 Step 567: Train Accuracy = 0.9173\n 567/2197 [======>.......................] - ETA: 16:35 - loss: 0.2724 - accuracy: 0.9173 Step 568: Train Accuracy = 0.9174\n 568/2197 [======>.......................] - ETA: 16:34 - loss: 0.2723 - accuracy: 0.9174 Step 569: Train Accuracy = 0.9175\n 569/2197 [======>.......................] - ETA: 16:33 - loss: 0.2719 - accuracy: 0.9175 Step 570: Train Accuracy = 0.9176\n 570/2197 [======>.......................] - ETA: 16:32 - loss: 0.2716 - accuracy: 0.9176 Step 571: Train Accuracy = 0.9176\n 571/2197 [======>.......................] - ETA: 16:32 - loss: 0.2713 - accuracy: 0.9176 Step 572: Train Accuracy = 0.9177\n 572/2197 [======>.......................] - ETA: 16:31 - loss: 0.2711 - accuracy: 0.9177 Step 573: Train Accuracy = 0.9178\n 573/2197 [======>.......................] - ETA: 16:30 - loss: 0.2708 - accuracy: 0.9178 Step 574: Train Accuracy = 0.9179\n 574/2197 [======>.......................] - ETA: 16:29 - loss: 0.2708 - accuracy: 0.9179 Step 575: Train Accuracy = 0.9181\n 575/2197 [======>.......................] - ETA: 16:29 - loss: 0.2704 - accuracy: 0.9181 Step 576: Train Accuracy = 0.9182\n 576/2197 [======>.......................] - ETA: 16:28 - loss: 0.2701 - accuracy: 0.9182 Step 577: Train Accuracy = 0.9183\n 577/2197 [======>.......................] - ETA: 16:28 - loss: 0.2698 - accuracy: 0.9183 Step 578: Train Accuracy = 0.9184\n 578/2197 [======>.......................] - ETA: 16:27 - loss: 0.2695 - accuracy: 0.9184 Step 579: Train Accuracy = 0.9185\n 579/2197 [======>.......................] - ETA: 16:27 - loss: 0.2694 - accuracy: 0.9185 Step 580: Train Accuracy = 0.9185\n 580/2197 [======>.......................] - ETA: 16:27 - loss: 0.2693 - accuracy: 0.9185 Step 581: Train Accuracy = 0.9186\n 581/2197 [======>.......................] - ETA: 16:26 - loss: 0.2689 - accuracy: 0.9186 Step 582: Train Accuracy = 0.9187\n 582/2197 [======>.......................] - ETA: 16:25 - loss: 0.2686 - accuracy: 0.9187 Step 583: Train Accuracy = 0.9188\n 583/2197 [======>.......................] - ETA: 16:25 - loss: 0.2685 - accuracy: 0.9188 Step 584: Train Accuracy = 0.9189\n 584/2197 [======>.......................] - ETA: 16:24 - loss: 0.2683 - accuracy: 0.9189 Step 585: Train Accuracy = 0.9190\n 585/2197 [======>.......................] - ETA: 16:24 - loss: 0.2679 - accuracy: 0.9190 Step 586: Train Accuracy = 0.9191\n 586/2197 [=======>......................] - ETA: 16:23 - loss: 0.2678 - accuracy: 0.9191 Step 587: Train Accuracy = 0.9191\n 587/2197 [=======>......................] - ETA: 16:23 - loss: 0.2677 - accuracy: 0.9191 Step 588: Train Accuracy = 0.9192\n 588/2197 [=======>......................] - ETA: 16:22 - loss: 0.2674 - accuracy: 0.9192 Step 589: Train Accuracy = 0.9192\n 589/2197 [=======>......................] - ETA: 16:22 - loss: 0.2676 - accuracy: 0.9192 Step 590: Train Accuracy = 0.9192\n 590/2197 [=======>......................] - ETA: 16:21 - loss: 0.2673 - accuracy: 0.9192 Step 591: Train Accuracy = 0.9192\n 591/2197 [=======>......................] - ETA: 16:21 - loss: 0.2672 - accuracy: 0.9192 Step 592: Train Accuracy = 0.9193\n 592/2197 [=======>......................] - ETA: 16:20 - loss: 0.2670 - accuracy: 0.9193 Step 593: Train Accuracy = 0.9192\n 593/2197 [=======>......................] - ETA: 16:20 - loss: 0.2672 - accuracy: 0.9192 Step 594: Train Accuracy = 0.9193\n 594/2197 [=======>......................] - ETA: 16:20 - loss: 0.2669 - accuracy: 0.9193 Step 595: Train Accuracy = 0.9192\n 595/2197 [=======>......................] - ETA: 16:19 - loss: 0.2667 - accuracy: 0.9192 Step 596: Train Accuracy = 0.9194\n 596/2197 [=======>......................] - ETA: 16:18 - loss: 0.2665 - accuracy: 0.9194 Step 597: Train Accuracy = 0.9195\n 597/2197 [=======>......................] - ETA: 16:18 - loss: 0.2661 - accuracy: 0.9195 Step 598: Train Accuracy = 0.9195\n 598/2197 [=======>......................] - ETA: 16:17 - loss: 0.2659 - accuracy: 0.9195 Step 599: Train Accuracy = 0.9195\n 599/2197 [=======>......................] - ETA: 16:16 - loss: 0.2659 - accuracy: 0.9195 Step 600: Train Accuracy = 0.9195\n 600/2197 [=======>......................] - ETA: 16:15 - loss: 0.2657 - accuracy: 0.9195 Step 601: Train Accuracy = 0.9194\n 601/2197 [=======>......................] - ETA: 16:15 - loss: 0.2657 - accuracy: 0.9194 Step 602: Train Accuracy = 0.9193\n 602/2197 [=======>......................] - ETA: 16:14 - loss: 0.2661 - accuracy: 0.9193 Step 603: Train Accuracy = 0.9194\n 603/2197 [=======>......................] - ETA: 16:14 - loss: 0.2657 - accuracy: 0.9194 Step 604: Train Accuracy = 0.9194\n 604/2197 [=======>......................] - ETA: 16:13 - loss: 0.2658 - accuracy: 0.9194 Step 605: Train Accuracy = 0.9193\n 605/2197 [=======>......................] - ETA: 16:12 - loss: 0.2660 - accuracy: 0.9193 Step 606: Train Accuracy = 0.9193\n 606/2197 [=======>......................] - ETA: 16:12 - loss: 0.2658 - accuracy: 0.9193 Step 607: Train Accuracy = 0.9194\n 607/2197 [=======>......................] - ETA: 16:11 - loss: 0.2654 - accuracy: 0.9194 Step 608: Train Accuracy = 0.9195\n 608/2197 [=======>......................] - ETA: 16:10 - loss: 0.2653 - accuracy: 0.9195 Step 609: Train Accuracy = 0.9196\n 609/2197 [=======>......................] - ETA: 16:10 - loss: 0.2650 - accuracy: 0.9196 Step 610: Train Accuracy = 0.9197\n 610/2197 [=======>......................] - ETA: 16:09 - loss: 0.2648 - accuracy: 0.9197 Step 611: Train Accuracy = 0.9198\n 611/2197 [=======>......................] - ETA: 16:09 - loss: 0.2645 - accuracy: 0.9198 Step 612: Train Accuracy = 0.9198\n 612/2197 [=======>......................] - ETA: 16:08 - loss: 0.2645 - accuracy: 0.9198 Step 613: Train Accuracy = 0.9198\n 613/2197 [=======>......................] - ETA: 16:07 - loss: 0.2645 - accuracy: 0.9198 Step 614: Train Accuracy = 0.9199\n 614/2197 [=======>......................] - ETA: 16:06 - loss: 0.2645 - accuracy: 0.9199 Step 615: Train Accuracy = 0.9199\n 615/2197 [=======>......................] - ETA: 16:06 - loss: 0.2642 - accuracy: 0.9199 Step 616: Train Accuracy = 0.9199\n 616/2197 [=======>......................] - ETA: 16:05 - loss: 0.2641 - accuracy: 0.9199 Step 617: Train Accuracy = 0.9199\n 617/2197 [=======>......................] - ETA: 16:05 - loss: 0.2640 - accuracy: 0.9199 Step 618: Train Accuracy = 0.9200\n 618/2197 [=======>......................] - ETA: 16:04 - loss: 0.2638 - accuracy: 0.9200 Step 619: Train Accuracy = 0.9200\n 619/2197 [=======>......................] - ETA: 16:04 - loss: 0.2638 - accuracy: 0.9200 Step 620: Train Accuracy = 0.9201\n 620/2197 [=======>......................] - ETA: 16:03 - loss: 0.2636 - accuracy: 0.9201 Step 621: Train Accuracy = 0.9201\n 621/2197 [=======>......................] - ETA: 16:02 - loss: 0.2635 - accuracy: 0.9201 Step 622: Train Accuracy = 0.9201\n 622/2197 [=======>......................] - ETA: 16:01 - loss: 0.2633 - accuracy: 0.9201 Step 623: Train Accuracy = 0.9201\n 623/2197 [=======>......................] - ETA: 16:01 - loss: 0.2633 - accuracy: 0.9201 Step 624: Train Accuracy = 0.9201\n 624/2197 [=======>......................] - ETA: 16:00 - loss: 0.2633 - accuracy: 0.9201 Step 625: Train Accuracy = 0.9201\n 625/2197 [=======>......................] - ETA: 16:00 - loss: 0.2633 - accuracy: 0.9201 Step 626: Train Accuracy = 0.9200\n 626/2197 [=======>......................] - ETA: 16:00 - loss: 0.2632 - accuracy: 0.9200 Step 627: Train Accuracy = 0.9201\n 627/2197 [=======>......................] - ETA: 15:59 - loss: 0.2633 - accuracy: 0.9201 Step 628: Train Accuracy = 0.9201\n 628/2197 [=======>......................] - ETA: 15:59 - loss: 0.2631 - accuracy: 0.9201 Step 629: Train Accuracy = 0.9202\n 629/2197 [=======>......................] - ETA: 15:58 - loss: 0.2628 - accuracy: 0.9202 Step 630: Train Accuracy = 0.9203\n 630/2197 [=======>......................] - ETA: 15:58 - loss: 0.2624 - accuracy: 0.9203 Step 631: Train Accuracy = 0.9203\n 631/2197 [=======>......................] - ETA: 15:57 - loss: 0.2623 - accuracy: 0.9203 Step 632: Train Accuracy = 0.9203\n 632/2197 [=======>......................] - ETA: 15:57 - loss: 0.2622 - accuracy: 0.9203 Step 633: Train Accuracy = 0.9204\n 633/2197 [=======>......................] - ETA: 15:56 - loss: 0.2619 - accuracy: 0.9204 Step 634: Train Accuracy = 0.9205\n 634/2197 [=======>......................] - ETA: 15:56 - loss: 0.2617 - accuracy: 0.9205 Step 635: Train Accuracy = 0.9205\n 635/2197 [=======>......................] - ETA: 15:55 - loss: 0.2614 - accuracy: 0.9205 Step 636: Train Accuracy = 0.9205\n 636/2197 [=======>......................] - ETA: 15:54 - loss: 0.2614 - accuracy: 0.9205 Step 637: Train Accuracy = 0.9206\n 637/2197 [=======>......................] - ETA: 15:54 - loss: 0.2610 - accuracy: 0.9206 Step 638: Train Accuracy = 0.9207\n 638/2197 [=======>......................] - ETA: 15:53 - loss: 0.2610 - accuracy: 0.9207 Step 639: Train Accuracy = 0.9208\n 639/2197 [=======>......................] - ETA: 15:53 - loss: 0.2607 - accuracy: 0.9208 Step 640: Train Accuracy = 0.9208\n 640/2197 [=======>......................] - ETA: 15:52 - loss: 0.2607 - accuracy: 0.9208 Step 641: Train Accuracy = 0.9208\n 641/2197 [=======>......................] - ETA: 15:51 - loss: 0.2606 - accuracy: 0.9208 Step 642: Train Accuracy = 0.9208\n 642/2197 [=======>......................] - ETA: 15:51 - loss: 0.2603 - accuracy: 0.9208 Step 643: Train Accuracy = 0.9208\n 643/2197 [=======>......................] - ETA: 15:50 - loss: 0.2603 - accuracy: 0.9208 Step 644: Train Accuracy = 0.9209\n 644/2197 [=======>......................] - ETA: 15:50 - loss: 0.2600 - accuracy: 0.9209 Step 645: Train Accuracy = 0.9209\n 645/2197 [=======>......................] - ETA: 15:49 - loss: 0.2598 - accuracy: 0.9209 Step 646: Train Accuracy = 0.9209\n 646/2197 [=======>......................] - ETA: 15:49 - loss: 0.2598 - accuracy: 0.9209 Step 647: Train Accuracy = 0.9209\n 647/2197 [=======>......................] - ETA: 15:48 - loss: 0.2597 - accuracy: 0.9209 Step 648: Train Accuracy = 0.9209\n 648/2197 [=======>......................] - ETA: 15:47 - loss: 0.2596 - accuracy: 0.9209 Step 649: Train Accuracy = 0.9210\n 649/2197 [=======>......................] - ETA: 15:46 - loss: 0.2593 - accuracy: 0.9210 Step 650: Train Accuracy = 0.9210\n 650/2197 [=======>......................] - ETA: 15:45 - loss: 0.2592 - accuracy: 0.9210 Step 651: Train Accuracy = 0.9211\n 651/2197 [=======>......................] - ETA: 15:45 - loss: 0.2590 - accuracy: 0.9211 Step 652: Train Accuracy = 0.9212\n 652/2197 [=======>......................] - ETA: 15:44 - loss: 0.2587 - accuracy: 0.9212 Step 653: Train Accuracy = 0.9212\n 653/2197 [=======>......................] - ETA: 15:43 - loss: 0.2591 - accuracy: 0.9212 Step 654: Train Accuracy = 0.9213\n 654/2197 [=======>......................] - ETA: 15:43 - loss: 0.2589 - accuracy: 0.9213 Step 655: Train Accuracy = 0.9213\n 655/2197 [=======>......................] - ETA: 15:42 - loss: 0.2586 - accuracy: 0.9213 Step 656: Train Accuracy = 0.9215\n 656/2197 [=======>......................] - ETA: 15:42 - loss: 0.2583 - accuracy: 0.9215 Step 657: Train Accuracy = 0.9215\n 657/2197 [=======>......................] - ETA: 15:41 - loss: 0.2580 - accuracy: 0.9215 Step 658: Train Accuracy = 0.9216\n 658/2197 [=======>......................] - ETA: 15:40 - loss: 0.2578 - accuracy: 0.9216 Step 659: Train Accuracy = 0.9217\n 659/2197 [=======>......................] - ETA: 15:39 - loss: 0.2575 - accuracy: 0.9217 Step 660: Train Accuracy = 0.9215\n 660/2197 [========>.....................] - ETA: 15:39 - loss: 0.2580 - accuracy: 0.9215 Step 661: Train Accuracy = 0.9216\n 661/2197 [========>.....................] - ETA: 15:38 - loss: 0.2578 - accuracy: 0.9216 Step 662: Train Accuracy = 0.9216\n 662/2197 [========>.....................] - ETA: 15:38 - loss: 0.2577 - accuracy: 0.9216 Step 663: Train Accuracy = 0.9217\n 663/2197 [========>.....................] - ETA: 15:37 - loss: 0.2573 - accuracy: 0.9217 Step 664: Train Accuracy = 0.9218\n 664/2197 [========>.....................] - ETA: 15:37 - loss: 0.2570 - accuracy: 0.9218 Step 665: Train Accuracy = 0.9219\n 665/2197 [========>.....................] - ETA: 15:36 - loss: 0.2566 - accuracy: 0.9219 Step 666: Train Accuracy = 0.9218\n 666/2197 [========>.....................] - ETA: 15:36 - loss: 0.2568 - accuracy: 0.9218 Step 667: Train Accuracy = 0.9218\n 667/2197 [========>.....................] - ETA: 15:35 - loss: 0.2568 - accuracy: 0.9218 Step 668: Train Accuracy = 0.9219\n 668/2197 [========>.....................] - ETA: 15:34 - loss: 0.2566 - accuracy: 0.9219 Step 669: Train Accuracy = 0.9220\n 669/2197 [========>.....................] - ETA: 15:34 - loss: 0.2562 - accuracy: 0.9220 Step 670: Train Accuracy = 0.9220\n 670/2197 [========>.....................] - ETA: 15:33 - loss: 0.2563 - accuracy: 0.9220 Step 671: Train Accuracy = 0.9221\n 671/2197 [========>.....................] - ETA: 15:33 - loss: 0.2561 - accuracy: 0.9221 Step 672: Train Accuracy = 0.9221\n 672/2197 [========>.....................] - ETA: 15:32 - loss: 0.2559 - accuracy: 0.9221 Step 673: Train Accuracy = 0.9221\n 673/2197 [========>.....................] - ETA: 15:32 - loss: 0.2561 - accuracy: 0.9221 Step 674: Train Accuracy = 0.9222\n 674/2197 [========>.....................] - ETA: 15:31 - loss: 0.2557 - accuracy: 0.9222 Step 675: Train Accuracy = 0.9222\n 675/2197 [========>.....................] - ETA: 15:30 - loss: 0.2556 - accuracy: 0.9222 Step 676: Train Accuracy = 0.9222\n 676/2197 [========>.....................] - ETA: 15:30 - loss: 0.2554 - accuracy: 0.9222 Step 677: Train Accuracy = 0.9221\n 677/2197 [========>.....................] - ETA: 15:29 - loss: 0.2554 - accuracy: 0.9221 Step 678: Train Accuracy = 0.9221\n 678/2197 [========>.....................] - ETA: 15:29 - loss: 0.2552 - accuracy: 0.9221 Step 679: Train Accuracy = 0.9222\n 679/2197 [========>.....................] - ETA: 15:28 - loss: 0.2549 - accuracy: 0.9222 Step 680: Train Accuracy = 0.9223\n 680/2197 [========>.....................] - ETA: 15:28 - loss: 0.2547 - accuracy: 0.9223 Step 681: Train Accuracy = 0.9224\n 681/2197 [========>.....................] - ETA: 15:27 - loss: 0.2545 - accuracy: 0.9224 Step 682: Train Accuracy = 0.9224\n 682/2197 [========>.....................] - ETA: 15:27 - loss: 0.2546 - accuracy: 0.9224 Step 683: Train Accuracy = 0.9223\n 683/2197 [========>.....................] - ETA: 15:26 - loss: 0.2545 - accuracy: 0.9223 Step 684: Train Accuracy = 0.9223\n 684/2197 [========>.....................] - ETA: 15:25 - loss: 0.2543 - accuracy: 0.9223 Step 685: Train Accuracy = 0.9223\n 685/2197 [========>.....................] - ETA: 15:25 - loss: 0.2542 - accuracy: 0.9223 Step 686: Train Accuracy = 0.9223\n 686/2197 [========>.....................] - ETA: 15:25 - loss: 0.2540 - accuracy: 0.9223 Step 687: Train Accuracy = 0.9223\n 687/2197 [========>.....................] - ETA: 15:24 - loss: 0.2544 - accuracy: 0.9223 Step 688: Train Accuracy = 0.9224\n 688/2197 [========>.....................] - ETA: 15:23 - loss: 0.2541 - accuracy: 0.9224 Step 689: Train Accuracy = 0.9225\n 689/2197 [========>.....................] - ETA: 15:23 - loss: 0.2538 - accuracy: 0.9225 Step 690: Train Accuracy = 0.9226\n 690/2197 [========>.....................] - ETA: 15:22 - loss: 0.2536 - accuracy: 0.9226 Step 691: Train Accuracy = 0.9226\n 691/2197 [========>.....................] - ETA: 15:22 - loss: 0.2534 - accuracy: 0.9226 Step 692: Train Accuracy = 0.9227\n 692/2197 [========>.....................] - ETA: 15:21 - loss: 0.2531 - accuracy: 0.9227 Step 693: Train Accuracy = 0.9229\n 693/2197 [========>.....................] - ETA: 15:20 - loss: 0.2528 - accuracy: 0.9229 Step 694: Train Accuracy = 0.9229\n 694/2197 [========>.....................] - ETA: 15:20 - loss: 0.2528 - accuracy: 0.9229 Step 695: Train Accuracy = 0.9229\n 695/2197 [========>.....................] - ETA: 15:19 - loss: 0.2525 - accuracy: 0.9229 Step 696: Train Accuracy = 0.9229\n 696/2197 [========>.....................] - ETA: 15:19 - loss: 0.2525 - accuracy: 0.9229 Step 697: Train Accuracy = 0.9230\n 697/2197 [========>.....................] - ETA: 15:18 - loss: 0.2522 - accuracy: 0.9230 Step 698: Train Accuracy = 0.9231\n 698/2197 [========>.....................] - ETA: 15:17 - loss: 0.2520 - accuracy: 0.9231 Step 699: Train Accuracy = 0.9232\n 699/2197 [========>.....................] - ETA: 15:16 - loss: 0.2518 - accuracy: 0.9232 Step 700: Train Accuracy = 0.9231\n 700/2197 [========>.....................] - ETA: 15:15 - loss: 0.2518 - accuracy: 0.9231 Step 701: Train Accuracy = 0.9231\n 701/2197 [========>.....................] - ETA: 15:15 - loss: 0.2516 - accuracy: 0.9231 Step 702: Train Accuracy = 0.9232\n 702/2197 [========>.....................] - ETA: 15:14 - loss: 0.2513 - accuracy: 0.9232 Step 703: Train Accuracy = 0.9233\n 703/2197 [========>.....................] - ETA: 15:14 - loss: 0.2511 - accuracy: 0.9233 Step 704: Train Accuracy = 0.9233\n 704/2197 [========>.....................] - ETA: 15:13 - loss: 0.2510 - accuracy: 0.9233 Step 705: Train Accuracy = 0.9233\n 705/2197 [========>.....................] - ETA: 15:12 - loss: 0.2509 - accuracy: 0.9233 Step 706: Train Accuracy = 0.9233\n 706/2197 [========>.....................] - ETA: 15:11 - loss: 0.2508 - accuracy: 0.9233 Step 707: Train Accuracy = 0.9232\n 707/2197 [========>.....................] - ETA: 15:11 - loss: 0.2510 - accuracy: 0.9232 Step 708: Train Accuracy = 0.9232\n 708/2197 [========>.....................] - ETA: 15:10 - loss: 0.2508 - accuracy: 0.9232 Step 709: Train Accuracy = 0.9232\n 709/2197 [========>.....................] - ETA: 15:09 - loss: 0.2507 - accuracy: 0.9232 Step 710: Train Accuracy = 0.9233\n 710/2197 [========>.....................] - ETA: 15:08 - loss: 0.2505 - accuracy: 0.9233 Step 711: Train Accuracy = 0.9234\n 711/2197 [========>.....................] - ETA: 15:07 - loss: 0.2502 - accuracy: 0.9234 Step 712: Train Accuracy = 0.9233\n 712/2197 [========>.....................] - ETA: 15:07 - loss: 0.2509 - accuracy: 0.9233 Step 713: Train Accuracy = 0.9234\n 713/2197 [========>.....................] - ETA: 15:06 - loss: 0.2507 - accuracy: 0.9234 Step 714: Train Accuracy = 0.9234\n 714/2197 [========>.....................] - ETA: 15:05 - loss: 0.2506 - accuracy: 0.9234 Step 715: Train Accuracy = 0.9234\n 715/2197 [========>.....................] - ETA: 15:05 - loss: 0.2505 - accuracy: 0.9234 Step 716: Train Accuracy = 0.9235\n 716/2197 [========>.....................] - ETA: 15:04 - loss: 0.2502 - accuracy: 0.9235 Step 717: Train Accuracy = 0.9235\n 717/2197 [========>.....................] - ETA: 15:04 - loss: 0.2500 - accuracy: 0.9235 Step 718: Train Accuracy = 0.9235\n 718/2197 [========>.....................] - ETA: 15:03 - loss: 0.2498 - accuracy: 0.9235 Step 719: Train Accuracy = 0.9235\n 719/2197 [========>.....................] - ETA: 15:03 - loss: 0.2498 - accuracy: 0.9235 Step 720: Train Accuracy = 0.9236\n 720/2197 [========>.....................] - ETA: 15:02 - loss: 0.2497 - accuracy: 0.9236 Step 721: Train Accuracy = 0.9236\n 721/2197 [========>.....................] - ETA: 15:01 - loss: 0.2495 - accuracy: 0.9236 Step 722: Train Accuracy = 0.9237\n 722/2197 [========>.....................] - ETA: 15:01 - loss: 0.2493 - accuracy: 0.9237 Step 723: Train Accuracy = 0.9237\n 723/2197 [========>.....................] - ETA: 15:00 - loss: 0.2490 - accuracy: 0.9237 Step 724: Train Accuracy = 0.9237\n 724/2197 [========>.....................] - ETA: 14:59 - loss: 0.2493 - accuracy: 0.9237 Step 725: Train Accuracy = 0.9237\n 725/2197 [========>.....................] - ETA: 14:59 - loss: 0.2492 - accuracy: 0.9237 Step 726: Train Accuracy = 0.9237\n 726/2197 [========>.....................] - ETA: 14:58 - loss: 0.2491 - accuracy: 0.9237 Step 727: Train Accuracy = 0.9238\n 727/2197 [========>.....................] - ETA: 14:57 - loss: 0.2488 - accuracy: 0.9238 Step 728: Train Accuracy = 0.9239\n 728/2197 [========>.....................] - ETA: 14:57 - loss: 0.2487 - accuracy: 0.9239 Step 729: Train Accuracy = 0.9238\n 729/2197 [========>.....................] - ETA: 14:56 - loss: 0.2486 - accuracy: 0.9238 Step 730: Train Accuracy = 0.9239\n 730/2197 [========>.....................] - ETA: 14:56 - loss: 0.2486 - accuracy: 0.9239 Step 731: Train Accuracy = 0.9239\n 731/2197 [========>.....................] - ETA: 14:55 - loss: 0.2484 - accuracy: 0.9239 Step 732: Train Accuracy = 0.9239\n 732/2197 [========>.....................] - ETA: 14:55 - loss: 0.2483 - accuracy: 0.9239 Step 733: Train Accuracy = 0.9240\n 733/2197 [=========>....................] - ETA: 14:54 - loss: 0.2480 - accuracy: 0.9240 Step 734: Train Accuracy = 0.9241\n 734/2197 [=========>....................] - ETA: 14:54 - loss: 0.2479 - accuracy: 0.9241 Step 735: Train Accuracy = 0.9242\n 735/2197 [=========>....................] - ETA: 14:53 - loss: 0.2477 - accuracy: 0.9242 Step 736: Train Accuracy = 0.9242\n 736/2197 [=========>....................] - ETA: 14:52 - loss: 0.2474 - accuracy: 0.9242 Step 737: Train Accuracy = 0.9243\n 737/2197 [=========>....................] - ETA: 14:52 - loss: 0.2472 - accuracy: 0.9243 Step 738: Train Accuracy = 0.9243\n 738/2197 [=========>....................] - ETA: 14:51 - loss: 0.2470 - accuracy: 0.9243 Step 739: Train Accuracy = 0.9244\n 739/2197 [=========>....................] - ETA: 14:51 - loss: 0.2468 - accuracy: 0.9244 Step 740: Train Accuracy = 0.9244\n 740/2197 [=========>....................] - ETA: 14:51 - loss: 0.2466 - accuracy: 0.9244 Step 741: Train Accuracy = 0.9245\n 741/2197 [=========>....................] - ETA: 14:50 - loss: 0.2464 - accuracy: 0.9245 Step 742: Train Accuracy = 0.9245\n 742/2197 [=========>....................] - ETA: 14:50 - loss: 0.2462 - accuracy: 0.9245 Step 743: Train Accuracy = 0.9245\n 743/2197 [=========>....................] - ETA: 14:49 - loss: 0.2462 - accuracy: 0.9245 Step 744: Train Accuracy = 0.9245\n 744/2197 [=========>....................] - ETA: 14:49 - loss: 0.2460 - accuracy: 0.9245 Step 745: Train Accuracy = 0.9246\n 745/2197 [=========>....................] - ETA: 14:48 - loss: 0.2458 - accuracy: 0.9246 Step 746: Train Accuracy = 0.9247\n 746/2197 [=========>....................] - ETA: 14:48 - loss: 0.2457 - accuracy: 0.9247 Step 747: Train Accuracy = 0.9248\n 747/2197 [=========>....................] - ETA: 14:47 - loss: 0.2454 - accuracy: 0.9248 Step 748: Train Accuracy = 0.9249\n 748/2197 [=========>....................] - ETA: 14:46 - loss: 0.2452 - accuracy: 0.9249 Step 749: Train Accuracy = 0.9248\n 749/2197 [=========>....................] - ETA: 14:46 - loss: 0.2452 - accuracy: 0.9248 Step 750: Train Accuracy = 0.9249\n 750/2197 [=========>....................] - ETA: 14:45 - loss: 0.2449 - accuracy: 0.9249 Step 751: Train Accuracy = 0.9249\n 751/2197 [=========>....................] - ETA: 14:44 - loss: 0.2450 - accuracy: 0.9249 Step 752: Train Accuracy = 0.9249\n 752/2197 [=========>....................] - ETA: 14:44 - loss: 0.2450 - accuracy: 0.9249 Step 753: Train Accuracy = 0.9250\n 753/2197 [=========>....................] - ETA: 14:43 - loss: 0.2448 - accuracy: 0.9250 Step 754: Train Accuracy = 0.9250\n 754/2197 [=========>....................] - ETA: 14:42 - loss: 0.2448 - accuracy: 0.9250 Step 755: Train Accuracy = 0.9251\n 755/2197 [=========>....................] - ETA: 14:42 - loss: 0.2446 - accuracy: 0.9251 Step 756: Train Accuracy = 0.9252\n 756/2197 [=========>....................] - ETA: 14:41 - loss: 0.2446 - accuracy: 0.9252 Step 757: Train Accuracy = 0.9253\n 757/2197 [=========>....................] - ETA: 14:41 - loss: 0.2443 - accuracy: 0.9253 Step 758: Train Accuracy = 0.9254\n 758/2197 [=========>....................] - ETA: 14:40 - loss: 0.2441 - accuracy: 0.9254 Step 759: Train Accuracy = 0.9254\n 759/2197 [=========>....................] - ETA: 14:39 - loss: 0.2438 - accuracy: 0.9254 Step 760: Train Accuracy = 0.9255\n 760/2197 [=========>....................] - ETA: 14:39 - loss: 0.2439 - accuracy: 0.9255 Step 761: Train Accuracy = 0.9255\n 761/2197 [=========>....................] - ETA: 14:38 - loss: 0.2440 - accuracy: 0.9255 Step 762: Train Accuracy = 0.9255\n 762/2197 [=========>....................] - ETA: 14:37 - loss: 0.2439 - accuracy: 0.9255 Step 763: Train Accuracy = 0.9256\n 763/2197 [=========>....................] - ETA: 14:37 - loss: 0.2437 - accuracy: 0.9256 Step 764: Train Accuracy = 0.9257\n 764/2197 [=========>....................] - ETA: 14:36 - loss: 0.2435 - accuracy: 0.9257 Step 765: Train Accuracy = 0.9257\n 765/2197 [=========>....................] - ETA: 14:35 - loss: 0.2433 - accuracy: 0.9257 Step 766: Train Accuracy = 0.9258\n 766/2197 [=========>....................] - ETA: 14:34 - loss: 0.2430 - accuracy: 0.9258 Step 767: Train Accuracy = 0.9259\n 767/2197 [=========>....................] - ETA: 14:33 - loss: 0.2427 - accuracy: 0.9259 Step 768: Train Accuracy = 0.9258\n 768/2197 [=========>....................] - ETA: 14:33 - loss: 0.2428 - accuracy: 0.9258 Step 769: Train Accuracy = 0.9259\n 769/2197 [=========>....................] - ETA: 14:32 - loss: 0.2426 - accuracy: 0.9259 Step 770: Train Accuracy = 0.9259\n 770/2197 [=========>....................] - ETA: 14:31 - loss: 0.2425 - accuracy: 0.9259 Step 771: Train Accuracy = 0.9259\n 771/2197 [=========>....................] - ETA: 14:31 - loss: 0.2423 - accuracy: 0.9259 Step 772: Train Accuracy = 0.9260\n 772/2197 [=========>....................] - ETA: 14:30 - loss: 0.2420 - accuracy: 0.9260 Step 773: Train Accuracy = 0.9260\n 773/2197 [=========>....................] - ETA: 14:29 - loss: 0.2419 - accuracy: 0.9260 Step 774: Train Accuracy = 0.9261\n 774/2197 [=========>....................] - ETA: 14:29 - loss: 0.2416 - accuracy: 0.9261 Step 775: Train Accuracy = 0.9261\n 775/2197 [=========>....................] - ETA: 14:28 - loss: 0.2416 - accuracy: 0.9261 Step 776: Train Accuracy = 0.9262\n 776/2197 [=========>....................] - ETA: 14:27 - loss: 0.2415 - accuracy: 0.9262 Step 777: Train Accuracy = 0.9261\n 777/2197 [=========>....................] - ETA: 14:27 - loss: 0.2419 - accuracy: 0.9261 Step 778: Train Accuracy = 0.9261\n 778/2197 [=========>....................] - ETA: 14:26 - loss: 0.2419 - accuracy: 0.9261 Step 779: Train Accuracy = 0.9260\n 779/2197 [=========>....................] - ETA: 14:26 - loss: 0.2421 - accuracy: 0.9260 Step 780: Train Accuracy = 0.9261\n 780/2197 [=========>....................] - ETA: 14:25 - loss: 0.2420 - accuracy: 0.9261 Step 781: Train Accuracy = 0.9261\n 781/2197 [=========>....................] - ETA: 14:24 - loss: 0.2418 - accuracy: 0.9261 Step 782: Train Accuracy = 0.9261\n 782/2197 [=========>....................] - ETA: 14:24 - loss: 0.2421 - accuracy: 0.9261 Step 783: Train Accuracy = 0.9261\n 783/2197 [=========>....................] - ETA: 14:23 - loss: 0.2419 - accuracy: 0.9261 Step 784: Train Accuracy = 0.9262\n 784/2197 [=========>....................] - ETA: 14:23 - loss: 0.2417 - accuracy: 0.9262 Step 785: Train Accuracy = 0.9262\n 785/2197 [=========>....................] - ETA: 14:22 - loss: 0.2417 - accuracy: 0.9262 Step 786: Train Accuracy = 0.9263\n 786/2197 [=========>....................] - ETA: 14:22 - loss: 0.2415 - accuracy: 0.9263 Step 787: Train Accuracy = 0.9263\n 787/2197 [=========>....................] - ETA: 14:21 - loss: 0.2414 - accuracy: 0.9263 Step 788: Train Accuracy = 0.9263\n 788/2197 [=========>....................] - ETA: 14:20 - loss: 0.2412 - accuracy: 0.9263 Step 789: Train Accuracy = 0.9263\n 789/2197 [=========>....................] - ETA: 14:20 - loss: 0.2415 - accuracy: 0.9263 Step 790: Train Accuracy = 0.9263\n 790/2197 [=========>....................] - ETA: 14:19 - loss: 0.2413 - accuracy: 0.9263 Step 791: Train Accuracy = 0.9263\n 791/2197 [=========>....................] - ETA: 14:19 - loss: 0.2414 - accuracy: 0.9263 Step 792: Train Accuracy = 0.9264\n 792/2197 [=========>....................] - ETA: 14:18 - loss: 0.2411 - accuracy: 0.9264 Step 793: Train Accuracy = 0.9264\n 793/2197 [=========>....................] - ETA: 14:17 - loss: 0.2411 - accuracy: 0.9264 Step 794: Train Accuracy = 0.9265\n 794/2197 [=========>....................] - ETA: 14:17 - loss: 0.2408 - accuracy: 0.9265 Step 795: Train Accuracy = 0.9265\n 795/2197 [=========>....................] - ETA: 14:16 - loss: 0.2407 - accuracy: 0.9265 Step 796: Train Accuracy = 0.9266\n 796/2197 [=========>....................] - ETA: 14:16 - loss: 0.2406 - accuracy: 0.9266 Step 797: Train Accuracy = 0.9266\n 797/2197 [=========>....................] - ETA: 14:15 - loss: 0.2405 - accuracy: 0.9266 Step 798: Train Accuracy = 0.9267\n 798/2197 [=========>....................] - ETA: 14:15 - loss: 0.2403 - accuracy: 0.9267 Step 799: Train Accuracy = 0.9266\n 799/2197 [=========>....................] - ETA: 14:14 - loss: 0.2403 - accuracy: 0.9266 Step 800: Train Accuracy = 0.9267\n 800/2197 [=========>....................] - ETA: 14:13 - loss: 0.2401 - accuracy: 0.9267 Step 801: Train Accuracy = 0.9268\n 801/2197 [=========>....................] - ETA: 14:12 - loss: 0.2398 - accuracy: 0.9268 Step 802: Train Accuracy = 0.9268\n 802/2197 [=========>....................] - ETA: 14:12 - loss: 0.2398 - accuracy: 0.9268 Step 803: Train Accuracy = 0.9268\n 803/2197 [=========>....................] - ETA: 14:11 - loss: 0.2399 - accuracy: 0.9268 Step 804: Train Accuracy = 0.9268\n 804/2197 [=========>....................] - ETA: 14:10 - loss: 0.2397 - accuracy: 0.9268 Step 805: Train Accuracy = 0.9269\n 805/2197 [=========>....................] - ETA: 14:10 - loss: 0.2395 - accuracy: 0.9269 Step 806: Train Accuracy = 0.9269\n 806/2197 [==========>...................] - ETA: 14:09 - loss: 0.2393 - accuracy: 0.9269 Step 807: Train Accuracy = 0.9269\n 807/2197 [==========>...................] - ETA: 14:09 - loss: 0.2392 - accuracy: 0.9269 Step 808: Train Accuracy = 0.9270\n 808/2197 [==========>...................] - ETA: 14:08 - loss: 0.2390 - accuracy: 0.9270 Step 809: Train Accuracy = 0.9271\n 809/2197 [==========>...................] - ETA: 14:08 - loss: 0.2388 - accuracy: 0.9271 Step 810: Train Accuracy = 0.9271\n 810/2197 [==========>...................] - ETA: 14:07 - loss: 0.2386 - accuracy: 0.9271 Step 811: Train Accuracy = 0.9272\n 811/2197 [==========>...................] - ETA: 14:07 - loss: 0.2383 - accuracy: 0.9272 Step 812: Train Accuracy = 0.9271\n 812/2197 [==========>...................] - ETA: 14:06 - loss: 0.2384 - accuracy: 0.9271 Step 813: Train Accuracy = 0.9271\n 813/2197 [==========>...................] - ETA: 14:05 - loss: 0.2383 - accuracy: 0.9271 Step 814: Train Accuracy = 0.9271\n 814/2197 [==========>...................] - ETA: 14:05 - loss: 0.2382 - accuracy: 0.9271 Step 815: Train Accuracy = 0.9272\n 815/2197 [==========>...................] - ETA: 14:04 - loss: 0.2379 - accuracy: 0.9272 Step 816: Train Accuracy = 0.9272\n 816/2197 [==========>...................] - ETA: 14:03 - loss: 0.2379 - accuracy: 0.9272 Step 817: Train Accuracy = 0.9273\n 817/2197 [==========>...................] - ETA: 14:03 - loss: 0.2379 - accuracy: 0.9273 Step 818: Train Accuracy = 0.9272\n 818/2197 [==========>...................] - ETA: 14:02 - loss: 0.2381 - accuracy: 0.9272 Step 819: Train Accuracy = 0.9272\n 819/2197 [==========>...................] - ETA: 14:01 - loss: 0.2378 - accuracy: 0.9272 Step 820: Train Accuracy = 0.9272\n 820/2197 [==========>...................] - ETA: 14:00 - loss: 0.2378 - accuracy: 0.9272 Step 821: Train Accuracy = 0.9272\n 821/2197 [==========>...................] - ETA: 14:00 - loss: 0.2377 - accuracy: 0.9272 Step 822: Train Accuracy = 0.9272\n 822/2197 [==========>...................] - ETA: 13:59 - loss: 0.2375 - accuracy: 0.9272 Step 823: Train Accuracy = 0.9273\n 823/2197 [==========>...................] - ETA: 13:59 - loss: 0.2374 - accuracy: 0.9273 Step 824: Train Accuracy = 0.9273\n 824/2197 [==========>...................] - ETA: 13:58 - loss: 0.2372 - accuracy: 0.9273 Step 825: Train Accuracy = 0.9274\n 825/2197 [==========>...................] - ETA: 13:57 - loss: 0.2370 - accuracy: 0.9274 Step 826: Train Accuracy = 0.9274\n 826/2197 [==========>...................] - ETA: 13:57 - loss: 0.2368 - accuracy: 0.9274 Step 827: Train Accuracy = 0.9275\n 827/2197 [==========>...................] - ETA: 13:56 - loss: 0.2366 - accuracy: 0.9275 Step 828: Train Accuracy = 0.9275\n 828/2197 [==========>...................] - ETA: 13:56 - loss: 0.2366 - accuracy: 0.9275 Step 829: Train Accuracy = 0.9275\n 829/2197 [==========>...................] - ETA: 13:55 - loss: 0.2365 - accuracy: 0.9275 Step 830: Train Accuracy = 0.9275\n 830/2197 [==========>...................] - ETA: 13:54 - loss: 0.2366 - accuracy: 0.9275 Step 831: Train Accuracy = 0.9275\n 831/2197 [==========>...................] - ETA: 13:54 - loss: 0.2365 - accuracy: 0.9275 Step 832: Train Accuracy = 0.9275\n 832/2197 [==========>...................] - ETA: 13:53 - loss: 0.2364 - accuracy: 0.9275 Step 833: Train Accuracy = 0.9276\n 833/2197 [==========>...................] - ETA: 13:53 - loss: 0.2361 - accuracy: 0.9276 Step 834: Train Accuracy = 0.9277\n 834/2197 [==========>...................] - ETA: 13:52 - loss: 0.2359 - accuracy: 0.9277 Step 835: Train Accuracy = 0.9277\n 835/2197 [==========>...................] - ETA: 13:52 - loss: 0.2358 - accuracy: 0.9277 Step 836: Train Accuracy = 0.9278\n 836/2197 [==========>...................] - ETA: 13:51 - loss: 0.2356 - accuracy: 0.9278 Step 837: Train Accuracy = 0.9278\n 837/2197 [==========>...................] - ETA: 13:51 - loss: 0.2354 - accuracy: 0.9278 Step 838: Train Accuracy = 0.9279\n 838/2197 [==========>...................] - ETA: 13:50 - loss: 0.2351 - accuracy: 0.9279 Step 839: Train Accuracy = 0.9280\n 839/2197 [==========>...................] - ETA: 13:49 - loss: 0.2349 - accuracy: 0.9280 Step 840: Train Accuracy = 0.9280\n 840/2197 [==========>...................] - ETA: 13:49 - loss: 0.2348 - accuracy: 0.9280 Step 841: Train Accuracy = 0.9281\n 841/2197 [==========>...................] - ETA: 13:48 - loss: 0.2346 - accuracy: 0.9281 Step 842: Train Accuracy = 0.9281\n 842/2197 [==========>...................] - ETA: 13:48 - loss: 0.2347 - accuracy: 0.9281 Step 843: Train Accuracy = 0.9281\n 843/2197 [==========>...................] - ETA: 13:47 - loss: 0.2345 - accuracy: 0.9281 Step 844: Train Accuracy = 0.9281\n 844/2197 [==========>...................] - ETA: 13:46 - loss: 0.2346 - accuracy: 0.9281 Step 845: Train Accuracy = 0.9282\n 845/2197 [==========>...................] - ETA: 13:46 - loss: 0.2343 - accuracy: 0.9282 Step 846: Train Accuracy = 0.9283\n 846/2197 [==========>...................] - ETA: 13:45 - loss: 0.2340 - accuracy: 0.9283 Step 847: Train Accuracy = 0.9283\n 847/2197 [==========>...................] - ETA: 13:45 - loss: 0.2339 - accuracy: 0.9283 Step 848: Train Accuracy = 0.9283\n 848/2197 [==========>...................] - ETA: 13:44 - loss: 0.2338 - accuracy: 0.9283 Step 849: Train Accuracy = 0.9284\n 849/2197 [==========>...................] - ETA: 13:44 - loss: 0.2337 - accuracy: 0.9284 Step 850: Train Accuracy = 0.9284\n 850/2197 [==========>...................] - ETA: 13:43 - loss: 0.2335 - accuracy: 0.9284 Step 851: Train Accuracy = 0.9284\n 851/2197 [==========>...................] - ETA: 13:42 - loss: 0.2335 - accuracy: 0.9284 Step 852: Train Accuracy = 0.9285\n 852/2197 [==========>...................] - ETA: 13:41 - loss: 0.2332 - accuracy: 0.9285 Step 853: Train Accuracy = 0.9286\n 853/2197 [==========>...................] - ETA: 13:41 - loss: 0.2331 - accuracy: 0.9286 Step 854: Train Accuracy = 0.9286\n 854/2197 [==========>...................] - ETA: 13:40 - loss: 0.2329 - accuracy: 0.9286 Step 855: Train Accuracy = 0.9286\n 855/2197 [==========>...................] - ETA: 13:40 - loss: 0.2331 - accuracy: 0.9286 Step 856: Train Accuracy = 0.9285\n 856/2197 [==========>...................] - ETA: 13:39 - loss: 0.2332 - accuracy: 0.9285 Step 857: Train Accuracy = 0.9285\n 857/2197 [==========>...................] - ETA: 13:38 - loss: 0.2331 - accuracy: 0.9285 Step 858: Train Accuracy = 0.9285\n 858/2197 [==========>...................] - ETA: 13:38 - loss: 0.2329 - accuracy: 0.9285 Step 859: Train Accuracy = 0.9286\n 859/2197 [==========>...................] - ETA: 13:37 - loss: 0.2326 - accuracy: 0.9286 Step 860: Train Accuracy = 0.9286\n 860/2197 [==========>...................] - ETA: 13:37 - loss: 0.2327 - accuracy: 0.9286 Step 861: Train Accuracy = 0.9286\n 861/2197 [==========>...................] - ETA: 13:36 - loss: 0.2326 - accuracy: 0.9286 Step 862: Train Accuracy = 0.9286\n 862/2197 [==========>...................] - ETA: 13:36 - loss: 0.2324 - accuracy: 0.9286 Step 863: Train Accuracy = 0.9287\n 863/2197 [==========>...................] - ETA: 13:35 - loss: 0.2322 - accuracy: 0.9287 Step 864: Train Accuracy = 0.9288\n 864/2197 [==========>...................] - ETA: 13:34 - loss: 0.2320 - accuracy: 0.9288 Step 865: Train Accuracy = 0.9288\n 865/2197 [==========>...................] - ETA: 13:34 - loss: 0.2318 - accuracy: 0.9288 Step 866: Train Accuracy = 0.9289\n 866/2197 [==========>...................] - ETA: 13:33 - loss: 0.2317 - accuracy: 0.9289 Step 867: Train Accuracy = 0.9288\n 867/2197 [==========>...................] - ETA: 13:32 - loss: 0.2316 - accuracy: 0.9288 Step 868: Train Accuracy = 0.9289\n 868/2197 [==========>...................] - ETA: 13:32 - loss: 0.2314 - accuracy: 0.9289 Step 869: Train Accuracy = 0.9290\n 869/2197 [==========>...................] - ETA: 13:31 - loss: 0.2312 - accuracy: 0.9290 Step 870: Train Accuracy = 0.9290\n 870/2197 [==========>...................] - ETA: 13:31 - loss: 0.2310 - accuracy: 0.9290 Step 871: Train Accuracy = 0.9291\n 871/2197 [==========>...................] - ETA: 13:30 - loss: 0.2309 - accuracy: 0.9291 Step 872: Train Accuracy = 0.9291\n 872/2197 [==========>...................] - ETA: 13:30 - loss: 0.2307 - accuracy: 0.9291 Step 873: Train Accuracy = 0.9291\n 873/2197 [==========>...................] - ETA: 13:29 - loss: 0.2307 - accuracy: 0.9291 Step 874: Train Accuracy = 0.9291\n 874/2197 [==========>...................] - ETA: 13:28 - loss: 0.2307 - accuracy: 0.9291 Step 875: Train Accuracy = 0.9292\n 875/2197 [==========>...................] - ETA: 13:28 - loss: 0.2307 - accuracy: 0.9292 Step 876: Train Accuracy = 0.9291\n 876/2197 [==========>...................] - ETA: 13:27 - loss: 0.2309 - accuracy: 0.9291 Step 877: Train Accuracy = 0.9290\n 877/2197 [==========>...................] - ETA: 13:26 - loss: 0.2310 - accuracy: 0.9290 Step 878: Train Accuracy = 0.9290\n 878/2197 [==========>...................] - ETA: 13:26 - loss: 0.2316 - accuracy: 0.9290 Step 879: Train Accuracy = 0.9291\n 879/2197 [===========>..................] - ETA: 13:25 - loss: 0.2314 - accuracy: 0.9291 Step 880: Train Accuracy = 0.9290\n 880/2197 [===========>..................] - ETA: 13:25 - loss: 0.2314 - accuracy: 0.9290 Step 881: Train Accuracy = 0.9290\n 881/2197 [===========>..................] - ETA: 13:24 - loss: 0.2312 - accuracy: 0.9290 Step 882: Train Accuracy = 0.9290\n 882/2197 [===========>..................] - ETA: 13:24 - loss: 0.2312 - accuracy: 0.9290 Step 883: Train Accuracy = 0.9291\n 883/2197 [===========>..................] - ETA: 13:23 - loss: 0.2311 - accuracy: 0.9291 Step 884: Train Accuracy = 0.9291\n 884/2197 [===========>..................] - ETA: 13:23 - loss: 0.2309 - accuracy: 0.9291 Step 885: Train Accuracy = 0.9291\n 885/2197 [===========>..................] - ETA: 13:22 - loss: 0.2311 - accuracy: 0.9291 Step 886: Train Accuracy = 0.9292\n 886/2197 [===========>..................] - ETA: 13:21 - loss: 0.2310 - accuracy: 0.9292 Step 887: Train Accuracy = 0.9292\n 887/2197 [===========>..................] - ETA: 13:21 - loss: 0.2310 - accuracy: 0.9292 Step 888: Train Accuracy = 0.9292\n 888/2197 [===========>..................] - ETA: 13:21 - loss: 0.2309 - accuracy: 0.9292 Step 889: Train Accuracy = 0.9293\n 889/2197 [===========>..................] - ETA: 13:20 - loss: 0.2308 - accuracy: 0.9293 Step 890: Train Accuracy = 0.9292\n 890/2197 [===========>..................] - ETA: 13:19 - loss: 0.2310 - accuracy: 0.9292 Step 891: Train Accuracy = 0.9293\n 891/2197 [===========>..................] - ETA: 13:18 - loss: 0.2308 - accuracy: 0.9293 Step 892: Train Accuracy = 0.9293\n 892/2197 [===========>..................] - ETA: 13:18 - loss: 0.2308 - accuracy: 0.9293 Step 893: Train Accuracy = 0.9293\n 893/2197 [===========>..................] - ETA: 13:17 - loss: 0.2307 - accuracy: 0.9293 Step 894: Train Accuracy = 0.9293\n 894/2197 [===========>..................] - ETA: 13:17 - loss: 0.2306 - accuracy: 0.9293 Step 895: Train Accuracy = 0.9293\n 895/2197 [===========>..................] - ETA: 13:16 - loss: 0.2306 - accuracy: 0.9293 Step 896: Train Accuracy = 0.9293\n 896/2197 [===========>..................] - ETA: 13:15 - loss: 0.2305 - accuracy: 0.9293 Step 897: Train Accuracy = 0.9293\n 897/2197 [===========>..................] - ETA: 13:15 - loss: 0.2305 - accuracy: 0.9293 Step 898: Train Accuracy = 0.9294\n 898/2197 [===========>..................] - ETA: 13:14 - loss: 0.2302 - accuracy: 0.9294 Step 899: Train Accuracy = 0.9294\n 899/2197 [===========>..................] - ETA: 13:14 - loss: 0.2303 - accuracy: 0.9294 Step 900: Train Accuracy = 0.9294\n 900/2197 [===========>..................] - ETA: 13:13 - loss: 0.2302 - accuracy: 0.9294 Step 901: Train Accuracy = 0.9294\n 901/2197 [===========>..................] - ETA: 13:13 - loss: 0.2301 - accuracy: 0.9294 Step 902: Train Accuracy = 0.9295\n 902/2197 [===========>..................] - ETA: 13:12 - loss: 0.2300 - accuracy: 0.9295 Step 903: Train Accuracy = 0.9296\n 903/2197 [===========>..................] - ETA: 13:11 - loss: 0.2298 - accuracy: 0.9296 Step 904: Train Accuracy = 0.9296\n 904/2197 [===========>..................] - ETA: 13:11 - loss: 0.2298 - accuracy: 0.9296 Step 905: Train Accuracy = 0.9296\n 905/2197 [===========>..................] - ETA: 13:10 - loss: 0.2296 - accuracy: 0.9296 Step 906: Train Accuracy = 0.9297\n 906/2197 [===========>..................] - ETA: 13:10 - loss: 0.2294 - accuracy: 0.9297 Step 907: Train Accuracy = 0.9297\n 907/2197 [===========>..................] - ETA: 13:09 - loss: 0.2293 - accuracy: 0.9297 Step 908: Train Accuracy = 0.9298\n 908/2197 [===========>..................] - ETA: 13:08 - loss: 0.2291 - accuracy: 0.9298 Step 909: Train Accuracy = 0.9298\n 909/2197 [===========>..................] - ETA: 13:08 - loss: 0.2292 - accuracy: 0.9298 Step 910: Train Accuracy = 0.9298\n 910/2197 [===========>..................] - ETA: 13:07 - loss: 0.2292 - accuracy: 0.9298 Step 911: Train Accuracy = 0.9298\n 911/2197 [===========>..................] - ETA: 13:07 - loss: 0.2291 - accuracy: 0.9298 Step 912: Train Accuracy = 0.9298\n 912/2197 [===========>..................] - ETA: 13:06 - loss: 0.2296 - accuracy: 0.9298 Step 913: Train Accuracy = 0.9297\n 913/2197 [===========>..................] - ETA: 13:06 - loss: 0.2295 - accuracy: 0.9297 Step 914: Train Accuracy = 0.9297\n 914/2197 [===========>..................] - ETA: 13:05 - loss: 0.2295 - accuracy: 0.9297 Step 915: Train Accuracy = 0.9297\n 915/2197 [===========>..................] - ETA: 13:04 - loss: 0.2294 - accuracy: 0.9297 Step 916: Train Accuracy = 0.9298\n 916/2197 [===========>..................] - ETA: 13:04 - loss: 0.2292 - accuracy: 0.9298 Step 917: Train Accuracy = 0.9298\n 917/2197 [===========>..................] - ETA: 13:03 - loss: 0.2290 - accuracy: 0.9298 Step 918: Train Accuracy = 0.9299\n 918/2197 [===========>..................] - ETA: 13:03 - loss: 0.2289 - accuracy: 0.9299 Step 919: Train Accuracy = 0.9300\n 919/2197 [===========>..................] - ETA: 13:02 - loss: 0.2286 - accuracy: 0.9300 Step 920: Train Accuracy = 0.9300\n 920/2197 [===========>..................] - ETA: 13:01 - loss: 0.2286 - accuracy: 0.9300 Step 921: Train Accuracy = 0.9300\n 921/2197 [===========>..................] - ETA: 13:01 - loss: 0.2286 - accuracy: 0.9300 Step 922: Train Accuracy = 0.9300\n 922/2197 [===========>..................] - ETA: 13:00 - loss: 0.2287 - accuracy: 0.9300 Step 923: Train Accuracy = 0.9300\n 923/2197 [===========>..................] - ETA: 13:00 - loss: 0.2286 - accuracy: 0.9300 Step 924: Train Accuracy = 0.9301\n 924/2197 [===========>..................] - ETA: 12:59 - loss: 0.2283 - accuracy: 0.9301 Step 925: Train Accuracy = 0.9302\n 925/2197 [===========>..................] - ETA: 12:59 - loss: 0.2281 - accuracy: 0.9302 Step 926: Train Accuracy = 0.9302\n 926/2197 [===========>..................] - ETA: 12:58 - loss: 0.2279 - accuracy: 0.9302 Step 927: Train Accuracy = 0.9303\n 927/2197 [===========>..................] - ETA: 12:58 - loss: 0.2278 - accuracy: 0.9303 Step 928: Train Accuracy = 0.9303\n 928/2197 [===========>..................] - ETA: 12:57 - loss: 0.2277 - accuracy: 0.9303 Step 929: Train Accuracy = 0.9304\n 929/2197 [===========>..................] - ETA: 12:56 - loss: 0.2275 - accuracy: 0.9304 Step 930: Train Accuracy = 0.9303\n 930/2197 [===========>..................] - ETA: 12:56 - loss: 0.2275 - accuracy: 0.9303 Step 931: Train Accuracy = 0.9303\n 931/2197 [===========>..................] - ETA: 12:55 - loss: 0.2273 - accuracy: 0.9303 Step 932: Train Accuracy = 0.9303\n 932/2197 [===========>..................] - ETA: 12:54 - loss: 0.2273 - accuracy: 0.9303 Step 933: Train Accuracy = 0.9303\n 933/2197 [===========>..................] - ETA: 12:54 - loss: 0.2271 - accuracy: 0.9303 Step 934: Train Accuracy = 0.9304\n 934/2197 [===========>..................] - ETA: 12:53 - loss: 0.2272 - accuracy: 0.9304 Step 935: Train Accuracy = 0.9304\n 935/2197 [===========>..................] - ETA: 12:52 - loss: 0.2272 - accuracy: 0.9304 Step 936: Train Accuracy = 0.9304\n 936/2197 [===========>..................] - ETA: 12:52 - loss: 0.2271 - accuracy: 0.9304 Step 937: Train Accuracy = 0.9304\n 937/2197 [===========>..................] - ETA: 12:51 - loss: 0.2269 - accuracy: 0.9304 Step 938: Train Accuracy = 0.9305\n 938/2197 [===========>..................] - ETA: 12:51 - loss: 0.2267 - accuracy: 0.9305 Step 939: Train Accuracy = 0.9305\n 939/2197 [===========>..................] - ETA: 12:50 - loss: 0.2266 - accuracy: 0.9305 Step 940: Train Accuracy = 0.9306\n 940/2197 [===========>..................] - ETA: 12:49 - loss: 0.2264 - accuracy: 0.9306 Step 941: Train Accuracy = 0.9306\n 941/2197 [===========>..................] - ETA: 12:49 - loss: 0.2262 - accuracy: 0.9306 Step 942: Train Accuracy = 0.9307\n 942/2197 [===========>..................] - ETA: 12:48 - loss: 0.2260 - accuracy: 0.9307 Step 943: Train Accuracy = 0.9307\n 943/2197 [===========>..................] - ETA: 12:47 - loss: 0.2260 - accuracy: 0.9307 Step 944: Train Accuracy = 0.9307\n 944/2197 [===========>..................] - ETA: 12:47 - loss: 0.2259 - accuracy: 0.9307 Step 945: Train Accuracy = 0.9308\n 945/2197 [===========>..................] - ETA: 12:46 - loss: 0.2257 - accuracy: 0.9308 Step 946: Train Accuracy = 0.9308\n 946/2197 [===========>..................] - ETA: 12:46 - loss: 0.2256 - accuracy: 0.9308 Step 947: Train Accuracy = 0.9308\n 947/2197 [===========>..................] - ETA: 12:45 - loss: 0.2254 - accuracy: 0.9308 Step 948: Train Accuracy = 0.9308\n 948/2197 [===========>..................] - ETA: 12:45 - loss: 0.2253 - accuracy: 0.9308 Step 949: Train Accuracy = 0.9308\n 949/2197 [===========>..................] - ETA: 12:44 - loss: 0.2253 - accuracy: 0.9308 Step 950: Train Accuracy = 0.9308\n 950/2197 [===========>..................] - ETA: 12:43 - loss: 0.2252 - accuracy: 0.9308 Step 951: Train Accuracy = 0.9309\n 951/2197 [===========>..................] - ETA: 12:43 - loss: 0.2251 - accuracy: 0.9309 Step 952: Train Accuracy = 0.9308\n 952/2197 [===========>..................] - ETA: 12:42 - loss: 0.2252 - accuracy: 0.9308 Step 953: Train Accuracy = 0.9309\n 953/2197 [============>.................] - ETA: 12:41 - loss: 0.2250 - accuracy: 0.9309 Step 954: Train Accuracy = 0.9309\n 954/2197 [============>.................] - ETA: 12:41 - loss: 0.2249 - accuracy: 0.9309 Step 955: Train Accuracy = 0.9309\n 955/2197 [============>.................] - ETA: 12:40 - loss: 0.2250 - accuracy: 0.9309 Step 956: Train Accuracy = 0.9309\n 956/2197 [============>.................] - ETA: 12:40 - loss: 0.2248 - accuracy: 0.9309 Step 957: Train Accuracy = 0.9310\n 957/2197 [============>.................] - ETA: 12:39 - loss: 0.2247 - accuracy: 0.9310 Step 958: Train Accuracy = 0.9309\n 958/2197 [============>.................] - ETA: 12:38 - loss: 0.2251 - accuracy: 0.9309 Step 959: Train Accuracy = 0.9310\n 959/2197 [============>.................] - ETA: 12:38 - loss: 0.2251 - accuracy: 0.9310 Step 960: Train Accuracy = 0.9310\n 960/2197 [============>.................] - ETA: 12:37 - loss: 0.2250 - accuracy: 0.9310 Step 961: Train Accuracy = 0.9310\n 961/2197 [============>.................] - ETA: 12:37 - loss: 0.2248 - accuracy: 0.9310 Step 962: Train Accuracy = 0.9311\n 962/2197 [============>.................] - ETA: 12:36 - loss: 0.2247 - accuracy: 0.9311 Step 963: Train Accuracy = 0.9311\n 963/2197 [============>.................] - ETA: 12:35 - loss: 0.2247 - accuracy: 0.9311 Step 964: Train Accuracy = 0.9311\n 964/2197 [============>.................] - ETA: 12:34 - loss: 0.2245 - accuracy: 0.9311 Step 965: Train Accuracy = 0.9311\n 965/2197 [============>.................] - ETA: 12:33 - loss: 0.2247 - accuracy: 0.9311 Step 966: Train Accuracy = 0.9311\n 966/2197 [============>.................] - ETA: 12:33 - loss: 0.2245 - accuracy: 0.9311 Step 967: Train Accuracy = 0.9312\n 967/2197 [============>.................] - ETA: 12:32 - loss: 0.2243 - accuracy: 0.9312 Step 968: Train Accuracy = 0.9312\n 968/2197 [============>.................] - ETA: 12:32 - loss: 0.2244 - accuracy: 0.9312 Step 969: Train Accuracy = 0.9312\n 969/2197 [============>.................] - ETA: 12:31 - loss: 0.2242 - accuracy: 0.9312 Step 970: Train Accuracy = 0.9313\n 970/2197 [============>.................] - ETA: 12:30 - loss: 0.2241 - accuracy: 0.9313 Step 971: Train Accuracy = 0.9313\n 971/2197 [============>.................] - ETA: 12:30 - loss: 0.2240 - accuracy: 0.9313 Step 972: Train Accuracy = 0.9313\n 972/2197 [============>.................] - ETA: 12:29 - loss: 0.2239 - accuracy: 0.9313 Step 973: Train Accuracy = 0.9313\n 973/2197 [============>.................] - ETA: 12:28 - loss: 0.2237 - accuracy: 0.9313 Step 974: Train Accuracy = 0.9314\n 974/2197 [============>.................] - ETA: 12:28 - loss: 0.2235 - accuracy: 0.9314 Step 975: Train Accuracy = 0.9315\n 975/2197 [============>.................] - ETA: 12:27 - loss: 0.2234 - accuracy: 0.9315 Step 976: Train Accuracy = 0.9315\n 976/2197 [============>.................] - ETA: 12:27 - loss: 0.2232 - accuracy: 0.9315 Step 977: Train Accuracy = 0.9315\n 977/2197 [============>.................] - ETA: 12:26 - loss: 0.2232 - accuracy: 0.9315 Step 978: Train Accuracy = 0.9316\n 978/2197 [============>.................] - ETA: 12:25 - loss: 0.2230 - accuracy: 0.9316 Step 979: Train Accuracy = 0.9316\n 979/2197 [============>.................] - ETA: 12:25 - loss: 0.2229 - accuracy: 0.9316 Step 980: Train Accuracy = 0.9317\n 980/2197 [============>.................] - ETA: 12:24 - loss: 0.2228 - accuracy: 0.9317 Step 981: Train Accuracy = 0.9317\n 981/2197 [============>.................] - ETA: 12:23 - loss: 0.2227 - accuracy: 0.9317 Step 982: Train Accuracy = 0.9318\n 982/2197 [============>.................] - ETA: 12:23 - loss: 0.2225 - accuracy: 0.9318 Step 983: Train Accuracy = 0.9318\n 983/2197 [============>.................] - ETA: 12:22 - loss: 0.2224 - accuracy: 0.9318 Step 984: Train Accuracy = 0.9318\n 984/2197 [============>.................] - ETA: 12:22 - loss: 0.2223 - accuracy: 0.9318 Step 985: Train Accuracy = 0.9318\n 985/2197 [============>.................] - ETA: 12:21 - loss: 0.2223 - accuracy: 0.9318 Step 986: Train Accuracy = 0.9318\n 986/2197 [============>.................] - ETA: 12:20 - loss: 0.2223 - accuracy: 0.9318 Step 987: Train Accuracy = 0.9318\n 987/2197 [============>.................] - ETA: 12:20 - loss: 0.2224 - accuracy: 0.9318 Step 988: Train Accuracy = 0.9319\n 988/2197 [============>.................] - ETA: 12:19 - loss: 0.2222 - accuracy: 0.9319 Step 989: Train Accuracy = 0.9319\n 989/2197 [============>.................] - ETA: 12:19 - loss: 0.2220 - accuracy: 0.9319 Step 990: Train Accuracy = 0.9319\n 990/2197 [============>.................] - ETA: 12:18 - loss: 0.2219 - accuracy: 0.9319 Step 991: Train Accuracy = 0.9320\n 991/2197 [============>.................] - ETA: 12:18 - loss: 0.2217 - accuracy: 0.9320 Step 992: Train Accuracy = 0.9320\n 992/2197 [============>.................] - ETA: 12:17 - loss: 0.2215 - accuracy: 0.9320 Step 993: Train Accuracy = 0.9321\n 993/2197 [============>.................] - ETA: 12:16 - loss: 0.2214 - accuracy: 0.9321 Step 994: Train Accuracy = 0.9320\n 994/2197 [============>.................] - ETA: 12:16 - loss: 0.2215 - accuracy: 0.9320 Step 995: Train Accuracy = 0.9321\n 995/2197 [============>.................] - ETA: 12:15 - loss: 0.2214 - accuracy: 0.9321 Step 996: Train Accuracy = 0.9321\n 996/2197 [============>.................] - ETA: 12:15 - loss: 0.2214 - accuracy: 0.9321 Step 997: Train Accuracy = 0.9321\n 997/2197 [============>.................] - ETA: 12:14 - loss: 0.2214 - accuracy: 0.9321 Step 998: Train Accuracy = 0.9321\n 998/2197 [============>.................] - ETA: 12:13 - loss: 0.2212 - accuracy: 0.9321 Step 999: Train Accuracy = 0.9321\n 999/2197 [============>.................] - ETA: 12:12 - loss: 0.2211 - accuracy: 0.9321 Step 1000: Train Accuracy = 0.9322\n1000/2197 [============>.................] - ETA: 12:12 - loss: 0.2209 - accuracy: 0.9322 Step 1001: Train Accuracy = 0.9322\n1001/2197 [============>.................] - ETA: 12:11 - loss: 0.2208 - accuracy: 0.9322 Step 1002: Train Accuracy = 0.9322\n1002/2197 [============>.................] - ETA: 12:10 - loss: 0.2206 - accuracy: 0.9322 Step 1003: Train Accuracy = 0.9323\n1003/2197 [============>.................] - ETA: 12:10 - loss: 0.2205 - accuracy: 0.9323 Step 1004: Train Accuracy = 0.9323\n1004/2197 [============>.................] - ETA: 12:09 - loss: 0.2204 - accuracy: 0.9323 Step 1005: Train Accuracy = 0.9324\n1005/2197 [============>.................] - ETA: 12:09 - loss: 0.2202 - accuracy: 0.9324 Step 1006: Train Accuracy = 0.9324\n1006/2197 [============>.................] - ETA: 12:08 - loss: 0.2200 - accuracy: 0.9324 Step 1007: Train Accuracy = 0.9325\n1007/2197 [============>.................] - ETA: 12:07 - loss: 0.2200 - accuracy: 0.9325 Step 1008: Train Accuracy = 0.9325\n1008/2197 [============>.................] - ETA: 12:07 - loss: 0.2199 - accuracy: 0.9325 Step 1009: Train Accuracy = 0.9325\n1009/2197 [============>.................] - ETA: 12:06 - loss: 0.2198 - accuracy: 0.9325 Step 1010: Train Accuracy = 0.9325\n1010/2197 [============>.................] - ETA: 12:06 - loss: 0.2196 - accuracy: 0.9325 Step 1011: Train Accuracy = 0.9326\n1011/2197 [============>.................] - ETA: 12:05 - loss: 0.2195 - accuracy: 0.9326 Step 1012: Train Accuracy = 0.9326\n1012/2197 [============>.................] - ETA: 12:04 - loss: 0.2194 - accuracy: 0.9326 Step 1013: Train Accuracy = 0.9326\n1013/2197 [============>.................] - ETA: 12:04 - loss: 0.2194 - accuracy: 0.9326 Step 1014: Train Accuracy = 0.9326\n1014/2197 [============>.................] - ETA: 12:03 - loss: 0.2193 - accuracy: 0.9326 Step 1015: Train Accuracy = 0.9326\n1015/2197 [============>.................] - ETA: 12:02 - loss: 0.2192 - accuracy: 0.9326 Step 1016: Train Accuracy = 0.9326\n1016/2197 [============>.................] - ETA: 12:01 - loss: 0.2193 - accuracy: 0.9326 Step 1017: Train Accuracy = 0.9326\n1017/2197 [============>.................] - ETA: 12:01 - loss: 0.2193 - accuracy: 0.9326 Step 1018: Train Accuracy = 0.9325\n1018/2197 [============>.................] - ETA: 12:00 - loss: 0.2196 - accuracy: 0.9325 Step 1019: Train Accuracy = 0.9326\n1019/2197 [============>.................] - ETA: 11:59 - loss: 0.2194 - accuracy: 0.9326 Step 1020: Train Accuracy = 0.9326\n1020/2197 [============>.................] - ETA: 11:59 - loss: 0.2192 - accuracy: 0.9326 Step 1021: Train Accuracy = 0.9326\n1021/2197 [============>.................] - ETA: 11:58 - loss: 0.2194 - accuracy: 0.9326 Step 1022: Train Accuracy = 0.9327\n1022/2197 [============>.................] - ETA: 11:58 - loss: 0.2193 - accuracy: 0.9327 Step 1023: Train Accuracy = 0.9327\n1023/2197 [============>.................] - ETA: 11:57 - loss: 0.2191 - accuracy: 0.9327 Step 1024: Train Accuracy = 0.9327\n1024/2197 [============>.................] - ETA: 11:57 - loss: 0.2191 - accuracy: 0.9327 Step 1025: Train Accuracy = 0.9327\n1025/2197 [============>.................] - ETA: 11:56 - loss: 0.2191 - accuracy: 0.9327 Step 1026: Train Accuracy = 0.9327\n1026/2197 [=============>................] - ETA: 11:56 - loss: 0.2189 - accuracy: 0.9327 Step 1027: Train Accuracy = 0.9327\n1027/2197 [=============>................] - ETA: 11:55 - loss: 0.2190 - accuracy: 0.9327 Step 1028: Train Accuracy = 0.9327\n1028/2197 [=============>................] - ETA: 11:55 - loss: 0.2190 - accuracy: 0.9327 Step 1029: Train Accuracy = 0.9328\n1029/2197 [=============>................] - ETA: 11:54 - loss: 0.2189 - accuracy: 0.9328 Step 1030: Train Accuracy = 0.9328\n1030/2197 [=============>................] - ETA: 11:53 - loss: 0.2189 - accuracy: 0.9328 Step 1031: Train Accuracy = 0.9328\n1031/2197 [=============>................] - ETA: 11:53 - loss: 0.2188 - accuracy: 0.9328 Step 1032: Train Accuracy = 0.9329\n1032/2197 [=============>................] - ETA: 11:52 - loss: 0.2187 - accuracy: 0.9329 Step 1033: Train Accuracy = 0.9328\n1033/2197 [=============>................] - ETA: 11:52 - loss: 0.2187 - accuracy: 0.9328 Step 1034: Train Accuracy = 0.9328\n1034/2197 [=============>................] - ETA: 11:51 - loss: 0.2187 - accuracy: 0.9328 Step 1035: Train Accuracy = 0.9328\n1035/2197 [=============>................] - ETA: 11:50 - loss: 0.2187 - accuracy: 0.9328 Step 1036: Train Accuracy = 0.9328\n1036/2197 [=============>................] - ETA: 11:50 - loss: 0.2186 - accuracy: 0.9328 Step 1037: Train Accuracy = 0.9328\n1037/2197 [=============>................] - ETA: 11:49 - loss: 0.2186 - accuracy: 0.9328 Step 1038: Train Accuracy = 0.9328\n1038/2197 [=============>................] - ETA: 11:49 - loss: 0.2185 - accuracy: 0.9328 Step 1039: Train Accuracy = 0.9328\n1039/2197 [=============>................] - ETA: 11:48 - loss: 0.2184 - accuracy: 0.9328 Step 1040: Train Accuracy = 0.9328\n1040/2197 [=============>................] - ETA: 11:47 - loss: 0.2182 - accuracy: 0.9328 Step 1041: Train Accuracy = 0.9328\n1041/2197 [=============>................] - ETA: 11:47 - loss: 0.2181 - accuracy: 0.9328 Step 1042: Train Accuracy = 0.9328\n1042/2197 [=============>................] - ETA: 11:46 - loss: 0.2182 - accuracy: 0.9328 Step 1043: Train Accuracy = 0.9329\n1043/2197 [=============>................] - ETA: 11:46 - loss: 0.2180 - accuracy: 0.9329 Step 1044: Train Accuracy = 0.9329\n1044/2197 [=============>................] - ETA: 11:45 - loss: 0.2179 - accuracy: 0.9329 Step 1045: Train Accuracy = 0.9329\n1045/2197 [=============>................] - ETA: 11:45 - loss: 0.2177 - accuracy: 0.9329 Step 1046: Train Accuracy = 0.9330\n1046/2197 [=============>................] - ETA: 11:44 - loss: 0.2175 - accuracy: 0.9330 Step 1047: Train Accuracy = 0.9330\n1047/2197 [=============>................] - ETA: 11:43 - loss: 0.2174 - accuracy: 0.9330 Step 1048: Train Accuracy = 0.9330\n1048/2197 [=============>................] - ETA: 11:43 - loss: 0.2173 - accuracy: 0.9330 Step 1049: Train Accuracy = 0.9331\n1049/2197 [=============>................] - ETA: 11:42 - loss: 0.2172 - accuracy: 0.9331 Step 1050: Train Accuracy = 0.9331\n1050/2197 [=============>................] - ETA: 11:41 - loss: 0.2172 - accuracy: 0.9331 Step 1051: Train Accuracy = 0.9331\n1051/2197 [=============>................] - ETA: 11:41 - loss: 0.2170 - accuracy: 0.9331 Step 1052: Train Accuracy = 0.9331\n1052/2197 [=============>................] - ETA: 11:40 - loss: 0.2169 - accuracy: 0.9331 Step 1053: Train Accuracy = 0.9331\n1053/2197 [=============>................] - ETA: 11:40 - loss: 0.2169 - accuracy: 0.9331 Step 1054: Train Accuracy = 0.9332\n1054/2197 [=============>................] - ETA: 11:39 - loss: 0.2168 - accuracy: 0.9332 Step 1055: Train Accuracy = 0.9331\n1055/2197 [=============>................] - ETA: 11:38 - loss: 0.2169 - accuracy: 0.9331 Step 1056: Train Accuracy = 0.9331\n1056/2197 [=============>................] - ETA: 11:38 - loss: 0.2168 - accuracy: 0.9331 Step 1057: Train Accuracy = 0.9331\n1057/2197 [=============>................] - ETA: 11:37 - loss: 0.2168 - accuracy: 0.9331 Step 1058: Train Accuracy = 0.9332\n1058/2197 [=============>................] - ETA: 11:36 - loss: 0.2167 - accuracy: 0.9332 Step 1059: Train Accuracy = 0.9332\n1059/2197 [=============>................] - ETA: 11:36 - loss: 0.2166 - accuracy: 0.9332 Step 1060: Train Accuracy = 0.9332\n1060/2197 [=============>................] - ETA: 11:35 - loss: 0.2167 - accuracy: 0.9332 Step 1061: Train Accuracy = 0.9332\n1061/2197 [=============>................] - ETA: 11:34 - loss: 0.2166 - accuracy: 0.9332 Step 1062: Train Accuracy = 0.9333\n1062/2197 [=============>................] - ETA: 11:34 - loss: 0.2164 - accuracy: 0.9333 Step 1063: Train Accuracy = 0.9333\n1063/2197 [=============>................] - ETA: 11:33 - loss: 0.2163 - accuracy: 0.9333 Step 1064: Train Accuracy = 0.9333\n1064/2197 [=============>................] - ETA: 11:33 - loss: 0.2162 - accuracy: 0.9333 Step 1065: Train Accuracy = 0.9333\n1065/2197 [=============>................] - ETA: 11:32 - loss: 0.2161 - accuracy: 0.9333 Step 1066: Train Accuracy = 0.9333\n1066/2197 [=============>................] - ETA: 11:31 - loss: 0.2161 - accuracy: 0.9333 Step 1067: Train Accuracy = 0.9334\n1067/2197 [=============>................] - ETA: 11:31 - loss: 0.2159 - accuracy: 0.9334 Step 1068: Train Accuracy = 0.9334\n1068/2197 [=============>................] - ETA: 11:30 - loss: 0.2158 - accuracy: 0.9334 Step 1069: Train Accuracy = 0.9334\n1069/2197 [=============>................] - ETA: 11:29 - loss: 0.2156 - accuracy: 0.9334 Step 1070: Train Accuracy = 0.9335\n1070/2197 [=============>................] - ETA: 11:29 - loss: 0.2155 - accuracy: 0.9335 Step 1071: Train Accuracy = 0.9335\n1071/2197 [=============>................] - ETA: 11:28 - loss: 0.2154 - accuracy: 0.9335 Step 1072: Train Accuracy = 0.9335\n1072/2197 [=============>................] - ETA: 11:28 - loss: 0.2153 - accuracy: 0.9335 Step 1073: Train Accuracy = 0.9334\n1073/2197 [=============>................] - ETA: 11:27 - loss: 0.2155 - accuracy: 0.9334 Step 1074: Train Accuracy = 0.9335\n1074/2197 [=============>................] - ETA: 11:27 - loss: 0.2154 - accuracy: 0.9335 Step 1075: Train Accuracy = 0.9334\n1075/2197 [=============>................] - ETA: 11:26 - loss: 0.2154 - accuracy: 0.9334 Step 1076: Train Accuracy = 0.9334\n1076/2197 [=============>................] - ETA: 11:25 - loss: 0.2154 - accuracy: 0.9334 Step 1077: Train Accuracy = 0.9334\n1077/2197 [=============>................] - ETA: 11:25 - loss: 0.2153 - accuracy: 0.9334 Step 1078: Train Accuracy = 0.9335\n1078/2197 [=============>................] - ETA: 11:24 - loss: 0.2152 - accuracy: 0.9335 Step 1079: Train Accuracy = 0.9335\n1079/2197 [=============>................] - ETA: 11:24 - loss: 0.2151 - accuracy: 0.9335 Step 1080: Train Accuracy = 0.9335\n1080/2197 [=============>................] - ETA: 11:23 - loss: 0.2150 - accuracy: 0.9335 Step 1081: Train Accuracy = 0.9335\n1081/2197 [=============>................] - ETA: 11:22 - loss: 0.2149 - accuracy: 0.9335 Step 1082: Train Accuracy = 0.9335\n1082/2197 [=============>................] - ETA: 11:22 - loss: 0.2149 - accuracy: 0.9335 Step 1083: Train Accuracy = 0.9335\n1083/2197 [=============>................] - ETA: 11:21 - loss: 0.2148 - accuracy: 0.9335 Step 1084: Train Accuracy = 0.9336\n1084/2197 [=============>................] - ETA: 11:21 - loss: 0.2147 - accuracy: 0.9336 Step 1085: Train Accuracy = 0.9336\n1085/2197 [=============>................] - ETA: 11:20 - loss: 0.2146 - accuracy: 0.9336 Step 1086: Train Accuracy = 0.9337\n1086/2197 [=============>................] - ETA: 11:19 - loss: 0.2146 - accuracy: 0.9337 Step 1087: Train Accuracy = 0.9337\n1087/2197 [=============>................] - ETA: 11:19 - loss: 0.2144 - accuracy: 0.9337 Step 1088: Train Accuracy = 0.9337\n1088/2197 [=============>................] - ETA: 11:18 - loss: 0.2144 - accuracy: 0.9337 Step 1089: Train Accuracy = 0.9337\n1089/2197 [=============>................] - ETA: 11:18 - loss: 0.2143 - accuracy: 0.9337 Step 1090: Train Accuracy = 0.9338\n1090/2197 [=============>................] - ETA: 11:17 - loss: 0.2141 - accuracy: 0.9338 Step 1091: Train Accuracy = 0.9338\n1091/2197 [=============>................] - ETA: 11:16 - loss: 0.2140 - accuracy: 0.9338 Step 1092: Train Accuracy = 0.9338\n1092/2197 [=============>................] - ETA: 11:16 - loss: 0.2139 - accuracy: 0.9338 Step 1093: Train Accuracy = 0.9338\n1093/2197 [=============>................] - ETA: 11:15 - loss: 0.2140 - accuracy: 0.9338 Step 1094: Train Accuracy = 0.9339\n1094/2197 [=============>................] - ETA: 11:14 - loss: 0.2139 - accuracy: 0.9339 Step 1095: Train Accuracy = 0.9338\n1095/2197 [=============>................] - ETA: 11:14 - loss: 0.2138 - accuracy: 0.9338 Step 1096: Train Accuracy = 0.9339\n1096/2197 [=============>................] - ETA: 11:13 - loss: 0.2137 - accuracy: 0.9339 Step 1097: Train Accuracy = 0.9339\n1097/2197 [=============>................] - ETA: 11:13 - loss: 0.2136 - accuracy: 0.9339 Step 1098: Train Accuracy = 0.9340\n1098/2197 [=============>................] - ETA: 11:12 - loss: 0.2134 - accuracy: 0.9340 Step 1099: Train Accuracy = 0.9340\n1099/2197 [==============>...............] - ETA: 11:12 - loss: 0.2132 - accuracy: 0.9340 Step 1100: Train Accuracy = 0.9340\n1100/2197 [==============>...............] - ETA: 11:11 - loss: 0.2132 - accuracy: 0.9340 Step 1101: Train Accuracy = 0.9341\n1101/2197 [==============>...............] - ETA: 11:10 - loss: 0.2130 - accuracy: 0.9341 Step 1102: Train Accuracy = 0.9341\n1102/2197 [==============>...............] - ETA: 11:10 - loss: 0.2130 - accuracy: 0.9341 Step 1103: Train Accuracy = 0.9341\n1103/2197 [==============>...............] - ETA: 11:09 - loss: 0.2129 - accuracy: 0.9341 Step 1104: Train Accuracy = 0.9341\n1104/2197 [==============>...............] - ETA: 11:08 - loss: 0.2128 - accuracy: 0.9341 Step 1105: Train Accuracy = 0.9341\n1105/2197 [==============>...............] - ETA: 11:08 - loss: 0.2128 - accuracy: 0.9341 Step 1106: Train Accuracy = 0.9341\n1106/2197 [==============>...............] - ETA: 11:07 - loss: 0.2127 - accuracy: 0.9341 Step 1107: Train Accuracy = 0.9342\n1107/2197 [==============>...............] - ETA: 11:07 - loss: 0.2127 - accuracy: 0.9342 Step 1108: Train Accuracy = 0.9342\n1108/2197 [==============>...............] - ETA: 11:06 - loss: 0.2125 - accuracy: 0.9342 Step 1109: Train Accuracy = 0.9341\n1109/2197 [==============>...............] - ETA: 11:05 - loss: 0.2128 - accuracy: 0.9341 Step 1110: Train Accuracy = 0.9341\n1110/2197 [==============>...............] - ETA: 11:05 - loss: 0.2126 - accuracy: 0.9341 Step 1111: Train Accuracy = 0.9342\n1111/2197 [==============>...............] - ETA: 11:04 - loss: 0.2124 - accuracy: 0.9342 Step 1112: Train Accuracy = 0.9342\n1112/2197 [==============>...............] - ETA: 11:04 - loss: 0.2124 - accuracy: 0.9342 Step 1113: Train Accuracy = 0.9343\n1113/2197 [==============>...............] - ETA: 11:03 - loss: 0.2122 - accuracy: 0.9343 Step 1114: Train Accuracy = 0.9343\n1114/2197 [==============>...............] - ETA: 11:02 - loss: 0.2121 - accuracy: 0.9343 Step 1115: Train Accuracy = 0.9343\n1115/2197 [==============>...............] - ETA: 11:02 - loss: 0.2121 - accuracy: 0.9343 Step 1116: Train Accuracy = 0.9343\n1116/2197 [==============>...............] - ETA: 11:01 - loss: 0.2121 - accuracy: 0.9343 Step 1117: Train Accuracy = 0.9343\n1117/2197 [==============>...............] - ETA: 11:00 - loss: 0.2120 - accuracy: 0.9343 Step 1118: Train Accuracy = 0.9343\n1118/2197 [==============>...............] - ETA: 11:00 - loss: 0.2120 - accuracy: 0.9343 Step 1119: Train Accuracy = 0.9343\n1119/2197 [==============>...............] - ETA: 10:59 - loss: 0.2119 - accuracy: 0.9343 Step 1120: Train Accuracy = 0.9343\n1120/2197 [==============>...............] - ETA: 10:58 - loss: 0.2118 - accuracy: 0.9343 Step 1121: Train Accuracy = 0.9343\n1121/2197 [==============>...............] - ETA: 10:58 - loss: 0.2118 - accuracy: 0.9343 Step 1122: Train Accuracy = 0.9343\n1122/2197 [==============>...............] - ETA: 10:57 - loss: 0.2118 - accuracy: 0.9343 Step 1123: Train Accuracy = 0.9343\n1123/2197 [==============>...............] - ETA: 10:57 - loss: 0.2117 - accuracy: 0.9343 Step 1124: Train Accuracy = 0.9343\n1124/2197 [==============>...............] - ETA: 10:56 - loss: 0.2117 - accuracy: 0.9343 Step 1125: Train Accuracy = 0.9343\n1125/2197 [==============>...............] - ETA: 10:55 - loss: 0.2116 - accuracy: 0.9343 Step 1126: Train Accuracy = 0.9344\n1126/2197 [==============>...............] - ETA: 10:55 - loss: 0.2115 - accuracy: 0.9344 Step 1127: Train Accuracy = 0.9344\n1127/2197 [==============>...............] - ETA: 10:54 - loss: 0.2114 - accuracy: 0.9344 Step 1128: Train Accuracy = 0.9344\n1128/2197 [==============>...............] - ETA: 10:54 - loss: 0.2113 - accuracy: 0.9344 Step 1129: Train Accuracy = 0.9344\n1129/2197 [==============>...............] - ETA: 10:53 - loss: 0.2113 - accuracy: 0.9344 Step 1130: Train Accuracy = 0.9344\n1130/2197 [==============>...............] - ETA: 10:52 - loss: 0.2112 - accuracy: 0.9344 Step 1131: Train Accuracy = 0.9344\n1131/2197 [==============>...............] - ETA: 10:52 - loss: 0.2111 - accuracy: 0.9344","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[50], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 17\u001b[0m     history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_generator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_batch_metrics\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError during training: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:2810\u001b[0m, in \u001b[0;36mModel.fit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2798\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fits the model on data yielded batch-by-batch by a Python generator.\u001b[39;00m\n\u001b[1;32m   2799\u001b[0m \n\u001b[1;32m   2800\u001b[0m \u001b[38;5;124;03mDEPRECATED:\u001b[39;00m\n\u001b[1;32m   2801\u001b[0m \u001b[38;5;124;03m  `Model.fit` now supports generators, so there is no longer any need to\u001b[39;00m\n\u001b[1;32m   2802\u001b[0m \u001b[38;5;124;03m  use this endpoint.\u001b[39;00m\n\u001b[1;32m   2803\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2804\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   2805\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`Model.fit_generator` is deprecated and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2806\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be removed in a future version. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2807\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease use `Model.fit`, which supports generators.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2808\u001b[0m     stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m   2809\u001b[0m )\n\u001b[0;32m-> 2810\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2811\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2812\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2813\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2814\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2815\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2816\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2817\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2818\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2819\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2820\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2821\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2822\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2823\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2824\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2825\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":50},{"cell_type":"markdown","source":"## 4. Evaluate the Model","metadata":{}},{"cell_type":"code","source":"# Evaluate on validation data\nval_loss, val_acc = model.evaluate(val_data)\nprint(f'Validation Loss: {val_loss}')\nprint(f'Validation Accuracy: {val_acc}')\n\n# Plot training history\nplt.figure(figsize=(12, 6))\nplt.plot(history.history['accuracy'], label='Train Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.title('Model Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()\n\nplt.figure(figsize=(12, 6))\nplt.plot(history.history['loss'], label='Train Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.title('Model Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T12:44:21.264620Z","iopub.status.idle":"2024-12-07T12:44:21.264916Z","shell.execute_reply.started":"2024-12-07T12:44:21.264777Z","shell.execute_reply":"2024-12-07T12:44:21.264792Z"}},"outputs":[],"execution_count":null}]}